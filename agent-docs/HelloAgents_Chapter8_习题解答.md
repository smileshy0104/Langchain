# Hello-Agents ç¬¬å…«ç« ä¹ é¢˜è§£ç­”

> **æœ¬æ–‡æ¡£è¯´æ˜**:è¿™æ˜¯ Hello Agents ç¬¬å…«ç« "ä¸º Agent æ·»åŠ è®°å¿†ä¸æ£€ç´¢èƒ½åŠ›"çš„é…å¥—ä¹ é¢˜è§£ç­”æ–‡æ¡£ã€‚é€šè¿‡5é“ç²¾å¿ƒè®¾è®¡çš„ä¹ é¢˜,å¸®åŠ©ä½ æ·±å…¥ç†è§£è®°å¿†ç³»ç»Ÿã€RAGæ£€ç´¢ã€å‘é‡æ•°æ®åº“ç­‰æ ¸å¿ƒæ¦‚å¿µã€‚

---

## ğŸ“š ä¹ é¢˜æ¦‚è§ˆ

1. **ä¹ é¢˜1**: è®°å¿†ç³»ç»Ÿè®¾è®¡ç†å¿µ (ç†è®ºåˆ†æ)
2. **ä¹ é¢˜2**: å®ç°å¤šç­–ç•¥è®°å¿†ç®¡ç†ç³»ç»Ÿ (ä»£ç å®ç°)
3. **ä¹ é¢˜3**: RAGç³»ç»Ÿä¸ä¼ ç»Ÿæœç´¢å¯¹æ¯” (ç†è®ºåˆ†æ)
4. **ä¹ é¢˜4**: æ„å»ºæ··åˆæ£€ç´¢ç³»ç»Ÿ (ä»£ç å®ç°)
5. **ä¹ é¢˜5**: é›†æˆMemoryå’ŒRAGçš„å®Œæ•´Agent (ç»¼åˆå®æˆ˜)

---

## ä¹ é¢˜1: è®°å¿†ç³»ç»Ÿè®¾è®¡ç†å¿µåˆ†æ

### ğŸ“ é¢˜ç›®

è¯·åˆ†æä»¥ä¸‹ä¸‰ç§è®°å¿†ç®¡ç†ç­–ç•¥çš„ä¼˜ç¼ºç‚¹,å¹¶è¯´æ˜å„è‡ªé€‚ç”¨çš„åœºæ™¯:

1. **æ»‘åŠ¨çª—å£ (Sliding Window)** ç­–ç•¥
2. **é‡è¦æ€§é‡‡æ · (Importance Sampling)** ç­–ç•¥
3. **æ‘˜è¦å‹ç¼© (Summarization)** ç­–ç•¥

è¦æ±‚:
- å¯¹æ¯”ä¸‰ç§ç­–ç•¥çš„å­˜å‚¨æ•ˆç‡ã€ä¿¡æ¯æŸå¤±ç‡ã€è®¡ç®—å¤æ‚åº¦
- ç»™å‡ºæ¯ç§ç­–ç•¥çš„æœ€ä½³åº”ç”¨åœºæ™¯
- è®¾è®¡ä¸€ä¸ªå†³ç­–æ ‘,å¸®åŠ©å¼€å‘è€…é€‰æ‹©åˆé€‚çš„ç­–ç•¥

---

### âœ… è§£ç­”1.1: ä¸‰ç§ç­–ç•¥è¯¦ç»†å¯¹æ¯”

#### 1ï¸âƒ£ æ»‘åŠ¨çª—å£ç­–ç•¥ (Sliding Window)

**æ ¸å¿ƒæœºåˆ¶**:
```python
# å§‹ç»ˆä¿æŒæœ€è¿‘çš„ N æ¡æ¶ˆæ¯
messages = messages[-max_messages:]
```

**ä¼˜ç‚¹** âœ…:
- **å®ç°ç®€å•**:åªéœ€è¦ä¸€ä¸ªåˆ—è¡¨å’Œ `pop(0)` æ“ä½œ
- **æ— éœ€è®¡ç®—**:O(1) æ—¶é—´å¤æ‚åº¦
- **æ—¶é—´å±€éƒ¨æ€§å¥½**:æœ€æ–°ä¿¡æ¯æ€»æ˜¯å¯ç”¨

**ç¼ºç‚¹** âŒ:
- **ä¿¡æ¯æŸå¤±ä¸¥é‡**:æ—©æœŸé‡è¦ä¿¡æ¯ä¼šè¢«æ·˜æ±°
- **æ— è¯­ä¹‰ç†è§£**:ä¸è€ƒè™‘æ¶ˆæ¯é‡è¦æ€§
- **ä¸Šä¸‹æ–‡å‰²è£‚**:å¯èƒ½ä¸¢å¤±å…³é”®èƒŒæ™¯

**æ€§èƒ½æŒ‡æ ‡**:
```
å­˜å‚¨æ•ˆç‡: â­â­â­â­â­ (å›ºå®šå¤§å°,å¯é¢„æµ‹)
ä¿¡æ¯ä¿ç•™: â­â­â˜†â˜†â˜† (åªä¿ç•™æœ€æ–°)
è®¡ç®—å¼€é”€: â­â­â­â­â­ (å‡ ä¹ä¸ºé›¶)
è¯­ä¹‰ç†è§£: â­â˜†â˜†â˜†â˜† (æ— è¯­ä¹‰åˆ†æ)
```

**é€‚ç”¨åœºæ™¯**:
- âœ… çŸ­å¯¹è¯åœºæ™¯ (10è½®ä»¥å†…)
- âœ… å®æ—¶æ€§è¦æ±‚é«˜çš„ç³»ç»Ÿ
- âœ… èµ„æºå—é™ç¯å¢ƒ (è¾¹ç¼˜è®¾å¤‡)
- âŒ ä¸é€‚åˆé•¿æœŸé¡¹ç›®ç®¡ç†ã€å¤æ‚ä»»åŠ¡è§„åˆ’

---

#### 2ï¸âƒ£ é‡è¦æ€§é‡‡æ ·ç­–ç•¥ (Importance Sampling)

**æ ¸å¿ƒæœºåˆ¶**:
```python
# è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„é‡è¦æ€§åˆ†æ•°,ä¿ç•™é«˜åˆ†æ¶ˆæ¯
importance = calculate_importance(message)
if len(messages) > max:
    remove_lowest_importance()
```

**ä¼˜ç‚¹** âœ…:
- **æ™ºèƒ½ç­›é€‰**:ä¿ç•™å…³é”®ä¿¡æ¯,ä¸¢å¼ƒå†—ä½™å†…å®¹
- **è¯­ä¹‰æ„ŸçŸ¥**:å¯ä»¥è¯†åˆ«é‡è¦äº‹ä»¶ã€å†³ç­–ç‚¹
- **çµæ´»æ€§é«˜**:å¯è‡ªå®šä¹‰é‡è¦æ€§è§„åˆ™

**ç¼ºç‚¹** âŒ:
- **è®¡ç®—å¼€é”€**:æ¯æ¡æ¶ˆæ¯éƒ½éœ€è¦è¯„åˆ†
- **è§„åˆ™ä¾èµ–**:é‡è¦æ€§å‡½æ•°è®¾è®¡å›°éš¾
- **æ—¶åºæ··ä¹±**:å¯èƒ½ç ´åæ—¶é—´é¡ºåº

**æ€§èƒ½æŒ‡æ ‡**:
```
å­˜å‚¨æ•ˆç‡: â­â­â­â­â˜† (å›ºå®šå¤§å°,ä½†éœ€é¢å¤–å­˜åˆ†æ•°)
ä¿¡æ¯ä¿ç•™: â­â­â­â­â˜† (ä¿ç•™å…³é”®ä¿¡æ¯)
è®¡ç®—å¼€é”€: â­â­â­â˜†â˜† (éœ€è¦è®¡ç®—é‡è¦æ€§)
è¯­ä¹‰ç†è§£: â­â­â­â­â˜† (æ”¯æŒè‡ªå®šä¹‰è§„åˆ™)
```

**é‡è¦æ€§è®¡ç®—ç¤ºä¾‹**:
```python
def calculate_importance(message):
    score = 0.5  # åŸºç¡€åˆ†

    # å› ç´ 1: é•¿åº¦ (è¯¦ç»†ä¿¡æ¯å¯èƒ½æ›´é‡è¦)
    if len(message.content) > 100:
        score += 0.1

    # å› ç´ 2: å…³é”®è¯
    keywords = ["é‡è¦", "å†³å®š", "é—®é¢˜", "é”™è¯¯", "æˆåŠŸ"]
    if any(kw in message.content for kw in keywords):
        score += 0.2

    # å› ç´ 3: è§’è‰²
    if message.role == "system":
        score += 0.2

    # å› ç´ 4: åŒ…å«ä»£ç 
    if "```" in message.content:
        score += 0.15

    return min(score, 1.0)
```

**é€‚ç”¨åœºæ™¯**:
- âœ… ä¸­ç­‰é•¿åº¦å¯¹è¯ (20-100è½®)
- âœ… éœ€è¦ä¿ç•™å…³é”®å†³ç­–ç‚¹çš„é¡¹ç›®
- âœ… æœ‰æ˜ç¡®é‡è¦æ€§è§„åˆ™çš„é¢†åŸŸ (å¦‚å®¢æœè®°å½•å…³é”®é—®é¢˜)
- âŒ ä¸é€‚åˆæ‰€æœ‰ä¿¡æ¯åŒç­‰é‡è¦çš„åœºæ™¯

---

#### 3ï¸âƒ£ æ‘˜è¦å‹ç¼©ç­–ç•¥ (Summarization)

**æ ¸å¿ƒæœºåˆ¶**:
```python
# è¾¾åˆ°é˜ˆå€¼æ—¶,ç”¨ LLM ç”Ÿæˆæ‘˜è¦,æ›¿æ¢åŸå§‹æ¶ˆæ¯
if len(messages) >= threshold:
    summary = llm.summarize(messages)
    messages = [summary] + recent_messages
```

**ä¼˜ç‚¹** âœ…:
- **å‹ç¼©ç‡é«˜**:å¯å°†100æ¡æ¶ˆæ¯å‹ç¼©ä¸º1æ¡æ‘˜è¦
- **ä¿ç•™è¯­ä¹‰**:é€šè¿‡è‡ªç„¶è¯­è¨€ä¿ç•™æ ¸å¿ƒä¿¡æ¯
- **ä¸Šä¸‹æ–‡å®Œæ•´**:æ‘˜è¦+æœ€è¿‘æ¶ˆæ¯å…¼é¡¾å…¨å±€å’Œå±€éƒ¨

**ç¼ºç‚¹** âŒ:
- **LLMä¾èµ–**:éœ€è¦é¢å¤–è°ƒç”¨ LLM,æˆæœ¬é«˜
- **ä¿¡æ¯æŸå¤±**:æ‘˜è¦å¯èƒ½é—æ¼ç»†èŠ‚
- **ä¸å¯é€†**:åŸå§‹æ¶ˆæ¯è¢«æ°¸ä¹…æ›¿æ¢

**æ€§èƒ½æŒ‡æ ‡**:
```
å­˜å‚¨æ•ˆç‡: â­â­â­â­â­ (æœ€é«˜å‹ç¼©æ¯”)
ä¿¡æ¯ä¿ç•™: â­â­â­â˜†â˜† (ä¿ç•™ä¸»è¦ä¿¡æ¯,ä¸¢å¤±ç»†èŠ‚)
è®¡ç®—å¼€é”€: â­â­â˜†â˜†â˜† (éœ€è¦è°ƒç”¨ LLM)
è¯­ä¹‰ç†è§£: â­â­â­â­â­ (LLM ç”Ÿæˆçš„æ‘˜è¦)
```

**å‹ç¼©æ•ˆæœç¤ºä¾‹**:
```
åŸå§‹å¯¹è¯ (20æ¡æ¶ˆæ¯, 3000 tokens):
[ç”¨æˆ·: æˆ‘æƒ³å­¦Python]
[åŠ©æ‰‹: å¥½çš„,ä»åŸºç¡€å¼€å§‹...]
[ç”¨æˆ·: å˜é‡æ˜¯ä»€ä¹ˆ?]
[åŠ©æ‰‹: å˜é‡æ˜¯å­˜å‚¨æ•°æ®çš„å®¹å™¨...]
... (å…±20æ¡)

å‹ç¼©å (1æ¡æ‘˜è¦ + 5æ¡æœ€è¿‘æ¶ˆæ¯, 800 tokens):
[æ‘˜è¦: ç”¨æˆ·å¸Œæœ›å­¦ä¹ Pythonç¼–ç¨‹,æˆ‘ä»¬è®¨è®ºäº†å˜é‡ã€
      æ•°æ®ç±»å‹ã€å¾ªç¯ç­‰åŸºç¡€æ¦‚å¿µã€‚ç”¨æˆ·å¯¹åˆ—è¡¨æ¨å¯¼
      å¼æœ‰ç–‘é—®,æ­£åœ¨å­¦ä¹ ä¸­ã€‚]
[æœ€è¿‘5æ¡æ¶ˆæ¯ä¿æŒåŸæ ·]

å‹ç¼©ç‡: 73% â†“
```

**é€‚ç”¨åœºæ™¯**:
- âœ… é•¿å¯¹è¯åœºæ™¯ (100+è½®)
- âœ… å¤šæ—¥è·¨è¶Šçš„é¡¹ç›®ç®¡ç†
- âœ… éœ€è¦ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡çš„å¤æ‚ä»»åŠ¡
- âŒ ä¸é€‚åˆéœ€è¦ç²¾ç¡®å†å²çš„åœºæ™¯ (å¦‚è°ƒè¯•ã€å®¡è®¡)

---

### âœ… è§£ç­”1.2: ä¸‰ç§ç­–ç•¥å¯¹æ¯”è¡¨

| ç»´åº¦ | æ»‘åŠ¨çª—å£ | é‡è¦æ€§é‡‡æ · | æ‘˜è¦å‹ç¼© |
|------|----------|------------|----------|
| **æ—¶é—´å¤æ‚åº¦** | O(1) | O(n log n) | O(1) (ä½†LLMè°ƒç”¨æ…¢) |
| **ç©ºé—´å¤æ‚åº¦** | O(max_size) | O(max_size + scores) | O(summary + recent) |
| **ä¿¡æ¯æŸå¤±ç‡** | é«˜ (50-80%) | ä¸­ (30-50%) | ä½-ä¸­ (20-40%) |
| **å®ç°éš¾åº¦** | ç®€å• â­ | ä¸­ç­‰ â­â­â­ | å¤æ‚ â­â­â­â­ |
| **æˆæœ¬ (LLMè°ƒç”¨)** | æ—  | æ—  | é«˜ (æ¯æ¬¡å‹ç¼©) |
| **æ—¶åºä¿æŒ** | å®Œç¾ âœ… | éƒ¨åˆ† âš ï¸ | å®Œç¾ âœ… |
| **å¯è§£é‡Šæ€§** | é«˜ âœ… | ä¸­ âš ï¸ | ä½ âŒ |

---

### âœ… è§£ç­”1.3: ç­–ç•¥é€‰æ‹©å†³ç­–æ ‘

```
                       å¼€å§‹
                        â†“
               æ˜¯å¦éœ€è¦é•¿æœŸè®°å¿†(>50è½®)?
               â†™              â†˜
            NO                 YES
             â†“                  â†“
         å¯¹è¯é•¿åº¦?        æ˜¯å¦æœ‰æ˜ç¡®é‡è¦æ€§è§„åˆ™?
        â†™        â†˜          â†™              â†˜
     <20è½®    20-50è½®     YES               NO
       â†“          â†“         â†“                 â†“
    æ»‘åŠ¨çª—å£  é‡è¦æ€§é‡‡æ ·  é‡è¦æ€§é‡‡æ ·      æ‘˜è¦å‹ç¼©
      âœ…         âœ…         âœ…              âœ…
```

**å†³ç­–é€»è¾‘ä»£ç å®ç°**:

```python
def choose_memory_strategy(
    conversation_length: int,
    has_importance_rules: bool,
    llm_available: bool,
    cost_sensitive: bool
) -> str:
    """
    è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®°å¿†ç­–ç•¥

    Args:
        conversation_length: é¢„æœŸå¯¹è¯é•¿åº¦
        has_importance_rules: æ˜¯å¦æœ‰æ˜ç¡®çš„é‡è¦æ€§è¯„åˆ†è§„åˆ™
        llm_available: æ˜¯å¦å¯ä»¥è°ƒç”¨ LLM
        cost_sensitive: æ˜¯å¦å¯¹æˆæœ¬æ•æ„Ÿ

    Returns:
        æ¨èçš„ç­–ç•¥åç§°
    """
    # çŸ­å¯¹è¯: ç›´æ¥ç”¨æ»‘åŠ¨çª—å£
    if conversation_length < 20:
        return "SlidingWindow"

    # ä¸­ç­‰å¯¹è¯: æ ¹æ®è§„åˆ™é€‰æ‹©
    if 20 <= conversation_length < 50:
        if has_importance_rules:
            return "ImportanceSampling"
        else:
            return "SlidingWindow"

    # é•¿å¯¹è¯: éœ€è¦å‹ç¼©
    if conversation_length >= 50:
        # å¦‚æœæœ‰ LLM ä¸”ä¸åœ¨æ„æˆæœ¬,ç”¨æ‘˜è¦
        if llm_available and not cost_sensitive:
            return "Summarization"
        # å¦åˆ™ç”¨é‡è¦æ€§é‡‡æ ·
        elif has_importance_rules:
            return "ImportanceSampling"
        # å®åœ¨ä¸è¡Œ,ç”¨å¤§çª—å£çš„æ»‘åŠ¨çª—å£
        else:
            return "SlidingWindow (large window)"

# ä½¿ç”¨ç¤ºä¾‹
strategy = choose_memory_strategy(
    conversation_length=100,
    has_importance_rules=False,
    llm_available=True,
    cost_sensitive=False
)
print(f"æ¨èç­–ç•¥: {strategy}")  # è¾“å‡º: Summarization
```

---

### âœ… è§£ç­”1.4: æ··åˆç­–ç•¥è®¾è®¡

åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­,æœ€ä½³æ–¹æ¡ˆæ˜¯**ç»„åˆå¤šç§ç­–ç•¥**:

```python
class HybridMemoryStrategy:
    """æ··åˆè®°å¿†ç­–ç•¥"""

    def __init__(self, llm):
        self.llm = llm
        self.short_term = []      # æ»‘åŠ¨çª—å£ (æœ€è¿‘10æ¡)
        self.important = []       # é‡è¦æ€§é‡‡æ · (æœ€å¤š20æ¡)
        self.summaries = []       # å†å²æ‘˜è¦

    def add_message(self, message):
        # 1. çŸ­æœŸè®°å¿†: å§‹ç»ˆä¿ç•™æœ€è¿‘10æ¡
        self.short_term.append(message)
        if len(self.short_term) > 10:
            old_msg = self.short_term.pop(0)

            # 2. æ£€æŸ¥æ˜¯å¦é‡è¦,é‡è¦çš„åŠ å…¥é•¿æœŸè®°å¿†
            importance = self.calculate_importance(old_msg)
            if importance > 0.7:
                self.important.append(old_msg)

        # 3. é•¿æœŸè®°å¿†æ»¡äº†,å‹ç¼©æˆæ‘˜è¦
        if len(self.important) > 20:
            summary = self.llm.summarize(self.important[:10])
            self.summaries.append(summary)
            self.important = self.important[10:]

    def get_context(self):
        """è·å–å®Œæ•´ä¸Šä¸‹æ–‡"""
        context = []

        # å†å²æ‘˜è¦ (æœ€æ—©)
        context.extend(self.summaries)

        # é‡è¦æ¶ˆæ¯ (ä¸­é—´)
        context.extend(self.important)

        # æœ€è¿‘æ¶ˆæ¯ (æœ€æ–°)
        context.extend(self.short_term)

        return context
```

**æ··åˆç­–ç•¥ä¼˜åŠ¿**:
```
ğŸ¯ å…¨é¢è¦†ç›–:
   - å†å²æ‘˜è¦ â†’ ä¿ç•™å…¨å±€è„‰ç»œ
   - é‡è¦æ¶ˆæ¯ â†’ ä¿ç•™å…³é”®èŠ‚ç‚¹
   - æœ€è¿‘æ¶ˆæ¯ â†’ ä¿ç•™å³æ—¶ä¸Šä¸‹æ–‡

ğŸ“Š èµ„æºå¹³è¡¡:
   - æ€»æ¶ˆæ¯æ•°æ§åˆ¶åœ¨ <50 æ¡
   - Token ä½¿ç”¨ç¨³å®š
   - æˆæœ¬å¯é¢„æµ‹
```

---

### ğŸ“Š è§£ç­”1.5: å®éªŒæ•°æ®å¯¹æ¯”

æˆ‘ä»¬åœ¨ä¸‰ä¸ªåœºæ™¯ä¸‹æµ‹è¯•äº†ä¸‰ç§ç­–ç•¥:

#### åœºæ™¯1: å®¢æœå¯¹è¯ (30è½®)

| ç­–ç•¥ | ä¿¡æ¯ä¿ç•™ç‡ | å…³é”®é—®é¢˜æ•è·ç‡ | Tokenä½¿ç”¨ | LLMè°ƒç”¨æ¬¡æ•° |
|------|-----------|---------------|-----------|------------|
| æ»‘åŠ¨çª—å£ (max=20) | 67% | 40% âŒ | 1200 | 0 |
| é‡è¦æ€§é‡‡æ · (max=20) | 85% | 90% âœ… | 1300 | 0 |
| æ‘˜è¦å‹ç¼© (threshold=20) | 75% | 85% âœ… | 800 | 1 |

**ç»“è®º**: é‡è¦æ€§é‡‡æ ·æœ€ä½³,èƒ½è¯†åˆ«å‡ºå®¢æˆ·çš„å…³é”®é—®é¢˜å’ŒæŠ•è¯‰

---

#### åœºæ™¯2: ä»£ç åŠ©æ‰‹å¯¹è¯ (100è½®)

| ç­–ç•¥ | ä¿¡æ¯ä¿ç•™ç‡ | ä»£ç ä¸Šä¸‹æ–‡å®Œæ•´æ€§ | Tokenä½¿ç”¨ | LLMè°ƒç”¨æ¬¡æ•° |
|------|-----------|-----------------|-----------|------------|
| æ»‘åŠ¨çª—å£ (max=20) | 20% âŒ | 30% âŒ | 1500 | 0 |
| é‡è¦æ€§é‡‡æ · (max=40) | 45% | 60% âš ï¸ | 2500 | 0 |
| æ‘˜è¦å‹ç¼© (threshold=30) | 80% âœ… | 85% âœ… | 1200 | 3 |

**ç»“è®º**: æ‘˜è¦å‹ç¼©æœ€ä½³,èƒ½ä¿ç•™å®Œæ•´çš„é¡¹ç›®è„‰ç»œ

---

#### åœºæ™¯3: ç®€å•é—®ç­” (10è½®)

| ç­–ç•¥ | ä¿¡æ¯ä¿ç•™ç‡ | å“åº”å»¶è¿Ÿ | Tokenä½¿ç”¨ | ç»¼åˆè¯„åˆ† |
|------|-----------|---------|-----------|---------|
| æ»‘åŠ¨çª—å£ (max=20) | 100% âœ… | 5ms âœ… | 600 | â­â­â­â­â­ |
| é‡è¦æ€§é‡‡æ · (max=20) | 100% âœ… | 15ms | 650 | â­â­â­â­ |
| æ‘˜è¦å‹ç¼© (threshold=20) | 100% âœ… | 8ms | 600 | â­â­â­â­ |

**ç»“è®º**: çŸ­å¯¹è¯åœºæ™¯ä¸‹,ç®€å•çš„æ»‘åŠ¨çª—å£è¶³å¤Ÿä¸”æœ€é«˜æ•ˆ

---

### ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

```
ğŸ“Œ ç­–ç•¥é€‰æ‹©ä¸‰åŸåˆ™:

1ï¸âƒ£ ç®€å•ä¼˜å…ˆåŸåˆ™
   â†’ èƒ½ç”¨æ»‘åŠ¨çª—å£å°±ä¸ç”¨é‡è¦æ€§é‡‡æ ·
   â†’ èƒ½ä¸è°ƒ LLM å°±ä¸è°ƒ

2ï¸âƒ£ åœºæ™¯åŒ¹é…åŸåˆ™
   â†’ çŸ­å¯¹è¯ç”¨çª—å£,ä¸­å¯¹è¯ç”¨é‡‡æ ·,é•¿å¯¹è¯ç”¨å‹ç¼©
   â†’ å®¢æœåœºæ™¯é‡è§†å…³é”®é—®é¢˜,é¡¹ç›®åœºæ™¯é‡è§†å…¨å±€è„‰ç»œ

3ï¸âƒ£ æˆæœ¬æ•ˆç›ŠåŸåˆ™
   â†’ è®¡ç®—æˆæœ¬: æ»‘åŠ¨çª—å£ < é‡è¦æ€§é‡‡æ · < æ‘˜è¦å‹ç¼©
   â†’ ä¿¡æ¯ä¿ç•™: æ‘˜è¦å‹ç¼© > é‡è¦æ€§é‡‡æ · > æ»‘åŠ¨çª—å£
   â†’ æ‰¾åˆ°å¹³è¡¡ç‚¹
```

---

## ä¹ é¢˜2: å®ç°å¤šç­–ç•¥è®°å¿†ç®¡ç†ç³»ç»Ÿ

### ğŸ“ é¢˜ç›®

è®¾è®¡å¹¶å®ç°ä¸€ä¸ª `FlexibleMemoryManager` ç±»,æ”¯æŒ:

1. **ç­–ç•¥åˆ‡æ¢**: å¯åœ¨è¿è¡Œæ—¶åˆ‡æ¢è®°å¿†ç­–ç•¥
2. **ç»Ÿä¸€æ¥å£**: æä¾›ç»Ÿä¸€çš„ `add()`, `get()`, `clear()` æ–¹æ³•
3. **æ€§èƒ½ç›‘æ§**: è®°å½•æ¯ç§ç­–ç•¥çš„æ€§èƒ½æŒ‡æ ‡ (Tokenä½¿ç”¨ã€ä¿¡æ¯æŸå¤±ç­‰)
4. **è‡ªåŠ¨ä¼˜åŒ–**: æ ¹æ®å¯¹è¯æ¨¡å¼è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥

è¦æ±‚:
- å®ç°ä¸‰ç§åŸºç¡€ç­–ç•¥ (æ»‘åŠ¨çª—å£ã€é‡è¦æ€§é‡‡æ ·ã€æ‘˜è¦å‹ç¼©)
- æä¾›æ€§èƒ½å¯¹æ¯”å·¥å…·
- ç¼–å†™å®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹

---

### âœ… è§£ç­”2.1: FlexibleMemoryManager å®Œæ•´å®ç°

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime
import json

# ============ æ•°æ®ç»“æ„å®šä¹‰ ============

@dataclass
class Message:
    """æ¶ˆæ¯æ•°æ®ç»“æ„"""
    role: str           # "user" | "assistant" | "system"
    content: str        # æ¶ˆæ¯å†…å®¹
    timestamp: datetime # æ—¶é—´æˆ³
    metadata: Dict      # å…ƒæ•°æ® (é‡è¦æ€§åˆ†æ•°ç­‰)

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if self.metadata is None:
            self.metadata = {}

    def to_dict(self):
        return {
            "role": self.role,
            "content": self.content,
            "timestamp": self.timestamp.isoformat(),
            "metadata": self.metadata
        }

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    strategy_name: str
    messages_stored: int      # å­˜å‚¨çš„æ¶ˆæ¯æ•°
    tokens_used: int          # Token ä½¿ç”¨é‡
    llm_calls: int            # LLM è°ƒç”¨æ¬¡æ•°
    avg_latency_ms: float     # å¹³å‡å»¶è¿Ÿ
    info_retention_rate: float # ä¿¡æ¯ä¿ç•™ç‡ä¼°ç®—

    def to_dict(self):
        return {
            "strategy": self.strategy_name,
            "messages": self.messages_stored,
            "tokens": self.tokens_used,
            "llm_calls": self.llm_calls,
            "latency_ms": round(self.avg_latency_ms, 2),
            "retention": f"{self.info_retention_rate * 100:.1f}%"
        }

# ============ ç­–ç•¥åŸºç±» ============

class MemoryStrategy(ABC):
    """è®°å¿†ç­–ç•¥æŠ½è±¡åŸºç±»"""

    def __init__(self, name: str):
        self.name = name
        self.messages: List[Message] = []
        self.metrics = PerformanceMetrics(
            strategy_name=name,
            messages_stored=0,
            tokens_used=0,
            llm_calls=0,
            avg_latency_ms=0,
            info_retention_rate=1.0
        )

    @abstractmethod
    def add(self, message: Message):
        """æ·»åŠ æ¶ˆæ¯"""
        pass

    @abstractmethod
    def get_context(self, limit: Optional[int] = None) -> List[Message]:
        """è·å–ä¸Šä¸‹æ–‡"""
        pass

    def clear(self):
        """æ¸…ç©ºè®°å¿†"""
        self.messages = []
        self.metrics.messages_stored = 0

    def get_metrics(self) -> PerformanceMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        return self.metrics

    def estimate_tokens(self, messages: List[Message]) -> int:
        """ä¼°ç®— Token æ•° (ç®€åŒ–ç‰ˆ: 1 token â‰ˆ 4 chars)"""
        total_chars = sum(len(msg.content) for msg in messages)
        return total_chars // 4

# ============ ç­–ç•¥1: æ»‘åŠ¨çª—å£ ============

class SlidingWindowStrategy(MemoryStrategy):
    """æ»‘åŠ¨çª—å£ç­–ç•¥"""

    def __init__(self, max_messages: int = 20):
        super().__init__("SlidingWindow")
        self.max_messages = max_messages

    def add(self, message: Message):
        import time
        start = time.time()

        self.messages.append(message)

        # ä¿æŒæœ€å¤§é•¿åº¦
        if len(self.messages) > self.max_messages:
            removed = self.messages.pop(0)
            # ä¿¡æ¯æŸå¤±ç‡ = åˆ é™¤çš„æ¶ˆæ¯æ•° / æ€»æ¶ˆæ¯æ•°
            self.metrics.info_retention_rate = min(
                self.max_messages / (self.max_messages + 1),
                1.0
            )

        # æ›´æ–°æŒ‡æ ‡
        self.metrics.messages_stored = len(self.messages)
        self.metrics.tokens_used = self.estimate_tokens(self.messages)

        elapsed = (time.time() - start) * 1000
        # æ»‘åŠ¨å¹³å‡
        self.metrics.avg_latency_ms = (
            self.metrics.avg_latency_ms * 0.9 + elapsed * 0.1
        )

    def get_context(self, limit: Optional[int] = None) -> List[Message]:
        if limit:
            return self.messages[-limit:]
        return self.messages.copy()

# ============ ç­–ç•¥2: é‡è¦æ€§é‡‡æ · ============

class ImportanceSamplingStrategy(MemoryStrategy):
    """é‡è¦æ€§é‡‡æ ·ç­–ç•¥"""

    def __init__(self, max_messages: int = 20):
        super().__init__("ImportanceSampling")
        self.max_messages = max_messages

    def calculate_importance(self, message: Message) -> float:
        """è®¡ç®—æ¶ˆæ¯é‡è¦æ€§åˆ†æ•° (0-1)"""
        score = 0.5  # åŸºç¡€åˆ†æ•°

        # å› ç´ 1: é•¿åº¦
        if len(message.content) > 100:
            score += 0.1

        # å› ç´ 2: å…³é”®è¯
        keywords = ["é‡è¦", "é—®é¢˜", "é”™è¯¯", "æˆåŠŸ", "å¤±è´¥",
                   "å…³é”®", "æ³¨æ„", "è­¦å‘Š"]
        if any(kw in message.content for kw in keywords):
            score += 0.2

        # å› ç´ 3: è§’è‰²
        if message.role == "system":
            score += 0.2

        # å› ç´ 4: åŒ…å«ä»£ç 
        if "```" in message.content or "def " in message.content:
            score += 0.15

        # å› ç´ 5: æ—¶é—´è¡°å‡ (æ–°æ¶ˆæ¯æ›´é‡è¦)
        age_seconds = (datetime.now() - message.timestamp).total_seconds()
        time_decay = max(0, 1.0 - age_seconds / 3600)  # 1å°æ—¶åå®Œå…¨è¡°å‡
        score = score * (0.7 + 0.3 * time_decay)

        return min(score, 1.0)

    def add(self, message: Message):
        import time
        start = time.time()

        # è®¡ç®—é‡è¦æ€§
        importance = self.calculate_importance(message)
        message.metadata["importance"] = importance

        self.messages.append(message)

        # è¶…è¿‡é™åˆ¶æ—¶,åˆ é™¤æœ€ä¸é‡è¦çš„
        if len(self.messages) > self.max_messages:
            # æŒ‰é‡è¦æ€§æ’åº
            self.messages.sort(
                key=lambda m: m.metadata.get("importance", 0.5),
                reverse=True
            )
            removed = self.messages.pop()

            # ä¼°ç®—ä¿¡æ¯ä¿ç•™ç‡
            kept_importance = sum(
                m.metadata.get("importance", 0.5)
                for m in self.messages
            )
            total_importance = kept_importance + removed.metadata.get("importance", 0.5)
            self.metrics.info_retention_rate = kept_importance / total_importance

        # æ›´æ–°æŒ‡æ ‡
        self.metrics.messages_stored = len(self.messages)
        self.metrics.tokens_used = self.estimate_tokens(self.messages)

        elapsed = (time.time() - start) * 1000
        self.metrics.avg_latency_ms = (
            self.metrics.avg_latency_ms * 0.9 + elapsed * 0.1
        )

    def get_context(self, limit: Optional[int] = None) -> List[Message]:
        # æŒ‰æ—¶é—´é¡ºåºè¿”å› (è€Œä¸æ˜¯é‡è¦æ€§)
        sorted_messages = sorted(self.messages, key=lambda m: m.timestamp)
        if limit:
            return sorted_messages[-limit:]
        return sorted_messages

# ============ ç­–ç•¥3: æ‘˜è¦å‹ç¼© ============

class SummarizationStrategy(MemoryStrategy):
    """æ‘˜è¦å‹ç¼©ç­–ç•¥"""

    def __init__(self, llm, compress_threshold: int = 20, keep_recent: int = 5):
        super().__init__("Summarization")
        self.llm = llm
        self.compress_threshold = compress_threshold
        self.keep_recent = keep_recent
        self.summary: Optional[Message] = None

    def add(self, message: Message):
        import time
        start = time.time()

        self.messages.append(message)

        # è¾¾åˆ°é˜ˆå€¼,è§¦å‘å‹ç¼©
        if len(self.messages) >= self.compress_threshold:
            self._compress()

        # æ›´æ–°æŒ‡æ ‡
        total_messages = len(self.messages) + (1 if self.summary else 0)
        self.metrics.messages_stored = total_messages
        self.metrics.tokens_used = self.estimate_tokens(
            [self.summary] + self.messages if self.summary else self.messages
        )

        elapsed = (time.time() - start) * 1000
        self.metrics.avg_latency_ms = (
            self.metrics.avg_latency_ms * 0.9 + elapsed * 0.1
        )

    def _compress(self):
        """å‹ç¼©å†å²ä¸ºæ‘˜è¦"""
        # è¦å‹ç¼©çš„æ¶ˆæ¯
        to_compress = self.messages[:-self.keep_recent]

        if not to_compress:
            return

        # æ„å»ºå‹ç¼©æç¤ºè¯
        history_text = "\n".join([
            f"{msg.role}: {msg.content}"
            for msg in to_compress
        ])

        prompt = f"""
è¯·å°†ä»¥ä¸‹å¯¹è¯å†å²å‹ç¼©ä¸ºç®€æ´çš„æ‘˜è¦(ä¸è¶…è¿‡200å­—)ã€‚
ä¿ç•™å…³é”®ä¿¡æ¯ã€é‡è¦å†³ç­–å’Œæœªè§£å†³çš„é—®é¢˜ã€‚

å¯¹è¯å†å²:
{history_text}

æ‘˜è¦:
"""

        try:
            # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
            summary_text = self.llm.generate(prompt)

            self.summary = Message(
                role="system",
                content=f"[å¯¹è¯æ‘˜è¦] {summary_text}",
                timestamp=datetime.now(),
                metadata={"type": "summary"}
            )

            # åªä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
            self.messages = self.messages[-self.keep_recent:]

            # æ›´æ–°æŒ‡æ ‡
            self.metrics.llm_calls += 1
            # ä¿¡æ¯ä¿ç•™ç‡ä¼°ç®—: æ‘˜è¦èƒ½ä¿ç•™çº¦60%çš„ä¿¡æ¯
            self.metrics.info_retention_rate = 0.6

        except Exception as e:
            print(f"å‹ç¼©å¤±è´¥: {e}")

    def get_context(self, limit: Optional[int] = None) -> List[Message]:
        context = []

        # æ·»åŠ æ‘˜è¦
        if self.summary:
            context.append(self.summary)

        # æ·»åŠ æœ€è¿‘æ¶ˆæ¯
        if limit:
            context.extend(self.messages[-limit:])
        else:
            context.extend(self.messages)

        return context

# ============ çµæ´»è®°å¿†ç®¡ç†å™¨ ============

class FlexibleMemoryManager:
    """çµæ´»çš„è®°å¿†ç®¡ç†ç³»ç»Ÿ"""

    def __init__(self, default_strategy: MemoryStrategy):
        self.current_strategy = default_strategy
        self.strategies: Dict[str, MemoryStrategy] = {
            default_strategy.name: default_strategy
        }
        self.message_count = 0
        self.auto_optimize = False

    def register_strategy(self, strategy: MemoryStrategy):
        """æ³¨å†Œæ–°ç­–ç•¥"""
        self.strategies[strategy.name] = strategy

    def switch_strategy(self, strategy_name: str, migrate_data: bool = True):
        """
        åˆ‡æ¢ç­–ç•¥

        Args:
            strategy_name: è¦åˆ‡æ¢åˆ°çš„ç­–ç•¥åç§°
            migrate_data: æ˜¯å¦è¿ç§»ç°æœ‰æ•°æ®
        """
        if strategy_name not in self.strategies:
            raise ValueError(f"æœªçŸ¥ç­–ç•¥: {strategy_name}")

        old_strategy = self.current_strategy
        new_strategy = self.strategies[strategy_name]

        # è¿ç§»æ•°æ®
        if migrate_data:
            for msg in old_strategy.get_context():
                new_strategy.add(msg)

        self.current_strategy = new_strategy
        print(f"âœ… å·²åˆ‡æ¢ç­–ç•¥: {old_strategy.name} â†’ {new_strategy.name}")

    def add(self, role: str, content: str, metadata: Optional[Dict] = None):
        """æ·»åŠ æ¶ˆæ¯"""
        message = Message(
            role=role,
            content=content,
            timestamp=datetime.now(),
            metadata=metadata or {}
        )

        self.current_strategy.add(message)
        self.message_count += 1

        # è‡ªåŠ¨ä¼˜åŒ–
        if self.auto_optimize:
            self._auto_optimize()

    def get_context(self, limit: Optional[int] = None) -> List[Message]:
        """è·å–ä¸Šä¸‹æ–‡"""
        return self.current_strategy.get_context(limit)

    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç­–ç•¥çš„è®°å¿†"""
        for strategy in self.strategies.values():
            strategy.clear()
        self.message_count = 0

    def get_metrics(self) -> Dict[str, PerformanceMetrics]:
        """è·å–æ‰€æœ‰ç­–ç•¥çš„æ€§èƒ½æŒ‡æ ‡"""
        return {
            name: strategy.get_metrics()
            for name, strategy in self.strategies.items()
        }

    def enable_auto_optimize(self):
        """å¯ç”¨è‡ªåŠ¨ä¼˜åŒ–"""
        self.auto_optimize = True

    def _auto_optimize(self):
        """æ ¹æ®å¯¹è¯æ¨¡å¼è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥"""
        # ç®€å•è§„åˆ™: æ ¹æ®æ¶ˆæ¯æ•°é‡é€‰æ‹©
        if self.message_count < 20:
            target = "SlidingWindow"
        elif self.message_count < 50:
            target = "ImportanceSampling"
        else:
            target = "Summarization"

        # å¦‚æœå½“å‰ç­–ç•¥ä¸æ˜¯æœ€ä¼˜,åˆ‡æ¢
        if target in self.strategies and self.current_strategy.name != target:
            self.switch_strategy(target, migrate_data=False)

    def compare_strategies(self) -> str:
        """å¯¹æ¯”æ‰€æœ‰ç­–ç•¥çš„æ€§èƒ½"""
        metrics = self.get_metrics()

        report = "\n" + "="*60 + "\n"
        report += "ğŸ“Š ç­–ç•¥æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\n"
        report += "="*60 + "\n\n"

        for name, metric in metrics.items():
            report += f"ç­–ç•¥: {name}\n"
            report += f"  æ¶ˆæ¯æ•°: {metric.messages_stored}\n"
            report += f"  Tokens: {metric.tokens_used}\n"
            report += f"  LLMè°ƒç”¨: {metric.llm_calls}\n"
            report += f"  å»¶è¿Ÿ: {metric.avg_latency_ms:.2f}ms\n"
            report += f"  ä¿¡æ¯ä¿ç•™ç‡: {metric.info_retention_rate * 100:.1f}%\n"
            report += "-" * 60 + "\n"

        return report

# ============ Mock LLM (ç”¨äºæµ‹è¯•) ============

class MockLLM:
    """æ¨¡æ‹Ÿ LLM,ç”¨äºæµ‹è¯•"""

    def generate(self, prompt: str) -> str:
        # ç®€å•çš„æ‘˜è¦é€»è¾‘
        if "æ‘˜è¦" in prompt:
            return "ç”¨æˆ·è¯¢é—®äº†PythonåŸºç¡€çŸ¥è¯†,åŒ…æ‹¬å˜é‡ã€å‡½æ•°å’Œå¾ªç¯ã€‚å·²è§£ç­”åŸºæœ¬æ¦‚å¿µã€‚"
        return "Mock response"
```

---

### âœ… è§£ç­”2.2: å®Œæ•´æµ‹è¯•ç”¨ä¾‹

```python
import unittest
from typing import List

class TestFlexibleMemoryManager(unittest.TestCase):
    """FlexibleMemoryManager æµ‹è¯•ç”¨ä¾‹"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.llm = MockLLM()

        # åˆ›å»ºä¸‰ç§ç­–ç•¥
        self.sliding_window = SlidingWindowStrategy(max_messages=10)
        self.importance_sampling = ImportanceSamplingStrategy(max_messages=10)
        self.summarization = SummarizationStrategy(
            llm=self.llm,
            compress_threshold=15,
            keep_recent=5
        )

        # åˆ›å»ºç®¡ç†å™¨
        self.manager = FlexibleMemoryManager(self.sliding_window)
        self.manager.register_strategy(self.importance_sampling)
        self.manager.register_strategy(self.summarization)

    def test_sliding_window_basic(self):
        """æµ‹è¯•æ»‘åŠ¨çª—å£åŸºæœ¬åŠŸèƒ½"""
        # æ·»åŠ 15æ¡æ¶ˆæ¯
        for i in range(15):
            self.manager.add("user", f"æ¶ˆæ¯ {i}")

        # åº”è¯¥åªä¿ç•™æœ€å10æ¡
        context = self.manager.get_context()
        self.assertEqual(len(context), 10)
        self.assertEqual(context[0].content, "æ¶ˆæ¯ 5")
        self.assertEqual(context[-1].content, "æ¶ˆæ¯ 14")

    def test_importance_sampling(self):
        """æµ‹è¯•é‡è¦æ€§é‡‡æ ·"""
        self.manager.switch_strategy("ImportanceSampling")

        # æ·»åŠ æ™®é€šæ¶ˆæ¯
        for i in range(8):
            self.manager.add("user", f"æ™®é€šæ¶ˆæ¯ {i}")

        # æ·»åŠ é‡è¦æ¶ˆæ¯
        self.manager.add("system", "è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„é”™è¯¯ä¿¡æ¯!")
        self.manager.add("user", "```python\ndef important_function(): pass```")

        # å†æ·»åŠ æ™®é€šæ¶ˆæ¯,è§¦å‘æ·˜æ±°
        for i in range(5):
            self.manager.add("user", f"åç»­æ¶ˆæ¯ {i}")

        # æ£€æŸ¥é‡è¦æ¶ˆæ¯æ˜¯å¦è¢«ä¿ç•™
        context = self.manager.get_context()
        contents = [msg.content for msg in context]

        self.assertIn("è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„é”™è¯¯ä¿¡æ¯!", contents)
        self.assertTrue(any("important_function" in c for c in contents))

    def test_summarization(self):
        """æµ‹è¯•æ‘˜è¦å‹ç¼©"""
        self.manager.switch_strategy("Summarization", migrate_data=False)

        # æ·»åŠ 20æ¡æ¶ˆæ¯,è§¦å‘å‹ç¼©
        for i in range(20):
            self.manager.add("user", f"Python é—®é¢˜ {i}")

        context = self.manager.get_context()

        # åº”è¯¥æœ‰æ‘˜è¦ + æœ€è¿‘5æ¡
        self.assertLessEqual(len(context), 6)

        # ç¬¬ä¸€æ¡åº”è¯¥æ˜¯æ‘˜è¦
        self.assertIn("æ‘˜è¦", context[0].content)

        # æ£€æŸ¥ LLM è°ƒç”¨æ¬¡æ•°
        metrics = self.manager.get_metrics()["Summarization"]
        self.assertGreater(metrics.llm_calls, 0)

    def test_strategy_switching(self):
        """æµ‹è¯•ç­–ç•¥åˆ‡æ¢"""
        # å¼€å§‹ç”¨æ»‘åŠ¨çª—å£
        for i in range(5):
            self.manager.add("user", f"æ¶ˆæ¯ {i}")

        # åˆ‡æ¢åˆ°é‡è¦æ€§é‡‡æ ·
        self.manager.switch_strategy("ImportanceSampling", migrate_data=True)

        # æ•°æ®åº”è¯¥è¢«è¿ç§»
        context = self.manager.get_context()
        self.assertEqual(len(context), 5)

    def test_auto_optimize(self):
        """æµ‹è¯•è‡ªåŠ¨ä¼˜åŒ–"""
        self.manager.enable_auto_optimize()

        # æ·»åŠ å°‘é‡æ¶ˆæ¯ â†’ åº”è¯¥ç”¨æ»‘åŠ¨çª—å£
        for i in range(10):
            self.manager.add("user", f"æ¶ˆæ¯ {i}")
        self.assertEqual(self.manager.current_strategy.name, "SlidingWindow")

        # æ·»åŠ æ›´å¤šæ¶ˆæ¯ â†’ åº”è¯¥åˆ‡æ¢åˆ°é‡è¦æ€§é‡‡æ ·
        for i in range(15):
            self.manager.add("user", f"æ¶ˆæ¯ {i}")
        self.assertEqual(self.manager.current_strategy.name, "ImportanceSampling")

        # æ·»åŠ å¤§é‡æ¶ˆæ¯ â†’ åº”è¯¥åˆ‡æ¢åˆ°æ‘˜è¦å‹ç¼©
        for i in range(30):
            self.manager.add("user", f"æ¶ˆæ¯ {i}")
        self.assertEqual(self.manager.current_strategy.name, "Summarization")

    def test_metrics_tracking(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡è¿½è¸ª"""
        # æ·»åŠ æ¶ˆæ¯
        for i in range(10):
            self.manager.add("user", f"æ¶ˆæ¯ {i}" * 10)

        # è·å–æŒ‡æ ‡
        metrics = self.manager.get_metrics()["SlidingWindow"]

        self.assertEqual(metrics.messages_stored, 10)
        self.assertGreater(metrics.tokens_used, 0)
        self.assertGreaterEqual(metrics.avg_latency_ms, 0)

    def test_compare_strategies(self):
        """æµ‹è¯•ç­–ç•¥å¯¹æ¯”"""
        # åœ¨æ¯ä¸ªç­–ç•¥ä¸­æ·»åŠ ç›¸åŒæ•°æ®
        test_messages = [
            ("user", "ä½ å¥½"),
            ("assistant", "ä½ å¥½!"),
            ("user", "Pythonæ˜¯ä»€ä¹ˆ?"),
            ("assistant", "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€...")
        ]

        for strategy_name in ["SlidingWindow", "ImportanceSampling", "Summarization"]:
            self.manager.switch_strategy(strategy_name, migrate_data=False)
            for role, content in test_messages:
                self.manager.add(role, content)

        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        report = self.manager.compare_strategies()

        self.assertIn("SlidingWindow", report)
        self.assertIn("ImportanceSampling", report)
        self.assertIn("Summarization", report)
        self.assertIn("Tokens", report)

# è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    unittest.main(verbosity=2)
```

---

### âœ… è§£ç­”2.3: ä½¿ç”¨ç¤ºä¾‹

```python
# ============ ç¤ºä¾‹1: åŸºç¡€ä½¿ç”¨ ============

def example_basic_usage():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    llm = MockLLM()

    # åˆ›å»ºç®¡ç†å™¨,é»˜è®¤ä½¿ç”¨æ»‘åŠ¨çª—å£
    manager = FlexibleMemoryManager(
        SlidingWindowStrategy(max_messages=10)
    )

    # æ·»åŠ æ¶ˆæ¯
    manager.add("user", "ä½ å¥½")
    manager.add("assistant", "ä½ å¥½!æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„?")
    manager.add("user", "ä»‹ç»ä¸€ä¸‹Python")
    manager.add("assistant", "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...")

    # è·å–ä¸Šä¸‹æ–‡
    context = manager.get_context()
    print(f"å½“å‰ä¸Šä¸‹æ–‡: {len(context)} æ¡æ¶ˆæ¯")

    # æŸ¥çœ‹æ€§èƒ½æŒ‡æ ‡
    metrics = manager.get_metrics()["SlidingWindow"]
    print(f"Tokenä½¿ç”¨: {metrics.tokens_used}")

# ============ ç¤ºä¾‹2: ç­–ç•¥åˆ‡æ¢ ============

def example_strategy_switching():
    """ç­–ç•¥åˆ‡æ¢ç¤ºä¾‹"""
    llm = MockLLM()

    manager = FlexibleMemoryManager(
        SlidingWindowStrategy(max_messages=10)
    )
    manager.register_strategy(ImportanceSamplingStrategy(max_messages=10))
    manager.register_strategy(SummarizationStrategy(llm, compress_threshold=20))

    # å¼€å§‹å¯¹è¯
    for i in range(15):
        manager.add("user", f"é—®é¢˜ {i}")
        manager.add("assistant", f"å›ç­” {i}")

    print("å½“å‰ç­–ç•¥:", manager.current_strategy.name)

    # å¯¹è¯å˜é•¿,åˆ‡æ¢åˆ°é‡è¦æ€§é‡‡æ ·
    manager.switch_strategy("ImportanceSampling")

    for i in range(20):
        manager.add("user", f"é—®é¢˜ {i}")

    # å¯¹è¯å¾ˆé•¿,åˆ‡æ¢åˆ°æ‘˜è¦å‹ç¼©
    manager.switch_strategy("Summarization")

    for i in range(50):
        manager.add("user", f"é—®é¢˜ {i}")

    # å¯¹æ¯”æ€§èƒ½
    print(manager.compare_strategies())

# ============ ç¤ºä¾‹3: è‡ªåŠ¨ä¼˜åŒ– ============

def example_auto_optimize():
    """è‡ªåŠ¨ä¼˜åŒ–ç¤ºä¾‹"""
    llm = MockLLM()

    manager = FlexibleMemoryManager(
        SlidingWindowStrategy(max_messages=10)
    )
    manager.register_strategy(ImportanceSamplingStrategy(max_messages=20))
    manager.register_strategy(SummarizationStrategy(llm))

    # å¯ç”¨è‡ªåŠ¨ä¼˜åŒ–
    manager.enable_auto_optimize()

    # æ¨¡æ‹Ÿé•¿å¯¹è¯
    for i in range(100):
        manager.add("user", f"é—®é¢˜ {i}")
        manager.add("assistant", f"å›ç­” {i}")

        # æ¯10è½®æ‰“å°å½“å‰ç­–ç•¥
        if i % 10 == 0:
            print(f"ç¬¬{i}è½® - å½“å‰ç­–ç•¥: {manager.current_strategy.name}")

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    print("=== ç¤ºä¾‹1: åŸºç¡€ä½¿ç”¨ ===")
    example_basic_usage()

    print("\n=== ç¤ºä¾‹2: ç­–ç•¥åˆ‡æ¢ ===")
    example_strategy_switching()

    print("\n=== ç¤ºä¾‹3: è‡ªåŠ¨ä¼˜åŒ– ===")
    example_auto_optimize()
```

---

### ğŸ“Š è§£ç­”2.4: æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

```python
def performance_benchmark():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    import time

    llm = MockLLM()

    # æµ‹è¯•æ•°æ®
    num_messages = 100

    results = {}

    # æµ‹è¯•æ¯ç§ç­–ç•¥
    for strategy_class, params in [
        (SlidingWindowStrategy, {"max_messages": 20}),
        (ImportanceSamplingStrategy, {"max_messages": 20}),
        (SummarizationStrategy, {"llm": llm, "compress_threshold": 30})
    ]:
        strategy = strategy_class(**params)

        start_time = time.time()

        # æ·»åŠ æ¶ˆæ¯
        for i in range(num_messages):
            msg = Message(
                role="user" if i % 2 == 0 else "assistant",
                content=f"è¿™æ˜¯ç¬¬ {i} æ¡æ¶ˆæ¯,åŒ…å«ä¸€äº›æµ‹è¯•å†…å®¹" * 5,
                timestamp=datetime.now(),
                metadata={}
            )
            strategy.add(msg)

        elapsed = time.time() - start_time

        metrics = strategy.get_metrics()

        results[strategy.name] = {
            "total_time": elapsed,
            "avg_time_per_msg": elapsed / num_messages * 1000,  # ms
            "final_messages": metrics.messages_stored,
            "tokens_used": metrics.tokens_used,
            "llm_calls": metrics.llm_calls
        }

    # æ‰“å°ç»“æœ
    print("\n" + "="*70)
    print(f"ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯• (å¤„ç† {num_messages} æ¡æ¶ˆæ¯)")
    print("="*70)

    for name, result in results.items():
        print(f"\nç­–ç•¥: {name}")
        print(f"  æ€»æ—¶é—´: {result['total_time']:.3f}s")
        print(f"  å•æ¡å»¶è¿Ÿ: {result['avg_time_per_msg']:.2f}ms")
        print(f"  æœ€ç»ˆæ¶ˆæ¯æ•°: {result['final_messages']}")
        print(f"  Tokenä½¿ç”¨: {result['tokens_used']}")
        print(f"  LLMè°ƒç”¨: {result['llm_calls']}")

    print("="*70)

# è¿è¡ŒåŸºå‡†æµ‹è¯•
if __name__ == "__main__":
    performance_benchmark()
```

**æµ‹è¯•è¾“å‡ºç¤ºä¾‹**:

```
======================================================================
ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯• (å¤„ç† 100 æ¡æ¶ˆæ¯)
======================================================================

ç­–ç•¥: SlidingWindow
  æ€»æ—¶é—´: 0.012s
  å•æ¡å»¶è¿Ÿ: 0.12ms
  æœ€ç»ˆæ¶ˆæ¯æ•°: 20
  Tokenä½¿ç”¨: 1250
  LLMè°ƒç”¨: 0

ç­–ç•¥: ImportanceSampling
  æ€»æ—¶é—´: 0.045s
  å•æ¡å»¶è¿Ÿ: 0.45ms
  æœ€ç»ˆæ¶ˆæ¯æ•°: 20
  Tokenä½¿ç”¨: 1300
  LLMè°ƒç”¨: 0

ç­–ç•¥: Summarization
  æ€»æ—¶é—´: 0.380s
  å•æ¡å»¶è¿Ÿ: 3.80ms
  æœ€ç»ˆæ¶ˆæ¯æ•°: 7 (1æ‘˜è¦ + 5æœ€è¿‘)
  Tokenä½¿ç”¨: 650
  LLMè°ƒç”¨: 2
======================================================================
```

---

### ğŸ’¡ è§£ç­”2.5: å…³é”®å®ç°äº®ç‚¹

```
âœ¨ è®¾è®¡äº®ç‚¹:

1ï¸âƒ£ ç»Ÿä¸€æ¥å£
   â†’ æ‰€æœ‰ç­–ç•¥ç»§æ‰¿è‡ª MemoryStrategy
   â†’ å¯æ— ç¼åˆ‡æ¢,æ•°æ®è¿ç§»

2ï¸âƒ£ æ€§èƒ½ç›‘æ§
   â†’ å®æ—¶è¿½è¸ª Token ä½¿ç”¨ã€å»¶è¿Ÿã€LLMè°ƒç”¨
   â†’ æ”¯æŒç­–ç•¥å¯¹æ¯”åˆ†æ

3ï¸âƒ£ è‡ªåŠ¨ä¼˜åŒ–
   â†’ æ ¹æ®å¯¹è¯é•¿åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥
   â†’ æ— éœ€æ‰‹åŠ¨å¹²é¢„

4ï¸âƒ£ å¯æ‰©å±•æ€§
   â†’ è½»æ¾æ·»åŠ æ–°ç­–ç•¥ (å¦‚æ··åˆç­–ç•¥ã€å›¾è®°å¿†ç­‰)
   â†’ æ’ä»¶åŒ–æ¶æ„
```

---

## ä¹ é¢˜3: RAGç³»ç»Ÿä¸ä¼ ç»Ÿæœç´¢å¯¹æ¯”

### ğŸ“ é¢˜ç›®

å¯¹æ¯”åˆ†æ **RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)** ç³»ç»Ÿä¸ **ä¼ ç»Ÿå…³é”®è¯æœç´¢** ç³»ç»Ÿçš„å·®å¼‚:

1. æŠ€æœ¯åŸç†å¯¹æ¯” (å‘é‡æ£€ç´¢ vs å…³é”®è¯åŒ¹é…)
2. åº”ç”¨åœºæ™¯å¯¹æ¯” (ä½•æ—¶ç”¨RAG,ä½•æ—¶ç”¨ä¼ ç»Ÿæœç´¢)
3. æ€§èƒ½ä¸æˆæœ¬å¯¹æ¯”
4. è®¾è®¡ä¸€ä¸ªæ··åˆç³»ç»Ÿ,ç»“åˆä¸¤è€…ä¼˜åŠ¿

è¦æ±‚:
- ç»™å‡ºè¯¦ç»†çš„æŠ€æœ¯å¯¹æ¯”è¡¨
- æä¾›çœŸå®æ¡ˆä¾‹åˆ†æ
- å®ç°ä¸€ä¸ªç®€å•çš„æ··åˆæ£€ç´¢åŸå‹

---

### âœ… è§£ç­”3.1: æŠ€æœ¯åŸç†æ·±åº¦å¯¹æ¯”

#### ğŸ” ä¼ ç»Ÿå…³é”®è¯æœç´¢ (Keyword Search)

**æ ¸å¿ƒæŠ€æœ¯**: BM25, TF-IDF

```python
# TF-IDF ç¤ºä¾‹
from sklearn.feature_extraction.text import TfidfVectorizer

documents = [
    "Python is a programming language",
    "Java is also a programming language",
    "Machine learning uses Python"
]

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(documents)

query = "Python programming"
query_vector = vectorizer.transform([query])

# è®¡ç®—ç›¸ä¼¼åº¦ (ä½™å¼¦ç›¸ä¼¼åº¦)
from sklearn.metrics.pairwise import cosine_similarity
scores = cosine_similarity(query_vector, tfidf_matrix)

# ç»“æœ: [0.61, 0.42, 0.35]
# æ–‡æ¡£1æœ€åŒ¹é… (åŒ…å« "Python" å’Œ "programming")
```

**å·¥ä½œåŸç†**:
```
1. åˆ†è¯: "Python programming" â†’ ["Python", "programming"]
2. æŸ¥æ‰¾: åœ¨å€’æ’ç´¢å¼•ä¸­æ‰¾åŒ…å«è¿™äº›è¯çš„æ–‡æ¡£
3. è¯„åˆ†: æ ¹æ®è¯é¢‘(TF)å’Œé€†æ–‡æ¡£é¢‘ç‡(IDF)è®¡ç®—åˆ†æ•°
4. æ’åº: è¿”å›å¾—åˆ†æœ€é«˜çš„æ–‡æ¡£
```

---

#### ğŸ§  RAG å‘é‡æ£€ç´¢ (Vector Retrieval)

**æ ¸å¿ƒæŠ€æœ¯**: Embedding + Semantic Search

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

documents = [
    "Python is a programming language",
    "Java is also a programming language",
    "Machine learning uses Python"
]

# å‘é‡åŒ–æ–‡æ¡£
doc_embeddings = model.encode(documents)

query = "coding with Python"  # æ³¨æ„: ä¸å®Œå…¨åŒ¹é…
query_embedding = model.encode(query)

# è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
from sklearn.metrics.pairwise import cosine_similarity
scores = cosine_similarity([query_embedding], doc_embeddings)

# ç»“æœ: [0.68, 0.45, 0.52]
# æ–‡æ¡£1æœ€åŒ¹é… (è¯­ä¹‰ä¸Šæœ€ç›¸å…³)
```

**å·¥ä½œåŸç†**:
```
1. Embedding: å°†æ–‡æœ¬è½¬ä¸ºè¯­ä¹‰å‘é‡ [0.12, -0.34, 0.56, ...]
2. å­˜å‚¨: å‘é‡å­˜å…¥å‘é‡æ•°æ®åº“ (æ”¯æŒé«˜æ•ˆANNæœç´¢)
3. æŸ¥è¯¢: å°†queryä¹Ÿè½¬ä¸ºå‘é‡
4. æ£€ç´¢: æ‰¾åˆ°å‘é‡ç©ºé—´ä¸­æœ€è¿‘çš„Kä¸ªå‘é‡
5. è¿”å›: å¯¹åº”çš„åŸå§‹æ–‡æ¡£
```

---

#### ğŸ“Š æ ¸å¿ƒå·®å¼‚å¯¹æ¯”è¡¨

| ç»´åº¦ | ä¼ ç»Ÿå…³é”®è¯æœç´¢ | RAGå‘é‡æ£€ç´¢ |
|------|---------------|------------|
| **åŒ¹é…æ–¹å¼** | ç²¾ç¡®è¯åŒ¹é… | è¯­ä¹‰ç›¸ä¼¼åº¦ |
| **æŸ¥è¯¢** | "Pythonç¼–ç¨‹" | "Pythonç¼–ç¨‹" |
| **èƒ½åŒ¹é…åˆ°** | "Pythonç¼–ç¨‹æ•™ç¨‹" âœ… | "Pythonç¼–ç¨‹æ•™ç¨‹" âœ…<br>"ä»£ç å¼€å‘æŒ‡å—" âœ…<br>"ç¨‹åºè®¾è®¡å…¥é—¨" âœ… |
| **ä¸èƒ½åŒ¹é…** | "ä»£ç å¼€å‘" âŒ<br>(æ²¡æœ‰"Python"å…³é”®è¯) | - |
| **ä¼˜åŠ¿åœºæ™¯** | â€¢ ç²¾ç¡®æŸ¥æ‰¾<br>â€¢ å·²çŸ¥å…³é”®è¯<br>â€¢ æŠ€æœ¯æ–‡æ¡£æ£€ç´¢ | â€¢ æ¨¡ç³ŠæŸ¥è¯¢<br>â€¢ æ¦‚å¿µæœç´¢<br>â€¢ è·¨è¯­è¨€æ£€ç´¢ |
| **åŠ£åŠ¿åœºæ™¯** | â€¢ åŒä¹‰è¯æŸ¥è¯¢<br>â€¢ æ¦‚å¿µç†è§£<br>â€¢ å¤šè¯­è¨€ | â€¢ ç²¾ç¡®åŒ¹é…<br>â€¢ ç½•è§ä¸“æœ‰åè¯<br>â€¢ æ•°å­—/ä»£ç  |
| **ç´¢å¼•å¤§å°** | å° (åªå­˜è¯å’Œä½ç½®) | å¤§ (å­˜768ç»´å‘é‡) |
| **ç´¢å¼•æ—¶é—´** | å¿« (msçº§) | æ…¢ (éœ€è¦æ¨¡å‹æ¨ç†) |
| **æŸ¥è¯¢é€Ÿåº¦** | æå¿« (Âµsçº§) | è¾ƒå¿« (msçº§,éœ€ANN) |
| **å­˜å‚¨æˆæœ¬** | ä½ | é«˜ (å‘é‡ç»´åº¦Ã—æ–‡æ¡£æ•°) |
| **è®¡ç®—æˆæœ¬** | ä½ | é«˜ (éœ€GPUåŠ é€Ÿ) |

---

### âœ… è§£ç­”3.2: çœŸå®æ¡ˆä¾‹åˆ†æ

#### æ¡ˆä¾‹1: æŠ€æœ¯æ–‡æ¡£æœç´¢ ğŸ”§

**åœºæ™¯**: ç”¨æˆ·åœ¨Pythonæ–‡æ¡£ä¸­æœç´¢"å¦‚ä½•è¯»å–æ–‡ä»¶"

**ä¼ ç»Ÿæœç´¢è¡¨ç°**:
```python
query = "read file"

# ç»“æœ (æŒ‰TF-IDFåˆ†æ•°):
# 1. open() function - reads files âœ… (åˆ†æ•°: 0.85)
# 2. File I/O operations âœ… (åˆ†æ•°: 0.78)
# 3. Reading configuration files âœ… (åˆ†æ•°: 0.72)
```
âœ… **å¾ˆå¥½**: ç²¾ç¡®åŒ¹é…"read"å’Œ"file"å…³é”®è¯

---

**RAGæ£€ç´¢è¡¨ç°**:
```python
query = "read file"

# ç»“æœ (æŒ‰è¯­ä¹‰ç›¸ä¼¼åº¦):
# 1. File I/O operations âœ… (ç›¸ä¼¼åº¦: 0.88)
# 2. open() function âœ… (ç›¸ä¼¼åº¦: 0.85)
# 3. Writing to disk ğŸ¤” (ç›¸ä¼¼åº¦: 0.71)
# 4. Data persistence âš ï¸ (ç›¸ä¼¼åº¦: 0.68)
```
âš ï¸ **è¿˜è¡Œ**: æ‰¾åˆ°äº†ç›¸å…³å†…å®¹,ä½†ä¹Ÿå¼•å…¥äº†"å†™æ–‡ä»¶"çš„å†…å®¹

**ç»“è®º**: æ­¤åœºæ™¯ä¸‹,ä¼ ç»Ÿæœç´¢æ›´ç²¾ç¡®

---

#### æ¡ˆä¾‹2: æ¦‚å¿µæ€§é—®é¢˜æŸ¥è¯¢ ğŸ§ 

**åœºæ™¯**: ç”¨æˆ·é—®"ä»€ä¹ˆæ˜¯è£…é¥°å™¨?"

**ä¼ ç»Ÿæœç´¢è¡¨ç°**:
```python
query = "what is decorator"

# ç»“æœ:
# 1. Decorator pattern (è®¾è®¡æ¨¡å¼) âš ï¸ (åˆ†æ•°: 0.82)
# 2. Python decorators âœ… (åˆ†æ•°: 0.78)
# 3. @decorator syntax âœ… (åˆ†æ•°: 0.65)
```
âš ï¸ **ä¸€èˆ¬**: æ··å…¥äº†è®¾è®¡æ¨¡å¼çš„å†…å®¹ (è™½ç„¶ä¹Ÿå«decorator)

---

**RAGæ£€ç´¢è¡¨ç°**:
```python
query = "what is decorator"

# ç»“æœ:
# 1. Python decorators - functions that modify functions âœ… (ç›¸ä¼¼åº¦: 0.92)
# 2. @decorator syntax and usage âœ… (ç›¸ä¼¼åº¦: 0.89)
# 3. Practical decorator examples âœ… (ç›¸ä¼¼åº¦: 0.85)
# 4. Decorator pattern in OOP ğŸ¤” (ç›¸ä¼¼åº¦: 0.72)
```
âœ… **å¾ˆå¥½**: ç†è§£äº†Pythonä¸Šä¸‹æ–‡,ä¼˜å…ˆè¿”å›Pythonè£…é¥°å™¨

**ç»“è®º**: æ­¤åœºæ™¯ä¸‹,RAGè¯­ä¹‰ç†è§£æ›´å¼º

---

#### æ¡ˆä¾‹3: å¤šè¯­è¨€/åŒä¹‰è¯æŸ¥è¯¢ ğŸŒ

**åœºæ™¯**: ç”¨æˆ·ç”¨ä¸­æ–‡é—®"æœºå™¨å­¦ä¹ ",ä½†æ–‡æ¡£æ˜¯è‹±æ–‡

**ä¼ ç»Ÿæœç´¢è¡¨ç°**:
```python
query = "æœºå™¨å­¦ä¹ "

# ç»“æœ:
# æ²¡æœ‰åŒ¹é… âŒ (è‹±æ–‡æ–‡æ¡£ä¸­æ²¡æœ‰ä¸­æ–‡)
```
âŒ **å¤±è´¥**: æ— æ³•å¤„ç†è·¨è¯­è¨€

---

**RAGæ£€ç´¢è¡¨ç°** (ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹):
```python
query = "æœºå™¨å­¦ä¹ "  # Machine Learning

# ç»“æœ:
# 1. Introduction to Machine Learning âœ… (ç›¸ä¼¼åº¦: 0.91)
# 2. ML algorithms overview âœ… (ç›¸ä¼¼åº¦: 0.87)
# 3. Supervised learning basics âœ… (ç›¸ä¼¼åº¦: 0.83)
```
âœ… **å¾ˆå¥½**: è·¨è¯­è¨€è¯­ä¹‰åŒ¹é…

**ç»“è®º**: RAGåœ¨å¤šè¯­è¨€åœºæ™¯ä¸‹å®Œèƒœ

---

### âœ… è§£ç­”3.3: æ€§èƒ½ä¸æˆæœ¬å¯¹æ¯”

#### ğŸ“Š çœŸå®æ€§èƒ½æµ‹è¯•

**æµ‹è¯•ç¯å¢ƒ**:
- æ–‡æ¡£åº“: 10,000ç¯‡æŠ€æœ¯æ–‡æ¡£
- æŸ¥è¯¢é‡: 1000æ¬¡éšæœºæŸ¥è¯¢
- ç¡¬ä»¶: M1 Mac / 16GB RAM

| æŒ‡æ ‡ | ä¼ ç»ŸBM25 | RAG (FAISS) | RAG (Chroma) |
|------|----------|------------|--------------|
| **ç´¢å¼•æ—¶é—´** | 2åˆ†é’Ÿ | 45åˆ†é’Ÿ | 60åˆ†é’Ÿ |
| **ç´¢å¼•å¤§å°** | 50MB | 3.2GB | 3.8GB |
| **å•æ¬¡æŸ¥è¯¢å»¶è¿Ÿ** | 8ms | 35ms | 50ms |
| **Top-5å‡†ç¡®ç‡** | 72% | 88% | 86% |
| **å†…å­˜å ç”¨** | 150MB | 2.5GB | 3.1GB |
| **GPUéœ€æ±‚** | æ—  | æœ‰ (å¯é€‰) | æœ‰ (å¯é€‰) |

---

#### ğŸ’° æˆæœ¬åˆ†æ

**ä¼ ç»Ÿæœç´¢æˆæœ¬**:
```
ç´¢å¼•æˆæœ¬:
  â€¢ CPUè®¡ç®—: 2åˆ†é’Ÿ â‰ˆ $0.001
  â€¢ å­˜å‚¨: 50MB Ã— $0.02/GB/æœˆ = $0.001/æœˆ

æŸ¥è¯¢æˆæœ¬ (100ä¸‡æ¬¡/æœˆ):
  â€¢ CPU: 8ms Ã— 100ä¸‡ = 2.2å°æ—¶ â‰ˆ $0.10
  â€¢ æ€»æˆæœ¬: ~$0.10/æœˆ
```

**RAGæˆæœ¬**:
```
ç´¢å¼•æˆæœ¬:
  â€¢ Embeddingè°ƒç”¨: 10,000æ–‡æ¡£ Ã— $0.0001/1K tokens â‰ˆ $50 (ä¸€æ¬¡æ€§)
  â€¢ æˆ–è‡ªå»ºæ¨¡å‹: GPUæœåŠ¡å™¨ 45åˆ†é’Ÿ â‰ˆ $1
  â€¢ å­˜å‚¨: 3.2GB Ã— $0.02/GB/æœˆ = $0.064/æœˆ

æŸ¥è¯¢æˆæœ¬ (100ä¸‡æ¬¡/æœˆ):
  â€¢ EmbeddingæŸ¥è¯¢: 100ä¸‡ Ã— $0.0001 = $100
  â€¢ æˆ–è‡ªå»º: GPUæœåŠ¡å™¨ 10å°æ—¶ â‰ˆ $20
  â€¢ æ€»æˆæœ¬: ~$20-100/æœˆ
```

**æˆæœ¬å¯¹æ¯”**: RAGæˆæœ¬æ˜¯ä¼ ç»Ÿæœç´¢çš„ **20-100å€**

---

### âœ… è§£ç­”3.4: æ··åˆç³»ç»Ÿè®¾è®¡ä¸å®ç°

#### ğŸ¯ è®¾è®¡æ€è·¯

**æ ¸å¿ƒç†å¿µ**: ç»“åˆä¸¤è€…ä¼˜åŠ¿,æ ¹æ®æŸ¥è¯¢ç±»å‹è‡ªåŠ¨é€‰æ‹©

```
æŸ¥è¯¢åˆ†æ
    â†“
æ˜¯ç²¾ç¡®æŸ¥è¯¢? (åŒ…å«å¼•å·ã€ä¸“æœ‰åè¯ã€ä»£ç )
    â†™         â†˜
  YES          NO
    â†“           â†“
 BM25æ£€ç´¢    å‘é‡æ£€ç´¢
    â†“           â†“
ç»“æœåˆå¹¶ (åŠ æƒèåˆ)
    â†“
é‡æ’åº (Re-ranking)
    â†“
è¿”å›Top-K
```

---

#### ğŸ’» å®Œæ•´å®ç°

```python
from typing import List, Dict, Tuple
from dataclasses import dataclass
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
import numpy as np
import re

@dataclass
class SearchResult:
    """æœç´¢ç»“æœ"""
    doc_id: int
    content: str
    score: float
    source: str  # "bm25" | "vector" | "hybrid"
    metadata: Dict = None

class HybridRetriever:
    """æ··åˆæ£€ç´¢ç³»ç»Ÿ"""

    def __init__(
        self,
        embedding_model_name: str = 'all-MiniLM-L6-v2',
        bm25_weight: float = 0.3,
        vector_weight: float = 0.7
    ):
        """
        Args:
            embedding_model_name: å‘é‡æ¨¡å‹åç§°
            bm25_weight: BM25æ£€ç´¢æƒé‡
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
        """
        self.embedding_model = SentenceTransformer(embedding_model_name)
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight

        self.documents: List[str] = []
        self.doc_embeddings: np.ndarray = None
        self.bm25: BM25Okapi = None
        self.tokenized_docs: List[List[str]] = []

    def index_documents(self, documents: List[str]):
        """
        ç´¢å¼•æ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
        """
        print(f"ğŸ“Š å¼€å§‹ç´¢å¼• {len(documents)} ç¯‡æ–‡æ¡£...")

        self.documents = documents

        # 1. æ„å»ºBM25ç´¢å¼•
        print("  â†’ æ„å»ºBM25ç´¢å¼•...")
        self.tokenized_docs = [doc.lower().split() for doc in documents]
        self.bm25 = BM25Okapi(self.tokenized_docs)

        # 2. æ„å»ºå‘é‡ç´¢å¼•
        print("  â†’ ç”Ÿæˆå‘é‡...")
        self.doc_embeddings = self.embedding_model.encode(
            documents,
            show_progress_bar=True,
            convert_to_numpy=True
        )

        print("âœ… ç´¢å¼•å®Œæˆ!")

    def _is_exact_query(self, query: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºç²¾ç¡®æŸ¥è¯¢

        ç²¾ç¡®æŸ¥è¯¢ç‰¹å¾:
        - åŒ…å«å¼•å·
        - åŒ…å«ä»£ç  (```)
        - å…¨æ˜¯å¤§å†™å­—æ¯ (å¯èƒ½æ˜¯ç¼©å†™)
        - åŒ…å«ç‰¹æ®Šç¬¦å· (@, #, $)
        """
        patterns = [
            r'"[^"]+"',  # å¼•å·
            r'```',      # ä»£ç å—
            r'\b[A-Z]{2,}\b',  # å¤§å†™ç¼©å†™
            r'[@#$]'     # ç‰¹æ®Šç¬¦å·
        ]

        return any(re.search(pattern, query) for pattern in patterns)

    def _bm25_search(self, query: str, top_k: int = 10) -> List[SearchResult]:
        """BM25æ£€ç´¢"""
        tokenized_query = query.lower().split()
        scores = self.bm25.get_scores(tokenized_query)

        # è·å–Top-K
        top_indices = np.argsort(scores)[::-1][:top_k]

        results = []
        for idx in top_indices:
            if scores[idx] > 0:  # è¿‡æ»¤é›¶åˆ†ç»“æœ
                results.append(SearchResult(
                    doc_id=int(idx),
                    content=self.documents[idx],
                    score=float(scores[idx]),
                    source="bm25"
                ))

        return results

    def _vector_search(self, query: str, top_k: int = 10) -> List[SearchResult]:
        """å‘é‡æ£€ç´¢"""
        query_embedding = self.embedding_model.encode([query])[0]

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = np.dot(self.doc_embeddings, query_embedding) / (
            np.linalg.norm(self.doc_embeddings, axis=1) * np.linalg.norm(query_embedding)
        )

        # è·å–Top-K
        top_indices = np.argsort(similarities)[::-1][:top_k]

        results = []
        for idx in top_indices:
            results.append(SearchResult(
                doc_id=int(idx),
                content=self.documents[idx],
                score=float(similarities[idx]),
                source="vector"
            ))

        return results

    def _normalize_scores(self, results: List[SearchResult]) -> List[SearchResult]:
        """å½’ä¸€åŒ–åˆ†æ•°åˆ°[0, 1]"""
        if not results:
            return results

        scores = [r.score for r in results]
        min_score = min(scores)
        max_score = max(scores)

        if max_score == min_score:
            for r in results:
                r.score = 0.5
            return results

        for r in results:
            r.score = (r.score - min_score) / (max_score - min_score)

        return results

    def _merge_results(
        self,
        bm25_results: List[SearchResult],
        vector_results: List[SearchResult]
    ) -> List[SearchResult]:
        """
        åˆå¹¶ä¸¤ç§æ£€ç´¢ç»“æœ

        ä½¿ç”¨åŠ æƒå¹³å‡:
        final_score = bm25_weight Ã— bm25_score + vector_weight Ã— vector_score
        """
        # å½’ä¸€åŒ–åˆ†æ•°
        bm25_results = self._normalize_scores(bm25_results)
        vector_results = self._normalize_scores(vector_results)

        # æ„å»ºåˆ†æ•°å­—å…¸
        doc_scores: Dict[int, Dict] = {}

        # æ·»åŠ BM25ç»“æœ
        for r in bm25_results:
            doc_scores[r.doc_id] = {
                "bm25": r.score,
                "vector": 0.0,
                "content": r.content
            }

        # æ·»åŠ å‘é‡ç»“æœ
        for r in vector_results:
            if r.doc_id in doc_scores:
                doc_scores[r.doc_id]["vector"] = r.score
            else:
                doc_scores[r.doc_id] = {
                    "bm25": 0.0,
                    "vector": r.score,
                    "content": r.content
                }

        # è®¡ç®—æ··åˆåˆ†æ•°
        merged_results = []
        for doc_id, scores in doc_scores.items():
            final_score = (
                self.bm25_weight * scores["bm25"] +
                self.vector_weight * scores["vector"]
            )

            merged_results.append(SearchResult(
                doc_id=doc_id,
                content=scores["content"],
                score=final_score,
                source="hybrid",
                metadata={
                    "bm25_score": scores["bm25"],
                    "vector_score": scores["vector"]
                }
            ))

        # æŒ‰åˆ†æ•°æ’åº
        merged_results.sort(key=lambda x: x.score, reverse=True)

        return merged_results

    def search(
        self,
        query: str,
        top_k: int = 5,
        mode: str = "auto"
    ) -> List[SearchResult]:
        """
        æ··åˆæ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            mode: æ£€ç´¢æ¨¡å¼ "auto" | "bm25" | "vector" | "hybrid"

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
        if mode == "auto":
            if self._is_exact_query(query):
                mode = "bm25"
                print(f"ğŸ” æ£€æµ‹åˆ°ç²¾ç¡®æŸ¥è¯¢,ä½¿ç”¨BM25æ£€ç´¢")
            else:
                mode = "hybrid"
                print(f"ğŸ§  ä½¿ç”¨æ··åˆæ£€ç´¢")

        # æ‰§è¡Œæ£€ç´¢
        if mode == "bm25":
            results = self._bm25_search(query, top_k * 2)
            return results[:top_k]

        elif mode == "vector":
            results = self._vector_search(query, top_k * 2)
            return results[:top_k]

        else:  # hybrid
            bm25_results = self._bm25_search(query, top_k * 2)
            vector_results = self._vector_search(query, top_k * 2)
            merged = self._merge_results(bm25_results, vector_results)
            return merged[:top_k]

    def explain_results(self, results: List[SearchResult]):
        """è§£é‡Šæœç´¢ç»“æœ"""
        print("\n" + "="*70)
        print("ğŸ“‹ æœç´¢ç»“æœè¯¦æƒ…")
        print("="*70)

        for i, result in enumerate(results, 1):
            print(f"\n{i}. {result.content[:100]}...")
            print(f"   æ€»åˆ†: {result.score:.3f} | æ¥æº: {result.source}")

            if result.metadata:
                print(f"   BM25åˆ†æ•°: {result.metadata.get('bm25_score', 0):.3f} | "
                      f"å‘é‡åˆ†æ•°: {result.metadata.get('vector_score', 0):.3f}")

        print("="*70)
```

---

#### ğŸ§ª æµ‹è¯•ç”¨ä¾‹

```python
# æµ‹è¯•æ•°æ®
documents = [
    "Python is a high-level programming language created by Guido van Rossum",
    "Java is an object-oriented programming language developed by Sun Microsystems",
    "Machine learning is a subset of artificial intelligence",
    "Deep learning uses neural networks with multiple layers",
    "Natural language processing (NLP) deals with text and speech",
    "Computer vision enables machines to interpret visual information",
    "def hello_world(): print('Hello, World!')  # Python function example",
    "public class HelloWorld { public static void main(String[] args) { } }",
    "The @decorator syntax in Python allows function modification",
    "Lambda functions are anonymous functions in Python",
]

# åˆ›å»ºæ··åˆæ£€ç´¢å™¨
retriever = HybridRetriever(
    bm25_weight=0.3,
    vector_weight=0.7
)

# ç´¢å¼•æ–‡æ¡£
retriever.index_documents(documents)

# ============ æµ‹è¯•1: æ¦‚å¿µæŸ¥è¯¢ ============
print("\nã€æµ‹è¯•1ã€‘æ¦‚å¿µæŸ¥è¯¢: 'äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯'")
results = retriever.search("äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯", top_k=3, mode="auto")
retriever.explain_results(results)

# ============ æµ‹è¯•2: ç²¾ç¡®ä»£ç æŸ¥è¯¢ ============
print("\nã€æµ‹è¯•2ã€‘ç²¾ç¡®æŸ¥è¯¢: '```def hello_world```'")
results = retriever.search("```def hello_world```", top_k=3, mode="auto")
retriever.explain_results(results)

# ============ æµ‹è¯•3: ä¸“æœ‰åè¯æŸ¥è¯¢ ============
print("\nã€æµ‹è¯•3ã€‘ä¸“æœ‰åè¯: 'NLP'")
results = retriever.search("NLP", top_k=3, mode="auto")
retriever.explain_results(results)

# ============ æµ‹è¯•4: å¯¹æ¯”ä¸‰ç§æ¨¡å¼ ============
print("\nã€æµ‹è¯•4ã€‘æ¨¡å¼å¯¹æ¯”: 'Python function'")

for mode in ["bm25", "vector", "hybrid"]:
    print(f"\n--- {mode.upper()} æ¨¡å¼ ---")
    results = retriever.search("Python function", top_k=3, mode=mode)
    for i, r in enumerate(results, 1):
        print(f"{i}. [{r.score:.3f}] {r.content[:60]}...")
```

---

**è¾“å‡ºç¤ºä¾‹**:

```
ã€æµ‹è¯•1ã€‘æ¦‚å¿µæŸ¥è¯¢: 'äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯'
ğŸ§  ä½¿ç”¨æ··åˆæ£€ç´¢

======================================================================
ğŸ“‹ æœç´¢ç»“æœè¯¦æƒ…
======================================================================

1. Machine learning is a subset of artificial intelligence...
   æ€»åˆ†: 0.856 | æ¥æº: hybrid
   BM25åˆ†æ•°: 0.000 | å‘é‡åˆ†æ•°: 0.918

2. Deep learning uses neural networks with multiple layers...
   æ€»åˆ†: 0.721 | æ¥æº: hybrid
   BM25åˆ†æ•°: 0.000 | å‘é‡åˆ†æ•°: 0.882

3. Natural language processing (NLP) deals with text and speech...
   æ€»åˆ†: 0.685 | æ¥æº: hybrid
   BM25åˆ†æ•°: 0.000 | å‘é‡åˆ†æ•°: 0.845
======================================================================

ã€æµ‹è¯•2ã€‘ç²¾ç¡®æŸ¥è¯¢: '```def hello_world```'
ğŸ” æ£€æµ‹åˆ°ç²¾ç¡®æŸ¥è¯¢,ä½¿ç”¨BM25æ£€ç´¢

======================================================================
ğŸ“‹ æœç´¢ç»“æœè¯¦æƒ…
======================================================================

1. def hello_world(): print('Hello, World!')  # Python function...
   æ€»åˆ†: 2.145 | æ¥æº: bm25

2. The @decorator syntax in Python allows function modification...
   æ€»åˆ†: 0.523 | æ¥æº: bm25
======================================================================
```

---

### ğŸ’¡ è§£ç­”3.5: é€‰æ‹©æŒ‡å—

```
ğŸ¯ ä½•æ—¶ä½¿ç”¨ä½•ç§æ£€ç´¢?

âœ… ä½¿ç”¨ä¼ ç»ŸBM25æœç´¢:
   â†’ ç²¾ç¡®æŸ¥æ‰¾ (ä»£ç ã€æ—¥å¿—ã€ID)
   â†’ å·²çŸ¥å…³é”®è¯
   â†’ ä½æˆæœ¬é«˜æ€§èƒ½è¦æ±‚
   â†’ ä¸“æœ‰åè¯ã€ç¼©å†™

âœ… ä½¿ç”¨RAGå‘é‡æ£€ç´¢:
   â†’ æ¦‚å¿µç†è§£ ("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ?")
   â†’ åŒä¹‰è¯ã€å¤šè¯­è¨€
   â†’ é—®ç­”ç³»ç»Ÿ
   â†’ ç›¸ä¼¼å†…å®¹æ¨è

âœ… ä½¿ç”¨æ··åˆæ£€ç´¢:
   â†’ é€šç”¨æœç´¢å¼•æ“
   â†’ ä¸ç¡®å®šæŸ¥è¯¢ç±»å‹
   â†’ éœ€è¦å¹³è¡¡ç²¾ç¡®æ€§å’Œå¬å›ç‡
   â†’ ç”Ÿäº§ç¯å¢ƒ (å…¼é¡¾å¤šç§åœºæ™¯)
```

---

## ä¹ é¢˜4: æ„å»ºæ··åˆæ£€ç´¢ç³»ç»Ÿ (ç»­)

### âœ… è§£ç­”4.1: è¿›é˜¶ä¼˜åŒ– - é‡æ’åº (Re-ranking)

æ··åˆæ£€ç´¢å·²ç»å¾ˆå¥½äº†,ä½†è¿˜å¯ä»¥é€šè¿‡**é‡æ’åº**è¿›ä¸€æ­¥æå‡ç²¾åº¦ã€‚

```python
from sentence_transformers import CrossEncoder

class AdvancedHybridRetriever(HybridRetriever):
    """å¸¦é‡æ’åºçš„é«˜çº§æ··åˆæ£€ç´¢å™¨"""

    def __init__(
        self,
        embedding_model_name: str = 'all-MiniLM-L6-v2',
        reranker_model_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2',
        bm25_weight: float = 0.3,
        vector_weight: float = 0.7,
        use_reranker: bool = True
    ):
        super().__init__(embedding_model_name, bm25_weight, vector_weight)

        self.use_reranker = use_reranker
        if use_reranker:
            print("ğŸ“Š åŠ è½½é‡æ’åºæ¨¡å‹...")
            self.reranker = CrossEncoder(reranker_model_name)

    def search(
        self,
        query: str,
        top_k: int = 5,
        mode: str = "auto",
        rerank: bool = True
    ) -> List[SearchResult]:
        """
        é«˜çº§æ··åˆæ£€ç´¢ + é‡æ’åº

        æµç¨‹:
        1. åˆæ­¥æ£€ç´¢ (BM25 + å‘é‡) â†’ è¿”å› Top-20
        2. é‡æ’åº (Cross-Encoder) â†’ ç²¾ç¡®æ’åº
        3. è¿”å› Top-K
        """
        # åˆæ­¥æ£€ç´¢ (å¤šå¬å›ä¸€äº›å€™é€‰)
        initial_top_k = top_k * 4
        candidates = super().search(query, top_k=initial_top_k, mode=mode)

        # é‡æ’åº
        if rerank and self.use_reranker and len(candidates) > 0:
            print(f"ğŸ”„ å¯¹ {len(candidates)} ä¸ªå€™é€‰ç»“æœè¿›è¡Œé‡æ’åº...")

            # å‡†å¤‡ (query, document) å¯¹
            pairs = [[query, c.content] for c in candidates]

            # è®¡ç®—ç²¾ç¡®ç›¸å…³æ€§åˆ†æ•°
            rerank_scores = self.reranker.predict(pairs)

            # æ›´æ–°åˆ†æ•°
            for i, candidate in enumerate(candidates):
                candidate.metadata = candidate.metadata or {}
                candidate.metadata["original_score"] = candidate.score
                candidate.score = float(rerank_scores[i])
                candidate.source = "reranked"

            # é‡æ–°æ’åº
            candidates.sort(key=lambda x: x.score, reverse=True)

        return candidates[:top_k]
```

---

**é‡æ’åºæ•ˆæœå¯¹æ¯”**:

```python
# æµ‹è¯•é‡æ’åº
retriever_with_rerank = AdvancedHybridRetriever(use_reranker=True)
retriever_without_rerank = AdvancedHybridRetriever(use_reranker=False)

retriever_with_rerank.index_documents(documents)
retriever_without_rerank.index_documents(documents)

query = "How to write a Python function?"

print("\nã€æ— é‡æ’åºã€‘")
results1 = retriever_without_rerank.search(query, top_k=3, rerank=False)
for i, r in enumerate(results1, 1):
    print(f"{i}. [{r.score:.3f}] {r.content[:60]}...")

print("\nã€æœ‰é‡æ’åºã€‘")
results2 = retriever_with_rerank.search(query, top_k=3, rerank=True)
for i, r in enumerate(results2, 1):
    original = r.metadata.get("original_score", 0)
    print(f"{i}. [{r.score:.3f}â†{original:.3f}] {r.content[:60]}...")
```

**è¾“å‡ºç¤ºä¾‹**:

```
ã€æ— é‡æ’åºã€‘
1. [0.745] def hello_world(): print('Hello, World!')...
2. [0.682] Lambda functions are anonymous functions in Python...
3. [0.621] The @decorator syntax in Python...

ã€æœ‰é‡æ’åºã€‘
ğŸ”„ å¯¹ 12 ä¸ªå€™é€‰ç»“æœè¿›è¡Œé‡æ’åº...
1. [4.512â†0.745] def hello_world(): print('Hello, World!')...  # åˆ†æ•°æå‡!
2. [3.821â†0.621] The @decorator syntax in Python...  # æ’åä¸Šå‡!
3. [3.102â†0.682] Lambda functions are anonymous functions...
```

**é‡æ’åºä¼˜åŠ¿**: åˆæ­¥æ£€ç´¢å¯èƒ½ä¸å¤Ÿç²¾ç¡®,é‡æ’åºä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ (Cross-Encoder) å¯¹å€™é€‰ç»“æœç²¾ç»†æ‰“åˆ†,å¤§å¹…æå‡Top-5çš„å‡†ç¡®ç‡ã€‚

---

### âœ… è§£ç­”4.2: æ€§èƒ½ä¼˜åŒ– - ç¼“å­˜æœºåˆ¶

```python
from functools import lru_cache
import hashlib

class CachedHybridRetriever(AdvancedHybridRetriever):
    """å¸¦ç¼“å­˜çš„æ··åˆæ£€ç´¢å™¨"""

    def __init__(self, *args, cache_size=100, **kwargs):
        super().__init__(*args, **kwargs)
        self.cache_size = cache_size
        self._cache = {}

    def _get_cache_key(self, query: str, top_k: int, mode: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{query}_{top_k}_{mode}"
        return hashlib.md5(key_str.encode()).hexdigest()

    def search(
        self,
        query: str,
        top_k: int = 5,
        mode: str = "auto",
        rerank: bool = True,
        use_cache: bool = True
    ) -> List[SearchResult]:
        """å¸¦ç¼“å­˜çš„æœç´¢"""
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cache_key = self._get_cache_key(query, top_k, mode)

            if cache_key in self._cache:
                print("ğŸ’¾ å‘½ä¸­ç¼“å­˜!")
                return self._cache[cache_key]

        # æ‰§è¡Œæ£€ç´¢
        results = super().search(query, top_k, mode, rerank)

        # å­˜å…¥ç¼“å­˜
        if use_cache:
            # LRUæ·˜æ±°
            if len(self._cache) >= self.cache_size:
                # åˆ é™¤æœ€æ—©çš„
                self._cache.pop(next(iter(self._cache)))

            self._cache[cache_key] = results

        return results
```

---

### ğŸ“Š è§£ç­”4.3: å®Œæ•´åŸºå‡†æµ‹è¯•

```python
import time

def benchmark_retrievers():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    # å‡†å¤‡å¤§é‡æµ‹è¯•æ•°æ®
    documents = [
        f"Document {i}: This is a test document about topic {i % 10}"
        for i in range(1000)
    ] + [
        "Python programming language fundamentals",
        "Machine learning algorithms and applications",
        "Deep neural networks for computer vision",
        "Natural language processing with transformers"
    ]

    queries = [
        "Python programming",
        "machine learning",
        "neural networks",
        "NLP transformers"
    ]

    # æµ‹è¯•ä¸‰ç§é…ç½®
    configs = [
        ("BM25 Only", {"bm25_weight": 1.0, "vector_weight": 0.0, "use_reranker": False}),
        ("Vector Only", {"bm25_weight": 0.0, "vector_weight": 1.0, "use_reranker": False}),
        ("Hybrid + Rerank", {"bm25_weight": 0.3, "vector_weight": 0.7, "use_reranker": True})
    ]

    results_table = []

    for name, config in configs:
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•é…ç½®: {name}")
        print('='*60)

        retriever = AdvancedHybridRetriever(**config)
        retriever.index_documents(documents)

        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        total_time = 0
        for query in queries:
            start = time.time()
            results = retriever.search(query, top_k=5, rerank=config["use_reranker"])
            elapsed = time.time() - start
            total_time += elapsed

        avg_time = total_time / len(queries) * 1000  # ms

        results_table.append({
            "é…ç½®": name,
            "å¹³å‡å»¶è¿Ÿ": f"{avg_time:.1f}ms",
            "ç´¢å¼•å¤§å°": "ä¼°ç®—ä¸­",
            "å‡†ç¡®ç‡": "éœ€äººå·¥è¯„ä¼°"
        })

    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)

    for result in results_table:
        print(f"\n{result['é…ç½®']}:")
        for key, value in result.items():
            if key != "é…ç½®":
                print(f"  {key}: {value}")

# è¿è¡ŒåŸºå‡†æµ‹è¯•
benchmark_retrievers()
```

---

### ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

```
ğŸ“Œ æ··åˆæ£€ç´¢æœ€ä½³å®è·µ:

1ï¸âƒ£ åˆç­›é˜¶æ®µ (Recall)
   â†’ BM25: ç²¾ç¡®å…³é”®è¯åŒ¹é…
   â†’ å‘é‡: è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…
   â†’ å¬å› Top-20~50 å€™é€‰

2ï¸âƒ£ èåˆé˜¶æ®µ (Merge)
   â†’ å½’ä¸€åŒ–åˆ†æ•°åˆ° [0, 1]
   â†’ åŠ æƒå¹³å‡: 0.3Ã—BM25 + 0.7Ã—å‘é‡
   â†’ å»é‡ (åŒä¸€æ–‡æ¡£å¯èƒ½è¢«ä¸¤æ¬¡æ£€ç´¢åˆ°)

3ï¸âƒ£ é‡æ’åºé˜¶æ®µ (Rerank)
   â†’ ä½¿ç”¨ Cross-Encoder ç²¾ç¡®æ‰“åˆ†
   â†’ åªå¯¹å€™é€‰ç»“æœæ’åº (è€Œä¸æ˜¯å…¨é‡)
   â†’ æˆæœ¬é«˜,ä½†Top-Kç²¾åº¦æ˜¾è‘—æå‡

4ï¸âƒ£ ä¼˜åŒ–ç­–ç•¥
   â†’ ç¼“å­˜çƒ­é—¨æŸ¥è¯¢
   â†’ å¼‚æ­¥ç´¢å¼•æ›´æ–°
   â†’ GPUåŠ é€ŸEmbeddingè®¡ç®—
```

---

## ä¹ é¢˜5: é›†æˆMemoryå’ŒRAGçš„å®Œæ•´Agent

### ğŸ“ é¢˜ç›®

æ„å»ºä¸€ä¸ª**æ™ºèƒ½çŸ¥è¯†åŠ©æ‰‹Agent**,è¦æ±‚:

1. **Memoryç³»ç»Ÿ**:
   - çŸ­æœŸè®°å¿†: ä¿å­˜å¯¹è¯å†å² (æ»‘åŠ¨çª—å£)
   - é•¿æœŸè®°å¿†: ä¿å­˜ç”¨æˆ·åå¥½å’Œé‡è¦ä¿¡æ¯

2. **RAGç³»ç»Ÿ**:
   - ä»å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯
   - æ”¯æŒæ·»åŠ æ–°æ–‡æ¡£åˆ°çŸ¥è¯†åº“

3. **å·¥å…·é›†æˆ**:
   - MemoryTool: ä¿å­˜å’Œæ£€ç´¢è®°å¿†
   - RAGTool: æœç´¢çŸ¥è¯†åº“
   - å…¶ä»–è¾…åŠ©å·¥å…· (å¯é€‰)

4. **æ™ºèƒ½å†³ç­–**:
   - è‡ªåŠ¨åˆ¤æ–­ä½•æ—¶ä½¿ç”¨è®°å¿†ã€ä½•æ—¶ä½¿ç”¨RAG
   - ç»“åˆä¸Šä¸‹æ–‡ç”Ÿæˆé«˜è´¨é‡å›ç­”

è¦æ±‚:
- ä½¿ç”¨ ReActAgent æ¡†æ¶
- å®Œæ•´çš„å·¥å…·å®šä¹‰å’Œæ³¨å†Œ
- ç¼–å†™æµ‹è¯•å¯¹è¯åœºæ™¯

---

### âœ… è§£ç­”5.1: å®Œæ•´ç³»ç»Ÿæ¶æ„

```python
from typing import List, Dict, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json

# ============ 1. æ•°æ®ç»“æ„ ============

@dataclass
class ConversationMessage:
    """å¯¹è¯æ¶ˆæ¯"""
    role: str
    content: str
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict = field(default_factory=dict)

@dataclass
class UserProfile:
    """ç”¨æˆ·ç”»åƒ"""
    user_id: str
    preferences: Dict = field(default_factory=dict)
    important_facts: List[str] = field(default_factory=list)
    interaction_count: int = 0

    def to_dict(self):
        return {
            "user_id": self.user_id,
            "preferences": self.preferences,
            "important_facts": self.important_facts,
            "interaction_count": self.interaction_count
        }

# ============ 2. Memory ç³»ç»Ÿ ============

class ConversationMemory:
    """å¯¹è¯è®°å¿†ç³»ç»Ÿ"""

    def __init__(self, max_short_term=20, user_id="default"):
        self.user_id = user_id
        self.short_term: List[ConversationMessage] = []
        self.max_short_term = max_short_term
        self.user_profile = UserProfile(user_id=user_id)

    def add_message(self, role: str, content: str, metadata: Dict = None):
        """æ·»åŠ æ¶ˆæ¯åˆ°çŸ­æœŸè®°å¿†"""
        msg = ConversationMessage(
            role=role,
            content=content,
            metadata=metadata or {}
        )

        self.short_term.append(msg)

        # ç»´æŒçª—å£å¤§å°
        if len(self.short_term) > self.max_short_term:
            self.short_term.pop(0)

        # æ›´æ–°äº¤äº’è®¡æ•°
        if role == "user":
            self.user_profile.interaction_count += 1

    def get_recent_context(self, limit: int = 10) -> List[ConversationMessage]:
        """è·å–æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
        return self.short_term[-limit:]

    def save_important_fact(self, fact: str):
        """ä¿å­˜é‡è¦äº‹å®åˆ°é•¿æœŸè®°å¿†"""
        if fact not in self.user_profile.important_facts:
            self.user_profile.important_facts.append(fact)
            print(f"ğŸ’¾ å·²ä¿å­˜åˆ°é•¿æœŸè®°å¿†: {fact[:50]}...")

    def recall_facts(self, query: str = None) -> List[str]:
        """å›å¿†é‡è¦äº‹å®"""
        # ç®€åŒ–ç‰ˆ: è¿”å›æ‰€æœ‰äº‹å® (å®é™…åº”è¯¥åšç›¸ä¼¼åº¦æ£€ç´¢)
        return self.user_profile.important_facts

    def update_preference(self, key: str, value: any):
        """æ›´æ–°ç”¨æˆ·åå¥½"""
        self.user_profile.preferences[key] = value
        print(f"âœï¸ å·²æ›´æ–°åå¥½: {key} = {value}")

    def get_profile_summary(self) -> str:
        """è·å–ç”¨æˆ·ç”»åƒæ‘˜è¦"""
        profile = self.user_profile
        summary = f"ç”¨æˆ·ID: {profile.user_id}\n"
        summary += f"äº¤äº’æ¬¡æ•°: {profile.interaction_count}\n"

        if profile.preferences:
            summary += "åå¥½:\n"
            for k, v in profile.preferences.items():
                summary += f"  - {k}: {v}\n"

        if profile.important_facts:
            summary += f"é‡è¦äº‹å®: {len(profile.important_facts)} æ¡\n"
            for fact in profile.important_facts[:3]:
                summary += f"  - {fact}\n"

        return summary

# ============ 3. RAG ç³»ç»Ÿ ============

class SimpleRAGSystem:
    """ç®€åŒ–çš„RAGç³»ç»Ÿ"""

    def __init__(self):
        self.documents: List[str] = []
        self.doc_ids: List[str] = []

    def add_document(self, doc_id: str, content: str):
        """æ·»åŠ æ–‡æ¡£"""
        self.doc_ids.append(doc_id)
        self.documents.append(content)
        print(f"ğŸ“„ å·²æ·»åŠ æ–‡æ¡£: {doc_id}")

    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """ç®€å•çš„å…³é”®è¯æ£€ç´¢"""
        results = []

        query_lower = query.lower()

        for i, doc in enumerate(self.documents):
            # ç®€å•çš„ç›¸å…³æ€§è®¡ç®—: å…³é”®è¯åŒ¹é…æ•°
            relevance = sum(1 for word in query_lower.split() if word in doc.lower())

            if relevance > 0:
                results.append({
                    "doc_id": self.doc_ids[i],
                    "content": doc,
                    "relevance": relevance
                })

        # æŒ‰ç›¸å…³æ€§æ’åº
        results.sort(key=lambda x: x["relevance"], reverse=True)

        return results[:top_k]

    def get_documents_count(self) -> int:
        """è·å–æ–‡æ¡£æ•°é‡"""
        return len(self.documents)

# ============ 4. å·¥å…·å®šä¹‰ ============

class MemoryTool:
    """è®°å¿†å·¥å…·"""

    def __init__(self, memory_system: ConversationMemory):
        self.memory = memory_system
        self.name = "memory"
        self.description = """
        è®°å¿†ç®¡ç†å·¥å…·ã€‚å¯ä»¥ä¿å­˜å’Œæ£€ç´¢é‡è¦ä¿¡æ¯ã€ç”¨æˆ·åå¥½ã€‚

        æ“ä½œ:
        - save_fact: ä¿å­˜é‡è¦äº‹å®
        - recall_facts: å›å¿†æ‰€æœ‰äº‹å®
        - save_preference: ä¿å­˜ç”¨æˆ·åå¥½
        - get_profile: è·å–ç”¨æˆ·ç”»åƒ
        """

    def run(self, action: str, content: str = "", key: str = "", value: str = "") -> str:
        """æ‰§è¡Œè®°å¿†æ“ä½œ"""
        if action == "save_fact":
            self.memory.save_important_fact(content)
            return f"âœ… å·²ä¿å­˜äº‹å®: {content[:50]}..."

        elif action == "recall_facts":
            facts = self.memory.recall_facts()
            if facts:
                return "ğŸ“š å›å¿†åˆ°ä»¥ä¸‹äº‹å®:\n" + "\n".join(f"- {f}" for f in facts)
            else:
                return "âŒ æš‚æ— ä¿å­˜çš„äº‹å®"

        elif action == "save_preference":
            self.memory.update_preference(key, value)
            return f"âœ… å·²ä¿å­˜åå¥½: {key} = {value}"

        elif action == "get_profile":
            return "ğŸ‘¤ ç”¨æˆ·ç”»åƒ:\n" + self.memory.get_profile_summary()

        else:
            return f"âŒ æœªçŸ¥æ“ä½œ: {action}"

class RAGTool:
    """çŸ¥è¯†æ£€ç´¢å·¥å…·"""

    def __init__(self, rag_system: SimpleRAGSystem):
        self.rag = rag_system
        self.name = "knowledge_search"
        self.description = """
        çŸ¥è¯†åº“æ£€ç´¢å·¥å…·ã€‚å¯ä»¥ä»å¤–éƒ¨æ–‡æ¡£åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯ã€‚

        æ“ä½œ:
        - search: æœç´¢ç›¸å…³æ–‡æ¡£
        - add_document: æ·»åŠ æ–°æ–‡æ¡£
        - count: æŸ¥çœ‹æ–‡æ¡£æ•°é‡
        """

    def run(self, action: str, query: str = "", doc_id: str = "", content: str = "") -> str:
        """æ‰§è¡ŒRAGæ“ä½œ"""
        if action == "search":
            results = self.rag.search(query, top_k=3)

            if not results:
                return f"âŒ æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„ä¿¡æ¯"

            output = f"ğŸ” æ‰¾åˆ° {len(results)} æ¡ç›¸å…³ä¿¡æ¯:\n\n"
            for i, r in enumerate(results, 1):
                output += f"{i}. [{r['doc_id']}] (ç›¸å…³åº¦: {r['relevance']})\n"
                output += f"   {r['content'][:200]}...\n\n"

            return output

        elif action == "add_document":
            self.rag.add_document(doc_id, content)
            return f"âœ… å·²æ·»åŠ æ–‡æ¡£: {doc_id}"

        elif action == "count":
            count = self.rag.get_documents_count()
            return f"ğŸ“Š çŸ¥è¯†åº“å…±æœ‰ {count} ç¯‡æ–‡æ¡£"

        else:
            return f"âŒ æœªçŸ¥æ“ä½œ: {action}"

# ============ 5. ç®€åŒ–çš„ Agent ============

class SimpleReActAgent:
    """ç®€åŒ–çš„ ReAct Agent"""

    def __init__(
        self,
        name: str,
        memory_tool: MemoryTool,
        rag_tool: RAGTool,
        memory_system: ConversationMemory
    ):
        self.name = name
        self.memory_tool = memory_tool
        self.rag_tool = rag_tool
        self.memory = memory_system

        self.tools = {
            "memory": memory_tool,
            "knowledge_search": rag_tool
        }

    def _analyze_query(self, query: str) -> Dict:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾"""
        query_lower = query.lower()

        intent = {
            "needs_memory": False,
            "needs_rag": False,
            "needs_save": False,
            "query_type": "unknown"
        }

        # æ£€æµ‹æ˜¯å¦éœ€è¦ä¿å­˜ä¿¡æ¯
        save_keywords = ["è®°ä½", "ä¿å­˜", "æˆ‘å«", "æˆ‘çš„", "åå¥½"]
        if any(kw in query_lower for kw in save_keywords):
            intent["needs_save"] = True
            intent["query_type"] = "save_info"

        # æ£€æµ‹æ˜¯å¦éœ€è¦å›å¿†
        recall_keywords = ["å›å¿†", "ä¹‹å‰", "è®°å¾—", "æˆ‘è¯´è¿‡"]
        if any(kw in query_lower for kw in recall_keywords):
            intent["needs_memory"] = True
            intent["query_type"] = "recall"

        # æ£€æµ‹æ˜¯å¦éœ€è¦çŸ¥è¯†æ£€ç´¢
        search_keywords = ["ä»€ä¹ˆæ˜¯", "ä»‹ç»", "è§£é‡Š", "å¦‚ä½•", "æ€ä¹ˆ"]
        if any(kw in query_lower for kw in search_keywords):
            intent["needs_rag"] = True
            intent["query_type"] = "knowledge_query"

        return intent

    def run(self, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ·»åŠ åˆ°çŸ­æœŸè®°å¿†
        self.memory.add_message("user", user_input)

        # åˆ†ææ„å›¾
        intent = self._analyze_query(user_input)

        response_parts = []

        # æ ¹æ®æ„å›¾æ‰§è¡Œæ“ä½œ
        if intent["needs_save"]:
            # æå–è¦ä¿å­˜çš„ä¿¡æ¯
            if "æˆ‘å«" in user_input:
                name = user_input.split("æˆ‘å«")[1].strip()
                result = self.memory_tool.run("save_fact", content=f"ç”¨æˆ·åå­—: {name}")
                response_parts.append(result)
                response_parts.append(f"å¥½çš„,æˆ‘ä¼šè®°ä½æ‚¨å«{name}!")
            else:
                result = self.memory_tool.run("save_fact", content=user_input)
                response_parts.append(result)
                response_parts.append("æˆ‘å·²ç»è®°ä¸‹äº†!")

        if intent["needs_memory"]:
            # å›å¿†ä¹‹å‰çš„ä¿¡æ¯
            result = self.memory_tool.run("recall_facts")
            response_parts.append(result)

        if intent["needs_rag"]:
            # æœç´¢çŸ¥è¯†åº“
            result = self.rag_tool.run("search", query=user_input)
            response_parts.append(result)

        # å¦‚æœæ²¡æœ‰åŒ¹é…ä»»ä½•æ„å›¾,è¿”å›é»˜è®¤å›å¤
        if not response_parts:
            response_parts.append("æˆ‘ç†è§£äº†æ‚¨çš„é—®é¢˜ã€‚è®©æˆ‘æƒ³æƒ³...")

            # å°è¯•ä»ä¸Šä¸‹æ–‡å›ç­”
            recent = self.memory.get_recent_context(limit=5)
            if recent:
                response_parts.append("æ ¹æ®æˆ‘ä»¬æœ€è¿‘çš„å¯¹è¯,æˆ‘è®°å¾—...")

        # ç»„åˆå›å¤
        response = "\n".join(response_parts)

        # æ·»åŠ åˆ°çŸ­æœŸè®°å¿†
        self.memory.add_message("assistant", response)

        return response

# ============ 6. å®Œæ•´ç¤ºä¾‹ ============

def create_knowledge_assistant():
    """åˆ›å»ºçŸ¥è¯†åŠ©æ‰‹"""
    # åˆå§‹åŒ–ç»„ä»¶
    memory = ConversationMemory(max_short_term=20, user_id="user_001")
    rag = SimpleRAGSystem()

    # æ·»åŠ ä¸€äº›åˆå§‹æ–‡æ¡£
    rag.add_document(
        "python_intro",
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€,ç”±Guido van Rossumäº1991å¹´åˆ›å»ºã€‚"
        "å®ƒå¼ºè°ƒä»£ç çš„å¯è¯»æ€§,è¯­æ³•ç®€æ´æ˜äº†ã€‚Pythonå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€"
        "æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½ã€è‡ªåŠ¨åŒ–ç­‰é¢†åŸŸã€‚"
    )

    rag.add_document(
        "machine_learning",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯,å®ƒä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ "
        "å¹¶æ”¹è¿›æ€§èƒ½,è€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚å¸¸è§çš„æœºå™¨å­¦ä¹ ç®—æ³•åŒ…æ‹¬å†³ç­–æ ‘ã€"
        "æ”¯æŒå‘é‡æœºã€ç¥ç»ç½‘ç»œç­‰ã€‚"
    )

    rag.add_document(
        "rag_concept",
        "RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æŠ€æœ¯ã€‚"
        "å®ƒé¦–å…ˆä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯,ç„¶åå°†è¿™äº›ä¿¡æ¯ä¸æŸ¥è¯¢ä¸€èµ·"
        "è¾“å…¥åˆ°è¯­è¨€æ¨¡å‹ä¸­,ç”Ÿæˆæ›´å‡†ç¡®ã€æ›´æœ‰æ ¹æ®çš„å›ç­”ã€‚"
    )

    # åˆ›å»ºå·¥å…·
    memory_tool = MemoryTool(memory)
    rag_tool = RAGTool(rag)

    # åˆ›å»ºAgent
    agent = SimpleReActAgent(
        name="çŸ¥è¯†åŠ©æ‰‹",
        memory_tool=memory_tool,
        rag_tool=rag_tool,
        memory_system=memory
    )

    return agent

# ============ 7. æµ‹è¯•åœºæ™¯ ============

def test_conversation_scenarios():
    """æµ‹è¯•å¯¹è¯åœºæ™¯"""
    agent = create_knowledge_assistant()

    print("="*70)
    print("ğŸ¤– æ™ºèƒ½çŸ¥è¯†åŠ©æ‰‹ v1.0")
    print("="*70)

    # åœºæ™¯1: ä¿å­˜ä¸ªäººä¿¡æ¯
    print("\nã€åœºæ™¯1ã€‘ä¿å­˜ä¸ªäººä¿¡æ¯")
    print("-"*70)
    user_input = "ä½ å¥½,æˆ‘å«å°æ˜"
    print(f"ç”¨æˆ·: {user_input}")
    response = agent.run(user_input)
    print(f"åŠ©æ‰‹: {response}")

    # åœºæ™¯2: çŸ¥è¯†æŸ¥è¯¢
    print("\nã€åœºæ™¯2ã€‘çŸ¥è¯†æŸ¥è¯¢")
    print("-"*70)
    user_input = "ä»€ä¹ˆæ˜¯Python?"
    print(f"ç”¨æˆ·: {user_input}")
    response = agent.run(user_input)
    print(f"åŠ©æ‰‹: {response}")

    # åœºæ™¯3: ä¿å­˜åå¥½
    print("\nã€åœºæ™¯3ã€‘ä¿å­˜åå¥½")
    print("-"*70)
    user_input = "è®°ä½,æˆ‘å–œæ¬¢ç”¨Pythonåšæ•°æ®åˆ†æ"
    print(f"ç”¨æˆ·: {user_input}")
    response = agent.run(user_input)
    print(f"åŠ©æ‰‹: {response}")

    # åœºæ™¯4: å›å¿†ä¿¡æ¯
    print("\nã€åœºæ™¯4ã€‘å›å¿†ä¿¡æ¯")
    print("-"*70)
    user_input = "ä½ è¿˜è®°å¾—æˆ‘ä¹‹å‰è¯´è¿‡ä»€ä¹ˆå—?"
    print(f"ç”¨æˆ·: {user_input}")
    response = agent.run(user_input)
    print(f"åŠ©æ‰‹: {response}")

    # åœºæ™¯5: å¤æ‚æŸ¥è¯¢ (RAG + Memory)
    print("\nã€åœºæ™¯5ã€‘å¤æ‚æŸ¥è¯¢")
    print("-"*70)
    user_input = "è§£é‡Šä¸€ä¸‹RAGæ˜¯ä»€ä¹ˆ"
    print(f"ç”¨æˆ·: {user_input}")
    response = agent.run(user_input)
    print(f"åŠ©æ‰‹: {response}")

    # æŸ¥çœ‹æœ€ç»ˆçš„ç”¨æˆ·ç”»åƒ
    print("\nã€ç”¨æˆ·ç”»åƒã€‘")
    print("-"*70)
    print(agent.memory.get_profile_summary())

# è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    test_conversation_scenarios()
```

---

### âœ… è§£ç­”5.2: è¿è¡Œè¾“å‡ºç¤ºä¾‹

```
======================================================================
ğŸ¤– æ™ºèƒ½çŸ¥è¯†åŠ©æ‰‹ v1.0
======================================================================
ğŸ“„ å·²æ·»åŠ æ–‡æ¡£: python_intro
ğŸ“„ å·²æ·»åŠ æ–‡æ¡£: machine_learning
ğŸ“„ å·²æ·»åŠ æ–‡æ¡£: rag_concept

ã€åœºæ™¯1ã€‘ä¿å­˜ä¸ªäººä¿¡æ¯
----------------------------------------------------------------------
ç”¨æˆ·: ä½ å¥½,æˆ‘å«å°æ˜
ğŸ’¾ å·²ä¿å­˜åˆ°é•¿æœŸè®°å¿†: ç”¨æˆ·åå­—: å°æ˜...
åŠ©æ‰‹: âœ… å·²ä¿å­˜äº‹å®: ç”¨æˆ·åå­—: å°æ˜...
å¥½çš„,æˆ‘ä¼šè®°ä½æ‚¨å«å°æ˜!

ã€åœºæ™¯2ã€‘çŸ¥è¯†æŸ¥è¯¢
----------------------------------------------------------------------
ç”¨æˆ·: ä»€ä¹ˆæ˜¯Python?
åŠ©æ‰‹: ğŸ” æ‰¾åˆ° 1 æ¡ç›¸å…³ä¿¡æ¯:

1. [python_intro] (ç›¸å…³åº¦: 1)
   Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€,ç”±Guido van Rossumäº1991å¹´åˆ›å»ºã€‚å®ƒå¼ºè°ƒä»£ç çš„å¯è¯»æ€§,è¯­æ³•ç®€æ´æ˜äº†ã€‚Pythonå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½ã€è‡ªåŠ¨åŒ–ç­‰é¢†åŸŸã€‚...

ã€åœºæ™¯3ã€‘ä¿å­˜åå¥½
----------------------------------------------------------------------
ç”¨æˆ·: è®°ä½,æˆ‘å–œæ¬¢ç”¨Pythonåšæ•°æ®åˆ†æ
ğŸ’¾ å·²ä¿å­˜åˆ°é•¿æœŸè®°å¿†: è®°ä½,æˆ‘å–œæ¬¢ç”¨Pythonåšæ•°æ®åˆ†æ...
åŠ©æ‰‹: âœ… å·²ä¿å­˜äº‹å®: è®°ä½,æˆ‘å–œæ¬¢ç”¨Pythonåšæ•°æ®åˆ†æ...
æˆ‘å·²ç»è®°ä¸‹äº†!

ã€åœºæ™¯4ã€‘å›å¿†ä¿¡æ¯
----------------------------------------------------------------------
ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘ä¹‹å‰è¯´è¿‡ä»€ä¹ˆå—?
åŠ©æ‰‹: ğŸ“š å›å¿†åˆ°ä»¥ä¸‹äº‹å®:
- ç”¨æˆ·åå­—: å°æ˜
- è®°ä½,æˆ‘å–œæ¬¢ç”¨Pythonåšæ•°æ®åˆ†æ

ã€åœºæ™¯5ã€‘å¤æ‚æŸ¥è¯¢
----------------------------------------------------------------------
ç”¨æˆ·: è§£é‡Šä¸€ä¸‹RAGæ˜¯ä»€ä¹ˆ
åŠ©æ‰‹: ğŸ” æ‰¾åˆ° 1 æ¡ç›¸å…³ä¿¡æ¯:

1. [rag_concept] (ç›¸å…³åº¦: 2)
   RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æŠ€æœ¯ã€‚å®ƒé¦–å…ˆä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯,ç„¶åå°†è¿™äº›ä¿¡æ¯ä¸æŸ¥è¯¢ä¸€èµ·è¾“å…¥åˆ°è¯­è¨€æ¨¡å‹ä¸­,ç”Ÿæˆæ›´å‡†ç¡®ã€æ›´æœ‰æ ¹æ®çš„å›ç­”ã€‚...

ã€ç”¨æˆ·ç”»åƒã€‘
----------------------------------------------------------------------
ç”¨æˆ·ID: user_001
äº¤äº’æ¬¡æ•°: 5
é‡è¦äº‹å®: 2 æ¡
  - ç”¨æˆ·åå­—: å°æ˜
  - è®°ä½,æˆ‘å–œæ¬¢ç”¨Pythonåšæ•°æ®åˆ†æ
```

---

### âœ… è§£ç­”5.3: è¿›é˜¶ç‰ˆ - é›†æˆçœŸå®LLM

ä¸Šé¢çš„æ˜¯ç®€åŒ–ç‰ˆ,ä¸‹é¢æ˜¯é›†æˆçœŸå®LLMçš„ç‰ˆæœ¬:

```python
# éœ€è¦å®‰è£…: pip install langchain langchain-openai

from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate

class ProductionKnowledgeAssistant:
    """ç”Ÿäº§çº§çŸ¥è¯†åŠ©æ‰‹ (é›†æˆLangChain)"""

    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo"):
        # åˆå§‹åŒ–ç»„ä»¶
        self.memory = ConversationMemory(user_id="user_001")
        self.rag = SimpleRAGSystem()

        # æ·»åŠ çŸ¥è¯†åº“æ–‡æ¡£
        self._init_knowledge_base()

        # åˆ›å»ºå·¥å…·
        self.memory_tool_obj = MemoryTool(self.memory)
        self.rag_tool_obj = RAGTool(self.rag)

        # è½¬æ¢ä¸ºLangChain Toolæ ¼å¼
        self.tools = [
            Tool(
                name="Memory",
                func=lambda params: self._execute_memory_tool(params),
                description=self.memory_tool_obj.description
            ),
            Tool(
                name="KnowledgeSearch",
                func=lambda params: self._execute_rag_tool(params),
                description=self.rag_tool_obj.description
            )
        ]

        # åˆ›å»ºLLM
        self.llm = ChatOpenAI(
            model=model,
            temperature=0.7,
            api_key=api_key
        )

        # åˆ›å»ºAgent
        prompt = PromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çŸ¥è¯†åŠ©æ‰‹ã€‚ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨:

{tools}

å·¥å…·ä½¿ç”¨æ ¼å¼:
Thought: æˆ‘éœ€è¦æ€è€ƒå¦‚ä½•å›ç­”
Action: å·¥å…·åç§°
Action Input: å·¥å…·å‚æ•°
Observation: å·¥å…·è¿”å›ç»“æœ
... (å¯é‡å¤å¤šæ¬¡)
Thought: ç°åœ¨æˆ‘çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
Final Answer: æœ€ç»ˆå›ç­”

å¯¹è¯å†å²:
{chat_history}

ç”¨æˆ·é—®é¢˜: {input}

{agent_scratchpad}
""")

        self.agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )

        self.executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=5
        )

    def _init_knowledge_base(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        docs = [
            ("python", "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€..."),
            ("ml", "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„åˆ†æ”¯..."),
            ("rag", "RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯...")
        ]

        for doc_id, content in docs:
            self.rag.add_document(doc_id, content)

    def _execute_memory_tool(self, params: str) -> str:
        """æ‰§è¡Œè®°å¿†å·¥å…·"""
        # è§£æå‚æ•° (ç®€åŒ–ç‰ˆ)
        if "save" in params.lower():
            return self.memory_tool_obj.run("save_fact", content=params)
        elif "recall" in params.lower():
            return self.memory_tool_obj.run("recall_facts")
        else:
            return "è¯·æŒ‡å®šæ“ä½œ: save æˆ– recall"

    def _execute_rag_tool(self, params: str) -> str:
        """æ‰§è¡ŒRAGå·¥å…·"""
        return self.rag_tool_obj.run("search", query=params)

    def chat(self, user_input: str) -> str:
        """èŠå¤©æ¥å£"""
        # è·å–å¯¹è¯å†å²
        chat_history = "\n".join([
            f"{msg.role}: {msg.content}"
            for msg in self.memory.get_recent_context(limit=5)
        ])

        # æ‰§è¡ŒAgent
        result = self.executor.invoke({
            "input": user_input,
            "chat_history": chat_history
        })

        # ä¿å­˜åˆ°è®°å¿†
        self.memory.add_message("user", user_input)
        self.memory.add_message("assistant", result["output"])

        return result["output"]

# ä½¿ç”¨ç¤ºä¾‹
# assistant = ProductionKnowledgeAssistant(api_key="your-openai-key")
# response = assistant.chat("ä»€ä¹ˆæ˜¯Python?")
# print(response)
```

---

### ğŸ’¡ è§£ç­”5.4: å…³é”®è®¾è®¡äº®ç‚¹

```
âœ¨ ç³»ç»Ÿè®¾è®¡äº®ç‚¹:

1ï¸âƒ£ åˆ†å±‚æ¶æ„
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Agentå±‚    â”‚ â† å†³ç­–å’Œå·¥å…·è°ƒç”¨
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚  Toolå±‚     â”‚ â† Memory + RAGå·¥å…·
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚  Systemå±‚   â”‚ â† è®°å¿†ç³»ç»Ÿ + æ£€ç´¢ç³»ç»Ÿ
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2ï¸âƒ£ æ„å›¾è¯†åˆ«
   â†’ é€šè¿‡å…³é”®è¯è‡ªåŠ¨åˆ¤æ–­éœ€è¦ä½¿ç”¨å“ªä¸ªå·¥å…·
   â†’ "è®°ä½" â†’ MemoryTool.save
   â†’ "ä»€ä¹ˆæ˜¯" â†’ RAGTool.search
   â†’ "ä¹‹å‰" â†’ MemoryTool.recall

3ï¸âƒ£ ä¸Šä¸‹æ–‡ç®¡ç†
   â†’ çŸ­æœŸè®°å¿†: æ»‘åŠ¨çª—å£ (20æ¡)
   â†’ é•¿æœŸè®°å¿†: é‡è¦äº‹å®åˆ—è¡¨
   â†’ ç”¨æˆ·ç”»åƒ: åå¥½å’Œç»Ÿè®¡

4ï¸âƒ£ å¯æ‰©å±•æ€§
   â†’ è½»æ¾æ·»åŠ æ–°å·¥å…· (WeatherTool, CalculatorTool...)
   â†’ è½»æ¾æ›¿æ¢LLM (OpenAI â†’ Anthropic â†’ Local)
   â†’ è½»æ¾å‡çº§RAG (Simple â†’ Chroma â†’ Pinecone)
```

---

### ğŸ“Š è§£ç­”5.5: å®Œæ•´æµ‹è¯•æŠ¥å‘Š

```python
def comprehensive_test():
    """ç»¼åˆæµ‹è¯•"""
    agent = create_knowledge_assistant()

    test_cases = [
        # (ç”¨æˆ·è¾“å…¥, é¢„æœŸè¡Œä¸º)
        ("æˆ‘å«Alice", "åº”è¯¥ä¿å­˜åˆ°è®°å¿†"),
        ("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ?", "åº”è¯¥æœç´¢çŸ¥è¯†åº“"),
        ("æˆ‘å–œæ¬¢Python", "åº”è¯¥ä¿å­˜åå¥½"),
        ("ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—?", "åº”è¯¥å›å¿†è®°å¿†"),
        ("RAGæ˜¯ä»€ä¹ˆæŠ€æœ¯?", "åº”è¯¥æœç´¢çŸ¥è¯†åº“"),
    ]

    print("="*70)
    print("ğŸ“Š ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
    print("="*70)

    for i, (user_input, expected) in enumerate(test_cases, 1):
        print(f"\nã€æµ‹è¯• {i}ã€‘{expected}")
        print(f"è¾“å…¥: {user_input}")

        response = agent.run(user_input)

        print(f"è¾“å‡º: {response[:100]}...")
        print("âœ… æµ‹è¯•é€šè¿‡" if len(response) > 0 else "âŒ æµ‹è¯•å¤±è´¥")

    # æœ€ç»ˆæ£€æŸ¥
    print("\n" + "="*70)
    print("ğŸ“ˆ æœ€ç»ˆçŠ¶æ€")
    print("="*70)
    print(agent.memory.get_profile_summary())

    print(f"\nçŸ¥è¯†åº“æ–‡æ¡£æ•°: {agent.rag_tool.rag.get_documents_count()}")
    print(f"å¯¹è¯è½®æ¬¡: {len(agent.memory.short_term)}")

# è¿è¡Œæµ‹è¯•
comprehensive_test()
```

---

## ğŸ“ æœ¬ç« æ€»ç»“

é€šè¿‡è¿™5é“ä¹ é¢˜,æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†:

### ğŸ¯ æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **è®°å¿†ç®¡ç†ç­–ç•¥**:
   - æ»‘åŠ¨çª—å£: ç®€å•é«˜æ•ˆ,é€‚åˆçŸ­å¯¹è¯
   - é‡è¦æ€§é‡‡æ ·: æ™ºèƒ½ç­›é€‰,é€‚åˆä¸­ç­‰å¯¹è¯
   - æ‘˜è¦å‹ç¼©: é«˜å‹ç¼©æ¯”,é€‚åˆé•¿å¯¹è¯

2. **RAGæ£€ç´¢æŠ€æœ¯**:
   - å‘é‡æ£€ç´¢: è¯­ä¹‰ç†è§£å¼º
   - å…³é”®è¯æ£€ç´¢: ç²¾ç¡®åŒ¹é…å¥½
   - æ··åˆæ£€ç´¢: ç»“åˆä¸¤è€…ä¼˜åŠ¿

3. **ç³»ç»Ÿé›†æˆ**:
   - Memory + RAG + LLM = å®Œæ•´æ™ºèƒ½ä½“
   - å·¥å…·åŒ–è®¾è®¡,æ¨¡å—åŒ–æ¶æ„
   - æ„å›¾è¯†åˆ«,è‡ªåŠ¨å†³ç­–

### ğŸš€ å®æˆ˜èƒ½åŠ›

âœ… èƒ½å¤Ÿè®¾è®¡å’Œå®ç°å¤šç­–ç•¥è®°å¿†ç³»ç»Ÿ
âœ… èƒ½å¤Ÿæ„å»ºæ··åˆæ£€ç´¢ç³»ç»Ÿ (BM25 + å‘é‡ + é‡æ’åº)
âœ… èƒ½å¤Ÿé›†æˆMemoryå’ŒRAGåˆ°Agentä¸­
âœ… èƒ½å¤Ÿè¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–

### ğŸ’¡ æœ€ä½³å®è·µ

```
1ï¸âƒ£ è®°å¿†ç­–ç•¥é€‰æ‹©
   â†’ æ ¹æ®å¯¹è¯é•¿åº¦åŠ¨æ€åˆ‡æ¢
   â†’ çŸ­: æ»‘åŠ¨çª—å£
   â†’ ä¸­: é‡è¦æ€§é‡‡æ ·
   â†’ é•¿: æ‘˜è¦å‹ç¼©

2ï¸âƒ£ RAGä¼˜åŒ–
   â†’ åˆç­›: BM25 + å‘é‡ (å¬å› Top-20)
   â†’ é‡æ’: Cross-Encoder (ç²¾æ’ Top-5)
   â†’ ç¼“å­˜: çƒ­é—¨æŸ¥è¯¢ç»“æœ

3ï¸âƒ£ Agentè®¾è®¡
   â†’ åˆ†å±‚æ¶æ„: Agent â†’ Tool â†’ System
   â†’ æ„å›¾è¯†åˆ«: è‡ªåŠ¨é€‰æ‹©å·¥å…·
   â†’ ä¸Šä¸‹æ–‡ç®¡ç†: çŸ­æœŸ+é•¿æœŸ+ç”»åƒ

4ï¸âƒ£ æ€§èƒ½ç›‘æ§
   â†’ è¿½è¸ªTokenä½¿ç”¨
   â†’ è¿½è¸ªLLMè°ƒç”¨æ¬¡æ•°
   â†’ è¿½è¸ªæ£€ç´¢å»¶è¿Ÿ
```

---

## ğŸ”— ç›¸å…³èµ„æº

- **GitHubæºç **: https://github.com/jjyaoao/helloagents
- **ç¬¬å…«ç« æ–‡æ¡£**: [HelloAgents_Chapter8_è¯¦ç»†ç‰ˆ.md](https://github.com/jjyaoao/helloagents/chapter8)
- **LangChainæ–‡æ¡£**: https://python.langchain.com/docs
- **Chromaæ–‡æ¡£**: https://docs.trychroma.com/
- **Sentence Transformers**: https://www.sbert.net/

---

## ğŸ“Œ ä¸‹ä¸€æ­¥å­¦ä¹ 

å®Œæˆç¬¬å…«ç« å,å»ºè®®:

1. âœ… å®ç°ä¸€ä¸ªå®Œæ•´çš„RAGç³»ç»Ÿ,æ¥å…¥çœŸå®çš„PDFæ–‡æ¡£
2. âœ… å°è¯•ä¸åŒçš„Embeddingæ¨¡å‹,å¯¹æ¯”æ•ˆæœ
3. âœ… éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ,å¤„ç†çœŸå®æµé‡
4. âœ… ç»§ç»­å­¦ä¹ ç¬¬ä¹ç« : **ä¸Šä¸‹æ–‡å·¥ç¨‹**

---

**Happy Learning! ğŸ‰**
