# Hello Agents ç¬¬å…«ç« ï¼šä¸º Agent æ·»åŠ è®°å¿†ä¸æ£€ç´¢èƒ½åŠ›(è¯¦ç»†ç‰ˆ)

> **æœ¬ç« æ ¸å¿ƒæ€æƒ³**ï¼šè®© Agent èƒ½å¤Ÿ"è®°ä½"å¯¹è¯å†å²ã€æ£€ç´¢å¤–éƒ¨çŸ¥è¯†,ä»"å¥å¿˜ç—‡æ‚£è€…"å˜æˆ"åšå­¦å¤šè¯†"çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

---

## ğŸ“– ç›®å½•

- [1. ä¸ºä»€ä¹ˆ Agent éœ€è¦è®°å¿†?](#1-ä¸ºä»€ä¹ˆ-agent-éœ€è¦è®°å¿†)
- [2. Memory ç³»ç»Ÿè®¾è®¡](#2-memory-ç³»ç»Ÿè®¾è®¡)
- [3. RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ](#3-rag-æ£€ç´¢å¢å¼ºç”Ÿæˆ)
- [4. å‘é‡æ•°æ®åº“å®æˆ˜](#4-å‘é‡æ•°æ®åº“å®æˆ˜)
- [5. Memory ä½œä¸ºå·¥å…·é›†æˆ](#5-memory-ä½œä¸ºå·¥å…·é›†æˆ)
- [6. æœ¬ç« æ€»ç»“](#6-æœ¬ç« æ€»ç»“)

---

## 1. ä¸ºä»€ä¹ˆ Agent éœ€è¦è®°å¿†?

### ğŸ¤” æ²¡æœ‰è®°å¿†çš„ Agent æœ‰ä»€ä¹ˆé—®é¢˜?

æƒ³è±¡ä¸€ä¸‹,ä½ æ¯å¤©å’Œæœ‹å‹èŠå¤©,ä½†ä»–æ€»æ˜¯å¿˜è®°ä½ ä»¬ä¹‹å‰è¯´è¿‡çš„è¯:

```
ä½ :æˆ‘å«å°æ˜,ä»Šå¹´25å²
Agent:ä½ å¥½!
ä½ :æˆ‘åˆšæ‰è¯´äº†ä»€ä¹ˆ?
Agent:å¯¹ä¸èµ·,æˆ‘ä¸çŸ¥é“ä½ åœ¨è¯´ä»€ä¹ˆ
```

**é—®é¢˜ä¸€:æ— æ³•ç»´æŒè¿è´¯å¯¹è¯** ğŸ˜µ
- æ¯æ¬¡å¯¹è¯éƒ½æ˜¯"æ–°æœ‹å‹"
- æ— æ³•åŸºäºä¸Šä¸‹æ–‡å›ç­”
- ç”¨æˆ·ä½“éªŒå¾ˆå·®

**é—®é¢˜äºŒ:æ— æ³•å­¦ä¹ ç”¨æˆ·åå¥½** ğŸ”„
- ä¸çŸ¥é“ç”¨æˆ·å–œå¥½
- é‡å¤è¯¢é—®ç›¸åŒä¿¡æ¯
- æ— æ³•ä¸ªæ€§åŒ–æœåŠ¡

**é—®é¢˜ä¸‰:çŸ¥è¯†å±€é™** ğŸ“¦
- åªèƒ½å›ç­”è®­ç»ƒæ•°æ®ä¸­çš„å†…å®¹
- æ— æ³•è·å–æœ€æ–°ä¿¡æ¯
- ä¸“ä¸šé¢†åŸŸçŸ¥è¯†ä¸è¶³

### ğŸ’¡ è®°å¿†ç³»ç»Ÿçš„ä»·å€¼

```
å¯¹è¯è®°å¿†(Short-term Memory)
    â†“
èƒ½è®°ä½æœ€è¿‘çš„å¯¹è¯
    â†“
çŸ¥è¯†è®°å¿†(Long-term Memory)
    â†“
èƒ½æ£€ç´¢ç›¸å…³çŸ¥è¯†
    â†“
ä¸ªæ€§åŒ–è®°å¿†(User Profile)
    â†“
èƒ½è®°ä½ç”¨æˆ·åå¥½
```

> ğŸ’­ **ç±»æ¯”**:å°±åƒäººçš„è®°å¿†ç³»ç»Ÿ,æœ‰çŸ­æœŸè®°å¿†(å¯¹è¯ä¸Šä¸‹æ–‡)å’Œé•¿æœŸè®°å¿†(çŸ¥è¯†åº“)

---

## 2. Memory ç³»ç»Ÿè®¾è®¡

### 2.1 è®°å¿†çš„ä¸‰ç§ç±»å‹

#### ğŸ“ çŸ­æœŸè®°å¿†(Short-term Memory)

**å®šä¹‰**:å½“å‰å¯¹è¯ä¼šè¯çš„ä¸Šä¸‹æ–‡

```python
class ShortTermMemory:
    """çŸ­æœŸè®°å¿†:å¯¹è¯å†å²"""

    def __init__(self, max_messages=20):
        self.messages = []  # å­˜å‚¨æ¶ˆæ¯
        self.max_messages = max_messages

    def add_message(self, role, content):
        """æ·»åŠ æ¶ˆæ¯"""
        message = Message(role=role, content=content)
        self.messages.append(message)

        # ä¿æŒæœ€å¤§é•¿åº¦
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages:]

    def get_messages(self):
        """è·å–å¯¹è¯å†å²"""
        return self.messages

    def clear(self):
        """æ¸…ç©ºè®°å¿†"""
        self.messages = []
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
memory = ShortTermMemory(max_messages=10)

# æ·»åŠ å¯¹è¯
memory.add_message("user", "æˆ‘å«å°æ˜")
memory.add_message("assistant", "ä½ å¥½,å°æ˜!")
memory.add_message("user", "æˆ‘åˆšæ‰å«ä»€ä¹ˆåå­—?")

# è·å–ä¸Šä¸‹æ–‡
messages = memory.get_messages()
# Agent å¯ä»¥çœ‹åˆ°å®Œæ•´å¯¹è¯å†å²,çŸ¥é“ç”¨æˆ·å«å°æ˜
```

#### ğŸ—„ï¸ é•¿æœŸè®°å¿†(Long-term Memory)

**å®šä¹‰**:æŒä¹…åŒ–å­˜å‚¨çš„çŸ¥è¯†å’Œç»éªŒ

```python
class LongTermMemory:
    """é•¿æœŸè®°å¿†:çŸ¥è¯†åº“"""

    def __init__(self, storage_path="memory.db"):
        self.storage_path = storage_path
        self.db = self._init_database()

    def save(self, key, value, metadata=None):
        """ä¿å­˜è®°å¿†"""
        memory = {
            "key": key,
            "value": value,
            "metadata": metadata or {},
            "timestamp": datetime.now()
        }
        self.db.insert(memory)

    def recall(self, query, limit=5):
        """æ£€ç´¢è®°å¿†"""
        # åŸºäºå…³é”®è¯æ£€ç´¢
        results = self.db.search(query, limit=limit)
        return results

    def forget(self, key):
        """åˆ é™¤è®°å¿†"""
        self.db.delete(key)
```

**ä½¿ç”¨åœºæ™¯**:

```python
ltm = LongTermMemory()

# ä¿å­˜ç”¨æˆ·ä¿¡æ¯
ltm.save(
    key="user_profile_xiaoming",
    value={
        "name": "å°æ˜",
        "age": 25,
        "interests": ["ç¼–ç¨‹", "é˜…è¯»"]
    },
    metadata={"type": "user_profile"}
)

# åç»­å¯¹è¯ä¸­æ£€ç´¢
profile = ltm.recall("å°æ˜çš„å…´è¶£")
# è¿”å›:["ç¼–ç¨‹", "é˜…è¯»"]
```

#### ğŸ‘¤ ä¸ªæ€§åŒ–è®°å¿†(User Profile)

**å®šä¹‰**:ç”¨æˆ·ç‰¹å®šçš„åå¥½å’Œä¹ æƒ¯

```python
class UserProfile:
    """ç”¨æˆ·ç”»åƒè®°å¿†"""

    def __init__(self, user_id):
        self.user_id = user_id
        self.preferences = {}  # åå¥½
        self.history = []      # äº¤äº’å†å²
        self.context = {}      # ä¸Šä¸‹æ–‡ä¿¡æ¯

    def update_preference(self, key, value):
        """æ›´æ–°åå¥½"""
        self.preferences[key] = value

    def add_interaction(self, interaction):
        """è®°å½•äº¤äº’"""
        self.history.append({
            "timestamp": datetime.now(),
            "content": interaction
        })

    def get_summary(self):
        """è·å–ç”¨æˆ·æ‘˜è¦"""
        return {
            "user_id": self.user_id,
            "preferences": self.preferences,
            "total_interactions": len(self.history)
        }
```

### 2.2 è®°å¿†ç®¡ç†ç­–ç•¥

#### ğŸ—‘ï¸ ç­–ç•¥ä¸€:æ»‘åŠ¨çª—å£(Sliding Window)

**é€‚ç”¨åœºæ™¯**:å¯¹è¯åœºæ™¯

```python
class SlidingWindowMemory(ShortTermMemory):
    """æ»‘åŠ¨çª—å£è®°å¿†"""

    def add_message(self, role, content):
        """æ·»åŠ æ¶ˆæ¯,è‡ªåŠ¨æ·˜æ±°æ—§æ¶ˆæ¯"""
        super().add_message(role, content)

        # åªä¿ç•™æœ€è¿‘çš„ N æ¡
        if len(self.messages) > self.max_messages:
            removed = self.messages.pop(0)
            print(f"æ·˜æ±°æ—§æ¶ˆæ¯: {removed.content[:20]}...")
```

**å¯è§†åŒ–**:

```
æ—¶é—´çº¿:
[msg1] [msg2] [msg3] [msg4] [msg5] ... [msg20]
                                         â†‘
                                      æ–°æ¶ˆæ¯æ¥äº†
[msg2] [msg3] [msg4] [msg5] ... [msg20] [msg21]
 åˆ é™¤ç¬¬ä¸€æ¡,ä¿æŒçª—å£å¤§å° = 20
```

#### â­ ç­–ç•¥äºŒ:é‡è¦æ€§é‡‡æ ·(Importance Sampling)

**é€‚ç”¨åœºæ™¯**:éœ€è¦ä¿ç•™å…³é”®ä¿¡æ¯

```python
class ImportanceMemory:
    """åŸºäºé‡è¦æ€§çš„è®°å¿†ç®¡ç†"""

    def __init__(self, max_messages=20):
        self.messages = []
        self.max_messages = max_messages

    def calculate_importance(self, message):
        """è®¡ç®—æ¶ˆæ¯é‡è¦æ€§(0-1)"""
        importance = 0.5  # åŸºç¡€åˆ†æ•°

        # å› ç´ 1:é•¿åº¦(é•¿æ¶ˆæ¯å¯èƒ½æ›´é‡è¦)
        if len(message.content) > 100:
            importance += 0.1

        # å› ç´ 2:åŒ…å«å…³é”®è¯
        keywords = ["é‡è¦", "è®°ä½", "å…³é”®"]
        if any(kw in message.content for kw in keywords):
            importance += 0.2

        # å› ç´ 3:è§’è‰²(ç³»ç»Ÿæ¶ˆæ¯æ›´é‡è¦)
        if message.role == "system":
            importance += 0.2

        return min(importance, 1.0)

    def add_message(self, role, content):
        """æ·»åŠ æ¶ˆæ¯å¹¶è®¡ç®—é‡è¦æ€§"""
        message = Message(role=role, content=content)
        importance = self.calculate_importance(message)

        self.messages.append({
            "message": message,
            "importance": importance
        })

        # è¶…è¿‡é™åˆ¶æ—¶,åˆ é™¤æœ€ä¸é‡è¦çš„
        if len(self.messages) > self.max_messages:
            self.messages.sort(key=lambda x: x["importance"], reverse=True)
            removed = self.messages.pop()
            print(f"åˆ é™¤ä½é‡è¦æ€§æ¶ˆæ¯: {removed['message'].content[:20]}...")
```

#### ğŸ“Š ç­–ç•¥ä¸‰:æ‘˜è¦å‹ç¼©(Summarization)

**é€‚ç”¨åœºæ™¯**:é•¿å¯¹è¯å†å²

```python
class SummarizationMemory:
    """æ‘˜è¦å‹ç¼©è®°å¿†"""

    def __init__(self, llm, compress_threshold=20):
        self.llm = llm
        self.messages = []
        self.compress_threshold = compress_threshold
        self.summary = None

    def add_message(self, role, content):
        """æ·»åŠ æ¶ˆæ¯,è¾¾åˆ°é˜ˆå€¼æ—¶å‹ç¼©"""
        self.messages.append(Message(role=role, content=content))

        if len(self.messages) >= self.compress_threshold:
            self._compress()

    def _compress(self):
        """å‹ç¼©å†å²ä¸ºæ‘˜è¦"""
        # æ„å»ºå‹ç¼©æç¤ºè¯
        history_text = "\n".join([
            f"{msg.role}: {msg.content}"
            for msg in self.messages
        ])

        prompt = f"""
        è¯·å°†ä»¥ä¸‹å¯¹è¯å†å²å‹ç¼©ä¸ºç®€æ´çš„æ‘˜è¦(200å­—ä»¥å†…):

        {history_text}

        æ‘˜è¦:
        """

        # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
        self.summary = self.llm.generate(prompt)

        # æ¸…ç©ºæ—§æ¶ˆæ¯,åªä¿ç•™æ‘˜è¦
        self.messages = []
        print(f"âœ… å‹ç¼©å®Œæˆ,æ‘˜è¦: {self.summary[:50]}...")

    def get_context(self):
        """è·å–ä¸Šä¸‹æ–‡(æ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯)"""
        context = []

        # æ·»åŠ æ‘˜è¦
        if self.summary:
            context.append(Message(
                role="system",
                content=f"[å¯¹è¯æ‘˜è¦] {self.summary}"
            ))

        # æ·»åŠ æœ€è¿‘æ¶ˆæ¯
        context.extend(self.messages)

        return context
```

**ä½¿ç”¨æ•ˆæœ**:

```
åŸå§‹å¯¹è¯(100æ¡æ¶ˆæ¯,5000 tokens)
        â†“ å‹ç¼©
æ‘˜è¦(200å­—,150 tokens) + æœ€è¿‘10æ¡æ¶ˆæ¯(500 tokens)
        â†“
æ€»è®¡:650 tokens(èŠ‚çœ 87%)
```

### 2.3 Memory ç»Ÿä¸€æ¥å£

#### ğŸ¯ è®¾è®¡ Memory åŸºç±»

```python
from abc import ABC, abstractmethod

class BaseMemory(ABC):
    """Memory ç»Ÿä¸€æ¥å£"""

    @abstractmethod
    def add(self, message: Message):
        """æ·»åŠ è®°å¿†"""
        pass

    @abstractmethod
    def get(self, query: Optional[str] = None, limit: int = 10) -> List[Message]:
        """è·å–è®°å¿†"""
        pass

    @abstractmethod
    def clear(self):
        """æ¸…ç©ºè®°å¿†"""
        pass

    @abstractmethod
    def save(self, path: str):
        """æŒä¹…åŒ–ä¿å­˜"""
        pass

    @abstractmethod
    def load(self, path: str):
        """åŠ è½½è®°å¿†"""
        pass
```

#### ğŸ“ å¤šç§ Memory å®ç°

```python
# 1. ç®€å•åˆ—è¡¨è®°å¿†
class ListMemory(BaseMemory):
    """åŸºäºåˆ—è¡¨çš„å†…å­˜è®°å¿†"""
    def __init__(self):
        self.messages = []

    def add(self, message):
        self.messages.append(message)

    def get(self, query=None, limit=10):
        return self.messages[-limit:]

# 2. å‘é‡æ£€ç´¢è®°å¿†
class VectorMemory(BaseMemory):
    """åŸºäºå‘é‡çš„è¯­ä¹‰æ£€ç´¢è®°å¿†"""
    def __init__(self, embedding_model):
        self.embeddings = []
        self.messages = []
        self.embedding_model = embedding_model

    def add(self, message):
        embedding = self.embedding_model.encode(message.content)
        self.embeddings.append(embedding)
        self.messages.append(message)

    def get(self, query, limit=10):
        # è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
        query_embedding = self.embedding_model.encode(query)
        similarities = cosine_similarity(query_embedding, self.embeddings)
        top_indices = similarities.argsort()[-limit:]
        return [self.messages[i] for i in top_indices]

# 3. æ•°æ®åº“è®°å¿†
class DatabaseMemory(BaseMemory):
    """åŸºäºæ•°æ®åº“çš„æŒä¹…åŒ–è®°å¿†"""
    def __init__(self, db_path="memory.db"):
        self.db = sqlite3.connect(db_path)
        self._init_table()

    def add(self, message):
        self.db.execute(
            "INSERT INTO messages (role, content, timestamp) VALUES (?, ?, ?)",
            (message.role, message.content, datetime.now())
        )
        self.db.commit()

    def get(self, query=None, limit=10):
        if query:
            # å…³é”®è¯æœç´¢
            results = self.db.execute(
                "SELECT * FROM messages WHERE content LIKE ? LIMIT ?",
                (f"%{query}%", limit)
            )
        else:
            # è·å–æœ€æ–°
            results = self.db.execute(
                "SELECT * FROM messages ORDER BY timestamp DESC LIMIT ?",
                (limit,)
            )
        return [Message(role=r[0], content=r[1]) for r in results]
```

---

## 3. RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ

### 3.1 ä»€ä¹ˆæ˜¯ RAG?

#### ğŸ¯ æ ¸å¿ƒæ€æƒ³

```
ç”¨æˆ·é—®é¢˜
    â†“
æ£€ç´¢ç›¸å…³æ–‡æ¡£(Retrieval)
    â†“
å¢å¼º LLM è¾“å…¥(Augmentation)
    â†“
ç”Ÿæˆå›ç­”(Generation)
```

**ä¼ ç»Ÿæ–¹å¼ vs RAG**:

```python
# âŒ ä¼ ç»Ÿæ–¹å¼:åªä¾èµ–æ¨¡å‹çŸ¥è¯†
response = llm.generate("ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?")
# å¯èƒ½å›ç­”ä¸å‡†ç¡®æˆ–è¿‡æ—¶

# âœ… RAG æ–¹å¼:æ£€ç´¢ + ç”Ÿæˆ
docs = retrieve("é‡å­è®¡ç®—")  # æ£€ç´¢ç›¸å…³æ–‡æ¡£
prompt = f"""
åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜:

{docs}

é—®é¢˜:ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?
ç­”æ¡ˆ:
"""
response = llm.generate(prompt)
# å›ç­”æ›´å‡†ç¡®ã€æ›´æ–°
```

### 3.2 RAG ç³»ç»Ÿæ¶æ„

#### ğŸ—ï¸ å®Œæ•´æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ–‡æ¡£åº“        â”‚
â”‚  (PDFs/Docs)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ åˆ†å—(Chunking)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ–‡æœ¬å—        â”‚
â”‚  (Chunks)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ å‘é‡åŒ–(Embedding)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‘é‡æ•°æ®åº“    â”‚
â”‚  (Vector DB)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ æ£€ç´¢(Retrieval)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç›¸å…³æ–‡æ¡£      â”‚
â”‚  (Top-K Docs)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ æ„å»ºæç¤ºè¯
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¢å¼ºè¾“å…¥      â”‚
â”‚  (Prompt)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ LLM ç”Ÿæˆ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœ€ç»ˆç­”æ¡ˆ      â”‚
â”‚  (Answer)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ“ ç®€å• RAG å®ç°

```python
class SimpleRAG:
    """ç®€å•çš„ RAG ç³»ç»Ÿ"""

    def __init__(self, llm, embedding_model):
        self.llm = llm
        self.embedding_model = embedding_model
        self.documents = []       # åŸå§‹æ–‡æ¡£
        self.chunks = []          # æ–‡æœ¬å—
        self.embeddings = []      # å‘é‡

    def add_documents(self, documents):
        """æ·»åŠ æ–‡æ¡£"""
        for doc in documents:
            # 1. åˆ†å—
            chunks = self._split_document(doc)

            # 2. å‘é‡åŒ–
            for chunk in chunks:
                embedding = self.embedding_model.encode(chunk)
                self.chunks.append(chunk)
                self.embeddings.append(embedding)

        print(f"âœ… å·²ç´¢å¼• {len(self.chunks)} ä¸ªæ–‡æœ¬å—")

    def _split_document(self, document, chunk_size=500):
        """å°†æ–‡æ¡£åˆ†å‰²æˆå°å—"""
        chunks = []
        for i in range(0, len(document), chunk_size):
            chunk = document[i:i + chunk_size]
            chunks.append(chunk)
        return chunks

    def retrieve(self, query, top_k=3):
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        # 1. æŸ¥è¯¢å‘é‡åŒ–
        query_embedding = self.embedding_model.encode(query)

        # 2. è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for i, doc_embedding in enumerate(self.embeddings):
            sim = cosine_similarity(query_embedding, doc_embedding)
            similarities.append((sim, i))

        # 3. è¿”å› Top-K
        similarities.sort(reverse=True)
        top_chunks = [self.chunks[i] for _, i in similarities[:top_k]]

        return top_chunks

    def query(self, question):
        """RAG æŸ¥è¯¢"""
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        relevant_docs = self.retrieve(question, top_k=3)

        # 2. æ„å»ºæç¤ºè¯
        context = "\n\n".join(relevant_docs)
        prompt = f"""
        åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯,è¯·è¯´"æˆ‘ä¸çŸ¥é“"ã€‚

        æ–‡æ¡£:
        {context}

        é—®é¢˜:{question}

        ç­”æ¡ˆ:
        """

        # 3. ç”Ÿæˆå›ç­”
        answer = self.llm.generate(prompt)

        return {
            "answer": answer,
            "sources": relevant_docs[:2]  # è¿”å›å¼•ç”¨æ¥æº
        }
```

#### ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

```python
from hello_agents import HelloAgentsLLM
from sentence_transformers import SentenceTransformer

# 1. åˆå§‹åŒ–
llm = HelloAgentsLLM()
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
rag = SimpleRAG(llm, embedding_model)

# 2. æ·»åŠ æ–‡æ¡£
documents = [
    "é‡å­è®¡ç®—æ˜¯åˆ©ç”¨é‡å­åŠ›å­¦ç°è±¡è¿›è¡Œä¿¡æ¯å¤„ç†çš„è®¡ç®—æ–¹å¼...",
    "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€,ç”± Guido van Rossum åˆ›å»º...",
    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯..."
]
rag.add_documents(documents)

# 3. æŸ¥è¯¢
result = rag.query("ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?")
print("ç­”æ¡ˆ:", result["answer"])
print("æ¥æº:", result["sources"])
```

### 3.3 RAG ä¼˜åŒ–æŠ€å·§

#### âš¡ ä¼˜åŒ–ä¸€:æ”¹è¿›åˆ†å—ç­–ç•¥

```python
class ImprovedChunker:
    """æ”¹è¿›çš„æ–‡æ¡£åˆ†å—å™¨"""

    def __init__(self, chunk_size=500, overlap=50):
        self.chunk_size = chunk_size
        self.overlap = overlap  # é‡å éƒ¨åˆ†

    def split_with_overlap(self, text):
        """å¸¦é‡å çš„åˆ†å—"""
        chunks = []
        start = 0

        while start < len(text):
            end = start + self.chunk_size
            chunk = text[start:end]
            chunks.append(chunk)

            # ä¸‹ä¸€å—çš„èµ·ç‚¹å‘åç§»åŠ¨(chunk_size - overlap)
            start = start + self.chunk_size - self.overlap

        return chunks

    def split_by_sentence(self, text):
        """æŒ‰å¥å­è¾¹ç•Œåˆ†å—"""
        sentences = text.split('. ')
        chunks = []
        current_chunk = ""

        for sentence in sentences:
            if len(current_chunk) + len(sentence) < self.chunk_size:
                current_chunk += sentence + ". "
            else:
                chunks.append(current_chunk)
                current_chunk = sentence + ". "

        if current_chunk:
            chunks.append(current_chunk)

        return chunks
```

**ä¸ºä»€ä¹ˆè¦é‡å ?**

```
åŸå§‹æ–‡æœ¬:
"...é‡å­è®¡ç®—åˆ©ç”¨å åŠ åŸç†ã€‚å åŠ åŸç†æ˜¯é‡å­åŠ›å­¦çš„æ ¸å¿ƒ..."

æ— é‡å åˆ†å—:
å—1: "...é‡å­è®¡ç®—åˆ©ç”¨å åŠ åŸç†ã€‚"
å—2: "å åŠ åŸç†æ˜¯é‡å­åŠ›å­¦çš„æ ¸å¿ƒ..."
âŒ ä¸Šä¸‹æ–‡å‰²è£‚

å¸¦é‡å åˆ†å—:
å—1: "...é‡å­è®¡ç®—åˆ©ç”¨å åŠ åŸç†ã€‚å åŠ åŸç†æ˜¯..."
å—2: "å åŠ åŸç†ã€‚å åŠ åŸç†æ˜¯é‡å­åŠ›å­¦çš„æ ¸å¿ƒ..."
âœ… ä¿ç•™ä¸Šä¸‹æ–‡
```

#### ğŸ¯ ä¼˜åŒ–äºŒ:æ··åˆæ£€ç´¢

```python
class HybridRetriever:
    """æ··åˆæ£€ç´¢:å‘é‡æ£€ç´¢ + å…³é”®è¯æ£€ç´¢"""

    def __init__(self, embedding_model):
        self.embedding_model = embedding_model
        self.vector_index = []  # å‘é‡ç´¢å¼•
        self.bm25_index = None  # BM25 ç´¢å¼•
        self.documents = []

    def build_index(self, documents):
        """æ„å»ºåŒé‡ç´¢å¼•"""
        from rank_bm25 import BM25Okapi

        self.documents = documents

        # 1. æ„å»ºå‘é‡ç´¢å¼•
        for doc in documents:
            embedding = self.embedding_model.encode(doc)
            self.vector_index.append(embedding)

        # 2. æ„å»º BM25 ç´¢å¼•
        tokenized_docs = [doc.split() for doc in documents]
        self.bm25_index = BM25Okapi(tokenized_docs)

    def retrieve(self, query, top_k=5):
        """æ··åˆæ£€ç´¢"""
        # 1. å‘é‡æ£€ç´¢åˆ†æ•°
        query_embedding = self.embedding_model.encode(query)
        vector_scores = [
            cosine_similarity(query_embedding, doc_emb)
            for doc_emb in self.vector_index
        ]

        # 2. BM25 æ£€ç´¢åˆ†æ•°
        tokenized_query = query.split()
        bm25_scores = self.bm25_index.get_scores(tokenized_query)

        # 3. å½’ä¸€åŒ–åˆ†æ•°
        vector_scores = self._normalize(vector_scores)
        bm25_scores = self._normalize(bm25_scores)

        # 4. èåˆåˆ†æ•°(å¯è°ƒæƒé‡)
        alpha = 0.7  # å‘é‡æ£€ç´¢æƒé‡
        final_scores = [
            alpha * v + (1 - alpha) * b
            for v, b in zip(vector_scores, bm25_scores)
        ]

        # 5. è¿”å› Top-K
        top_indices = sorted(
            range(len(final_scores)),
            key=lambda i: final_scores[i],
            reverse=True
        )[:top_k]

        return [self.documents[i] for i in top_indices]

    def _normalize(self, scores):
        """å½’ä¸€åŒ–åˆ†æ•°åˆ° [0, 1]"""
        min_s, max_s = min(scores), max(scores)
        if max_s == min_s:
            return [0.5] * len(scores)
        return [(s - min_s) / (max_s - min_s) for s in scores]
```

#### ğŸ”„ ä¼˜åŒ–ä¸‰:é‡æ’åº(Re-ranking)

```python
class ReRanker:
    """é‡æ’åºå™¨"""

    def __init__(self, cross_encoder_model):
        self.model = cross_encoder_model

    def rerank(self, query, documents, top_k=3):
        """å¯¹æ£€ç´¢ç»“æœé‡æ’åº"""
        # 1. è®¡ç®—æ¯ä¸ªæ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§åˆ†æ•°
        pairs = [[query, doc] for doc in documents]
        scores = self.model.predict(pairs)

        # 2. æ’åº
        ranked_indices = sorted(
            range(len(scores)),
            key=lambda i: scores[i],
            reverse=True
        )

        # 3. è¿”å› Top-K
        return [documents[i] for i in ranked_indices[:top_k]]
```

**å®Œæ•´æµç¨‹**:

```
æŸ¥è¯¢:ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?
    â†“
åˆæ­¥æ£€ç´¢(æ··åˆ)â†’ è¿”å› 20 ä¸ªå€™é€‰æ–‡æ¡£
    â†“
é‡æ’åº(ç²¾ç¡®)â†’ è¿”å› Top 3 æœ€ç›¸å…³æ–‡æ¡£
    â†“
ç”Ÿæˆç­”æ¡ˆ
```

---

## 4. å‘é‡æ•°æ®åº“å®æˆ˜

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦å‘é‡æ•°æ®åº“?

#### ğŸ¤” é—®é¢˜åœºæ™¯

```python
# âŒ é—®é¢˜:åœ¨å†…å­˜ä¸­å­˜å‚¨å¤§é‡å‘é‡
embeddings = []  # 100ä¸‡ä¸ªå‘é‡
documents = []   # 100ä¸‡ä¸ªæ–‡æ¡£

# å ç”¨å†…å­˜:100ä¸‡ Ã— 768ç»´ Ã— 4å­—èŠ‚ â‰ˆ 3GB
# æ£€ç´¢é€Ÿåº¦:O(n) çº¿æ€§æœç´¢,éå¸¸æ…¢
```

#### âœ… å‘é‡æ•°æ®åº“çš„ä¼˜åŠ¿

1. **é«˜æ•ˆå­˜å‚¨**:å‹ç¼©ç®—æ³•,èŠ‚çœç©ºé—´
2. **å¿«é€Ÿæ£€ç´¢**:è¿‘ä¼¼æœ€è¿‘é‚»ç®—æ³•(ANN),äºšçº¿æ€§å¤æ‚åº¦
3. **å¯æ‰©å±•æ€§**:æ”¯æŒæµ·é‡æ•°æ®
4. **æŒä¹…åŒ–**:æ•°æ®ä¸ä¼šä¸¢å¤±

### 4.2 Chroma å‘é‡æ•°æ®åº“

#### ğŸš€ å¿«é€Ÿå¼€å§‹

```python
import chromadb
from chromadb.utils import embedding_functions

# 1. åˆ›å»ºå®¢æˆ·ç«¯
client = chromadb.Client()

# 2. åˆ›å»ºé›†åˆ(ç±»ä¼¼æ•°æ®åº“è¡¨)
collection = client.create_collection(
    name="my_knowledge_base",
    embedding_function=embedding_functions.DefaultEmbeddingFunction()
)

# 3. æ·»åŠ æ–‡æ¡£
collection.add(
    documents=[
        "é‡å­è®¡ç®—æ˜¯åˆ©ç”¨é‡å­åŠ›å­¦ç°è±¡è¿›è¡Œä¿¡æ¯å¤„ç†çš„è®¡ç®—æ–¹å¼",
        "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯"
    ],
    metadatas=[
        {"source": "wiki", "topic": "physics"},
        {"source": "wiki", "topic": "programming"},
        {"source": "wiki", "topic": "AI"}
    ],
    ids=["doc1", "doc2", "doc3"]
)

# 4. æŸ¥è¯¢
results = collection.query(
    query_texts=["ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?"],
    n_results=2
)

print("æ£€ç´¢ç»“æœ:", results['documents'][0])
print("ç›¸å…³æ€§:", results['distances'][0])
```

#### ğŸ’¡ é›†æˆåˆ° RAG ç³»ç»Ÿ

```python
class ChromaRAG:
    """åŸºäº Chroma çš„ RAG ç³»ç»Ÿ"""

    def __init__(self, llm, collection_name="knowledge_base"):
        self.llm = llm
        self.client = chromadb.Client()
        self.collection = self.client.get_or_create_collection(
            name=collection_name
        )

    def add_documents(self, documents, metadatas=None):
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“"""
        ids = [f"doc_{i}" for i in range(len(documents))]

        self.collection.add(
            documents=documents,
            metadatas=metadatas or [{}] * len(documents),
            ids=ids
        )

        print(f"âœ… å·²æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")

    def query(self, question, top_k=3):
        """RAG æŸ¥è¯¢"""
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        results = self.collection.query(
            query_texts=[question],
            n_results=top_k
        )

        relevant_docs = results['documents'][0]

        # 2. æ„å»ºæç¤ºè¯
        context = "\n\n".join(relevant_docs)
        prompt = f"""
        åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜:

        {context}

        é—®é¢˜:{question}
        ç­”æ¡ˆ:
        """

        # 3. ç”Ÿæˆå›ç­”
        answer = self.llm.generate(prompt)

        return {
            "answer": answer,
            "sources": relevant_docs,
            "metadata": results['metadatas'][0]
        }

    def delete(self, doc_id):
        """åˆ é™¤æ–‡æ¡£"""
        self.collection.delete(ids=[doc_id])

    def update(self, doc_id, new_document):
        """æ›´æ–°æ–‡æ¡£"""
        self.collection.update(
            ids=[doc_id],
            documents=[new_document]
        )
```

### 4.3 å…¶ä»–å‘é‡æ•°æ®åº“å¯¹æ¯”

| æ•°æ®åº“ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ | éƒ¨ç½²æ–¹å¼ |
|--------|------|----------|----------|
| **Chroma** | è½»é‡çº§ã€æ˜“ç”¨ | å¼€å‘åŸå‹ã€å°è§„æ¨¡ | æœ¬åœ°/åµŒå…¥å¼ |
| **Pinecone** | äº‘åŸç”Ÿã€é«˜æ€§èƒ½ | ç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡ | äº‘æœåŠ¡ |
| **Qdrant** | é«˜æ€§èƒ½ã€å¯æ‰©å±• | ä¸­å¤§å‹é¡¹ç›® | æœ¬åœ°/äº‘ç«¯ |
| **Milvus** | ä¼ä¸šçº§ã€åˆ†å¸ƒå¼ | å¤§è§„æ¨¡ç”Ÿäº§ | åˆ†å¸ƒå¼é›†ç¾¤ |
| **FAISS** | Meta å‡ºå“ã€æé€Ÿ | ç ”ç©¶å®éªŒ | çº¯å†…å­˜/æœ¬åœ° |

---

## 5. Memory ä½œä¸ºå·¥å…·é›†æˆ

### 5.1 Memory Tool è®¾è®¡

#### ğŸ¯ æ ¸å¿ƒæ€æƒ³

å°† Memory å½“ä½œ"å·¥å…·",è®© Agent ä¸»åŠ¨å†³å®šä½•æ—¶è¯»å†™è®°å¿†

```python
from hello_agents import Tool

class MemoryTool(Tool):
    """è®°å¿†å·¥å…·"""

    def __init__(self, memory_system):
        super().__init__(
            name="memory",
            description="ä¿å­˜å’Œæ£€ç´¢é•¿æœŸè®°å¿†"
        )
        self.memory = memory_system

    def get_parameters(self):
        return [
            ToolParameter(
                name="action",
                type="string",
                description="æ“ä½œç±»å‹:save(ä¿å­˜)æˆ– recall(æ£€ç´¢)",
                required=True
            ),
            ToolParameter(
                name="content",
                type="string",
                description="è¦ä¿å­˜çš„å†…å®¹æˆ–æ£€ç´¢çš„æŸ¥è¯¢",
                required=True
            )
        ]

    def run(self, parameters):
        """æ‰§è¡Œè®°å¿†æ“ä½œ"""
        action = parameters.get("action")
        content = parameters.get("content")

        if action == "save":
            # ä¿å­˜è®°å¿†
            self.memory.save(content)
            return f"âœ… å·²ä¿å­˜è®°å¿†: {content[:50]}..."

        elif action == "recall":
            # æ£€ç´¢è®°å¿†
            results = self.memory.recall(content, limit=3)
            if results:
                return f"ğŸ“š æ£€ç´¢åˆ° {len(results)} æ¡è®°å¿†:\n" + "\n".join(results)
            else:
                return "âŒ æœªæ‰¾åˆ°ç›¸å…³è®°å¿†"

        else:
            return f"âŒ æœªçŸ¥æ“ä½œ: {action}"
```

#### ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

```python
from hello_agents import ReActAgent, ToolRegistry

# 1. åˆ›å»ºè®°å¿†ç³»ç»Ÿ
memory = LongTermMemory(storage_path="agent_memory.db")

# 2. åˆ›å»ºè®°å¿†å·¥å…·
memory_tool = MemoryTool(memory)

# 3. æ³¨å†Œåˆ° Agent
registry = ToolRegistry()
registry.register_tool(memory_tool)

agent = ReActAgent(
    name="è®°å¿†åŠ©æ‰‹",
    llm=llm,
    tool_registry=registry
)

# 4. å¯¹è¯ä¸­è‡ªåŠ¨ä½¿ç”¨è®°å¿†
agent.run("è¯·è®°ä½,æˆ‘çš„ç”Ÿæ—¥æ˜¯ 1990å¹´1æœˆ1æ—¥")
# Agent å†…éƒ¨ä¼šè°ƒç”¨:memory_tool.run({"action": "save", "content": "ç”¨æˆ·ç”Ÿæ—¥: 1990-01-01"})

agent.run("æˆ‘çš„ç”Ÿæ—¥æ˜¯ä»€ä¹ˆæ—¶å€™?")
# Agent å†…éƒ¨ä¼šè°ƒç”¨:memory_tool.run({"action": "recall", "content": "ç”¨æˆ·ç”Ÿæ—¥"})
# è¿”å›:æ‚¨çš„ç”Ÿæ—¥æ˜¯ 1990å¹´1æœˆ1æ—¥
```

### 5.2 RAG Tool è®¾è®¡

```python
class RAGTool(Tool):
    """RAG æ£€ç´¢å·¥å…·"""

    def __init__(self, rag_system):
        super().__init__(
            name="knowledge_search",
            description="ä»çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯"
        )
        self.rag = rag_system

    def get_parameters(self):
        return [
            ToolParameter(
                name="query",
                type="string",
                description="è¦æœç´¢çš„é—®é¢˜æˆ–å…³é”®è¯",
                required=True
            ),
            ToolParameter(
                name="top_k",
                type="integer",
                description="è¿”å›ç»“æœæ•°é‡(é»˜è®¤3)",
                required=False,
                default=3
            )
        ]

    def run(self, parameters):
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢"""
        query = parameters.get("query")
        top_k = parameters.get("top_k", 3)

        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = self.rag.retrieve(query, top_k=top_k)

        if not docs:
            return "âŒ æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

        # æ ¼å¼åŒ–è¿”å›
        result = f"ğŸ“š æ‰¾åˆ° {len(docs)} æ¡ç›¸å…³ä¿¡æ¯:\n\n"
        for i, doc in enumerate(docs, 1):
            result += f"{i}. {doc[:200]}...\n\n"

        return result
```

### 5.3 å®Œæ•´ç¤ºä¾‹:Agent with Memory & RAG

```python
from hello_agents import ReActAgent, HelloAgentsLLM, ToolRegistry

# 1. åˆå§‹åŒ–ç»„ä»¶
llm = HelloAgentsLLM()
short_term_memory = ShortTermMemory(max_messages=20)
long_term_memory = LongTermMemory(storage_path="memory.db")
rag_system = ChromaRAG(llm, collection_name="docs")

# 2. æ·»åŠ çŸ¥è¯†åˆ° RAG
rag_system.add_documents([
    "å…¬å¸æ”¿ç­–:å‘˜å·¥å¯äº«å—å¹´å‡15å¤©",
    "å…¬å¸åœ°å€:åŒ—äº¬å¸‚æœé˜³åŒºxxxå¤§å¦",
    "å·¥ä½œæ—¶é—´:å‘¨ä¸€è‡³å‘¨äº” 9:00-18:00"
])

# 3. åˆ›å»ºå·¥å…·
memory_tool = MemoryTool(long_term_memory)
rag_tool = RAGTool(rag_system)

# 4. åˆ›å»º Agent
registry = ToolRegistry()
registry.register_tool(memory_tool)
registry.register_tool(rag_tool)

agent = ReActAgent(
    name="æ™ºèƒ½åŠ©æ‰‹",
    llm=llm,
    tool_registry=registry,
    memory=short_term_memory  # æ·»åŠ çŸ­æœŸè®°å¿†
)

# 5. å¤šè½®å¯¹è¯
print("=== ç¬¬1è½® ===")
response1 = agent.run("å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯ä»€ä¹ˆ?")
# Agent ä¼šè°ƒç”¨ knowledge_search å·¥å…·æ£€ç´¢
print(response1)

print("\n=== ç¬¬2è½® ===")
response2 = agent.run("å¸®æˆ‘è®°ä½,æˆ‘æ‰“ç®—åœ¨7æœˆä¼‘å¹´å‡")
# Agent ä¼šè°ƒç”¨ memory å·¥å…·ä¿å­˜
print(response2)

print("\n=== ç¬¬3è½® ===")
response3 = agent.run("æˆ‘ä¹‹å‰è¯´çš„ä¼‘å‡è®¡åˆ’æ˜¯ä»€ä¹ˆ?")
# Agent ä¼šä»çŸ­æœŸè®°å¿†ä¸­æ‰¾åˆ°ä¹‹å‰çš„å¯¹è¯
# æˆ–è°ƒç”¨ memory å·¥å…·æ£€ç´¢é•¿æœŸè®°å¿†
print(response3)
```

**æ‰§è¡Œæµç¨‹å¯è§†åŒ–**:

```
ç”¨æˆ·:å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯ä»€ä¹ˆ?
    â†“
Agent æ€è€ƒ:éœ€è¦æŸ¥è¯¢å…¬å¸æ”¿ç­–
    â†“
è°ƒç”¨ knowledge_search("å¹´å‡æ”¿ç­–")
    â†“
RAG ç³»ç»Ÿæ£€ç´¢ â†’ "å‘˜å·¥å¯äº«å—å¹´å‡15å¤©"
    â†“
Agent å›ç­”:æ ¹æ®å…¬å¸æ”¿ç­–,å‘˜å·¥å¯äº«å—å¹´å‡15å¤©

ç”¨æˆ·:å¸®æˆ‘è®°ä½,æˆ‘æ‰“ç®—åœ¨7æœˆä¼‘å¹´å‡
    â†“
Agent æ€è€ƒ:ç”¨æˆ·è¦ä¿å­˜ä¿¡æ¯
    â†“
è°ƒç”¨ memory.save("ç”¨æˆ·è®¡åˆ’7æœˆä¼‘å¹´å‡")
    â†“
ç¡®è®¤:âœ… å·²ä¿å­˜

ç”¨æˆ·:æˆ‘ä¹‹å‰è¯´çš„ä¼‘å‡è®¡åˆ’æ˜¯ä»€ä¹ˆ?
    â†“
Agent æ€è€ƒ:éœ€è¦æ£€ç´¢ä¹‹å‰çš„è®°å½•
    â†“
æ–¹æ¡ˆ1:æŸ¥çœ‹çŸ­æœŸè®°å¿†(å¯¹è¯å†å²)
æ–¹æ¡ˆ2:è°ƒç”¨ memory.recall("ä¼‘å‡è®¡åˆ’")
    â†“
Agent å›ç­”:æ‚¨ä¹‹å‰è¯´æ‰“ç®—åœ¨7æœˆä¼‘å¹´å‡
```

---

## 6. æœ¬ç« æ€»ç»“

### ğŸ¯ ä½ å­¦åˆ°äº†ä»€ä¹ˆ?

#### 1. è®°å¿†ç³»ç»Ÿä¸‰å±‚æ¶æ„

```
çŸ­æœŸè®°å¿†(å¯¹è¯ä¸Šä¸‹æ–‡)
   â”œâ”€â”€ æ»‘åŠ¨çª—å£ç­–ç•¥
   â”œâ”€â”€ é‡è¦æ€§é‡‡æ ·
   â””â”€â”€ æ‘˜è¦å‹ç¼©

é•¿æœŸè®°å¿†(çŸ¥è¯†å­˜å‚¨)
   â”œâ”€â”€ æ•°æ®åº“æŒä¹…åŒ–
   â”œâ”€â”€ å‘é‡æ£€ç´¢
   â””â”€â”€ å…³é”®è¯ç´¢å¼•

ä¸ªæ€§åŒ–è®°å¿†(ç”¨æˆ·ç”»åƒ)
   â”œâ”€â”€ åå¥½è®°å½•
   â”œâ”€â”€ äº¤äº’å†å²
   â””â”€â”€ ä¸Šä¸‹æ–‡ä¿¡æ¯
```

#### 2. RAG æ ¸å¿ƒæµç¨‹

```
æ–‡æ¡£ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ å­˜å‚¨
                      â†“
ç”¨æˆ·æŸ¥è¯¢ â†’ å‘é‡åŒ– â†’ æ£€ç´¢ â†’ Top-Kæ–‡æ¡£
                           â†“
                    æ„å»ºæç¤ºè¯ â†’ LLMç”Ÿæˆ â†’ ç­”æ¡ˆ
```

#### 3. æŠ€æœ¯æ ˆé€‰æ‹©

| ç»„ä»¶ | æ¨èæ–¹æ¡ˆ | å¤‡é€‰æ–¹æ¡ˆ |
|------|----------|----------|
| **Embedding** | OpenAI text-embedding-ada-002 | sentence-transformers |
| **å‘é‡æ•°æ®åº“** | Chroma(å¼€å‘), Pinecone(ç”Ÿäº§) | Qdrant, Milvus |
| **æ£€ç´¢ç®—æ³•** | æ··åˆæ£€ç´¢(å‘é‡+BM25) | çº¯å‘é‡æ£€ç´¢ |
| **ä¼˜åŒ–ç­–ç•¥** | é‡æ’åº | - |

### ğŸ“ˆ Memory vs RAG å¯¹æ¯”

| ç»´åº¦ | Memory(è®°å¿†) | RAG(æ£€ç´¢) |
|-----|---------------|------------|
| **ç”¨é€”** | è®°ä½å¯¹è¯å†å²å’Œç”¨æˆ·ä¿¡æ¯ | æ£€ç´¢å¤–éƒ¨çŸ¥è¯† |
| **æ•°æ®æ¥æº** | å¯¹è¯è¿‡ç¨‹ä¸­ç”Ÿæˆ | é¢„å…ˆå‡†å¤‡çš„æ–‡æ¡£åº“ |
| **æ›´æ–°é¢‘ç‡** | å®æ—¶æ›´æ–° | å®šæœŸæ‰¹é‡æ›´æ–° |
| **å­˜å‚¨æ–¹å¼** | åˆ—è¡¨/æ•°æ®åº“ | å‘é‡æ•°æ®åº“ |
| **æ£€ç´¢æ–¹å¼** | æ—¶é—´é¡ºåº/å…³é”®è¯ | è¯­ä¹‰ç›¸ä¼¼åº¦ |
| **å…¸å‹åœºæ™¯** | "è®°ä½æˆ‘çš„åå¥½" | "æŸ¥æ‰¾ç›¸å…³æ–‡æ¡£" |

### ğŸš€ å®æˆ˜å»ºè®®

#### å¯¹äºåˆå­¦è€…

1. âœ… **ä»ç®€å•å¼€å§‹**
   ```python
   # å…ˆå®ç°ä¸€ä¸ªç®€å•çš„åˆ—è¡¨è®°å¿†
   memory = []
   memory.append("ç”¨æˆ·å–œæ¬¢Python")
   ```

2. âœ… **ç†è§£æ ¸å¿ƒæ¦‚å¿µ**
   - ä»€ä¹ˆæ˜¯å‘é‡?(æ•°å­—è¡¨ç¤ºçš„è¯­ä¹‰)
   - ä»€ä¹ˆæ˜¯ç›¸ä¼¼åº¦?(å‘é‡ä¹‹é—´çš„è·ç¦»)
   - ä»€ä¹ˆæ˜¯æ£€ç´¢?(æ‰¾åˆ°æœ€ç›¸ä¼¼çš„)

3. âœ… **è·‘é€šå®Œæ•´æµç¨‹**
   - ä½¿ç”¨ Chroma åšä¸€ä¸ªç®€å• RAG
   - ä½“éªŒæ£€ç´¢æ•ˆæœ

#### å¯¹äºè¿›é˜¶è€…

1. âœ… **ä¼˜åŒ–æ£€ç´¢è´¨é‡**
   - è°ƒæ•´åˆ†å—å¤§å°å’Œé‡å 
   - å°è¯•ä¸åŒçš„ Embedding æ¨¡å‹
   - å®ç°æ··åˆæ£€ç´¢

2. âœ… **æå‡ç³»ç»Ÿæ€§èƒ½**
   - ä½¿ç”¨ GPU åŠ é€Ÿ Embedding
   - ä¼˜åŒ–å‘é‡ç´¢å¼•ç»“æ„
   - å®ç°ç»“æœç¼“å­˜

3. âœ… **å¤„ç†å®é™…é—®é¢˜**
   - å¤šè¯­è¨€æ–‡æ¡£å¤„ç†
   - å¤§è§„æ¨¡æ•°æ®ç´¢å¼•
   - å®æ—¶æ›´æ–°ç­–ç•¥

#### å¯¹äºä¸“ä¸šå¼€å‘è€…

1. âœ… **ç”Ÿäº§çº§éƒ¨ç½²**
   - ä½¿ç”¨ Pinecone/Qdrant äº‘æœåŠ¡
   - å®ç°åˆ†å¸ƒå¼ç´¢å¼•
   - æ·»åŠ ç›‘æ§å’Œæ—¥å¿—

2. âœ… **é«˜çº§ä¼˜åŒ–**
   - è‡ªè®­ç»ƒ Embedding æ¨¡å‹
   - å®ç° Hypothetical Document Embeddings (HyDE)
   - å¤šæ¨¡æ€æ£€ç´¢(æ–‡æœ¬+å›¾ç‰‡)

3. âœ… **ç³»ç»Ÿé›†æˆ**
   - ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ
   - æ„å»ºçŸ¥è¯†ç®¡ç†å¹³å°
   - å®ç°æ™ºèƒ½å®¢æœç³»ç»Ÿ

### ğŸ’¡ å¸¸è§é—®é¢˜ FAQ

#### Q1: å‘é‡æ•°æ®åº“å’Œä¼ ç»Ÿæ•°æ®åº“æœ‰ä»€ä¹ˆåŒºåˆ«?

**ä¼ ç»Ÿæ•°æ®åº“**:
```sql
SELECT * FROM docs WHERE title = 'é‡å­è®¡ç®—'
```
- ç²¾ç¡®åŒ¹é…
- æ— æ³•ç†è§£è¯­ä¹‰

**å‘é‡æ•°æ®åº“**:
```python
search("ä»€ä¹ˆæ˜¯é‡å­?")
# èƒ½æ‰¾åˆ°"é‡å­è®¡ç®—"ã€"é‡å­åŠ›å­¦"ç­‰ç›¸å…³æ–‡æ¡£
```
- è¯­ä¹‰ç›¸ä¼¼
- æ¨¡ç³ŠåŒ¹é…

#### Q2: å¦‚ä½•é€‰æ‹©åˆé€‚çš„ Embedding æ¨¡å‹?

```
å°é¡¹ç›®(<10ä¸‡æ–‡æ¡£):
  â†’ sentence-transformers/all-MiniLM-L6-v2
  â†’ å¿«é€Ÿã€å…è´¹

ä¸­å‹é¡¹ç›®(10-100ä¸‡æ–‡æ¡£):
  â†’ OpenAI text-embedding-ada-002
  â†’ è´¨é‡å¥½ã€æˆæœ¬å¯æ§

å¤§å‹é¡¹ç›®(>100ä¸‡æ–‡æ¡£):
  â†’ è‡ªè®­ç»ƒé¢†åŸŸæ¨¡å‹
  â†’ é’ˆå¯¹ç‰¹å®šé¢†åŸŸä¼˜åŒ–
```

#### Q3: RAG æ£€ç´¢æ•ˆæœä¸å¥½æ€ä¹ˆåŠ?

**è¯Šæ–­æ­¥éª¤**:

1. **æ£€æŸ¥åˆ†å—è´¨é‡**
   ```python
   # æ‰“å°å‡ ä¸ª chunk çœ‹çœ‹
   for chunk in chunks[:5]:
       print(chunk)
       print("---")
   ```

2. **æ£€æŸ¥æ£€ç´¢ç»“æœ**
   ```python
   results = retrieve("æŸ¥è¯¢è¯")
   print("æ˜¯å¦åŒ…å«ç›¸å…³ä¿¡æ¯?", results)
   ```

3. **è°ƒæ•´å‚æ•°**
   ```python
   # å¢åŠ æ£€ç´¢æ•°é‡
   results = retrieve(query, top_k=10)

   # å°è¯•ä¸åŒçš„ chunk_size
   chunker = Chunker(chunk_size=300)  # é»˜è®¤500
   ```

#### Q4: Memory å’Œ RAG å¦‚ä½•é…åˆä½¿ç”¨?

```python
# çŸ­æœŸè®°å¿†:å½“å‰å¯¹è¯
short_memory = [
    "ç”¨æˆ·:æˆ‘æƒ³äº†è§£é‡å­è®¡ç®—",
    "åŠ©æ‰‹:å¥½çš„,è®©æˆ‘æŸ¥æ‰¾ç›¸å…³èµ„æ–™"
]

# é•¿æœŸè®°å¿†:ç”¨æˆ·ç”»åƒ
long_memory = {
    "interests": ["ç‰©ç†", "ç¼–ç¨‹"],
    "skill_level": "ä¸­çº§"
}

# RAG:çŸ¥è¯†åº“æ£€ç´¢
rag_docs = retrieve("é‡å­è®¡ç®—", user_profile=long_memory)

# ç»¼åˆç”Ÿæˆç­”æ¡ˆ
context = {
    "recent_chat": short_memory,
    "user_profile": long_memory,
    "knowledge": rag_docs
}
answer = llm.generate_with_context(context)
```

### ğŸ”— ç›¸å…³èµ„æº

- **GitHub ä»“åº“**: https://github.com/jjyaoao/helloagents
- **Chroma æ–‡æ¡£**: https://docs.trychroma.com/
- **LangChain RAG æ•™ç¨‹**: https://python.langchain.com/docs/use_cases/question_answering/
- **Sentence Transformers**: https://www.sbert.net/

---

## ğŸ“ å¿«é€Ÿå‚è€ƒ

### å®‰è£…ä¾èµ–

```bash
# åŸºç¡€åŒ…
pip install "hello-agents==0.1.1"

# å‘é‡æ•°æ®åº“
pip install chromadb

# Embedding æ¨¡å‹
pip install sentence-transformers

# å¯é€‰:BM25æ£€ç´¢
pip install rank-bm25
```

### æœ€å° Memory ç¤ºä¾‹

```python
from hello_agents import ShortTermMemory

memory = ShortTermMemory(max_messages=10)
memory.add_message("user", "æˆ‘å«å°æ˜")
memory.add_message("assistant", "ä½ å¥½,å°æ˜!")

print(memory.get_messages())
```

### æœ€å° RAG ç¤ºä¾‹

```python
import chromadb

client = chromadb.Client()
collection = client.create_collection("my_docs")

# æ·»åŠ æ–‡æ¡£
collection.add(
    documents=["Pythonæ˜¯ç¼–ç¨‹è¯­è¨€", "æœºå™¨å­¦ä¹ æ˜¯AIåˆ†æ”¯"],
    ids=["doc1", "doc2"]
)

# æŸ¥è¯¢
results = collection.query(
    query_texts=["ä»€ä¹ˆæ˜¯Python?"],
    n_results=1
)
print(results['documents'])
```

### é›†æˆåˆ° Agent

```python
from hello_agents import ReActAgent, ToolRegistry

# åˆ›å»º Memory å’Œ RAG å·¥å…·
memory_tool = MemoryTool(memory_system)
rag_tool = RAGTool(rag_system)

# æ³¨å†Œåˆ° Agent
registry = ToolRegistry()
registry.register_tool(memory_tool)
registry.register_tool(rag_tool)

agent = ReActAgent(llm=llm, tool_registry=registry)
```

---

## ğŸ“ ç« èŠ‚ä¹ é¢˜æç¤º

1. **Memory ç­–ç•¥å¯¹æ¯”**:å®ç°ä¸‰ç§è®°å¿†ç®¡ç†ç­–ç•¥,å¯¹æ¯”æ•ˆæœ
2. **RAG ç³»ç»Ÿæ­å»º**:ä»é›¶æ­å»ºä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿ
3. **æ··åˆæ£€ç´¢å®è·µ**:å®ç°å‘é‡æ£€ç´¢ + BM25 çš„æ··åˆæ£€ç´¢
4. **å‘é‡æ•°æ®åº“é€‰å‹**:å¯¹æ¯” Chromaã€Pineconeã€Qdrant çš„æ€§èƒ½
5. **å®æˆ˜é¡¹ç›®**:æ„å»ºä¸€ä¸ªå¸¦è®°å¿†çš„å®¢æœ Agent

---

## ğŸ“Œ æ ¸å¿ƒè¦ç‚¹å›é¡¾

```
ğŸ§  ä¸ºä»€ä¹ˆéœ€è¦è®°å¿†?
   â†’ ä¿æŒå¯¹è¯è¿è´¯ + å­¦ä¹ ç”¨æˆ·åå¥½ + æ‰©å±•çŸ¥è¯†è¾¹ç•Œ

ğŸ“ ä¸‰ç§è®°å¿†ç±»å‹
   â†’ çŸ­æœŸ(å¯¹è¯) + é•¿æœŸ(çŸ¥è¯†) + ä¸ªæ€§åŒ–(ç”»åƒ)

ğŸ” RAG æ ¸å¿ƒæµç¨‹
   â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ å­˜å‚¨ â†’ æ£€ç´¢ â†’ ç”Ÿæˆ

ğŸ—„ï¸ å‘é‡æ•°æ®åº“
   â†’ é«˜æ•ˆå­˜å‚¨ + å¿«é€Ÿæ£€ç´¢ + å¯æ‰©å±•

ğŸ”§ å·¥å…·åŒ–é›†æˆ
   â†’ Memory Tool + RAG Tool â†’ Agent ä¸»åŠ¨ä½¿ç”¨
```

---

**ä¸‹ä¸€ç« é¢„å‘Š**:ç¬¬ä¹ç« å°†æ¢è®¨ä¸Šä¸‹æ–‡å·¥ç¨‹,å­¦ä¹ å¦‚ä½•ä¼˜åŒ–æç¤ºè¯ã€ç®¡ç† Token æ¶ˆè€—ã€å®ç°é«˜æ•ˆçš„ä¸Šä¸‹æ–‡ç­–ç•¥!

**Happy Learning! ğŸš€**
