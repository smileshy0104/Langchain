# 第一章《初识智能体》通俗总结

面向刚接触智能体的同学，这份笔记把 Datawhale《Hello-Agents》第一章拆成 5 个关键问题，帮助你快速建立整体概念，并配上易懂的例子。

## 1. 智能体到底是什么？
- **最简定义**：能用传感器感知环境、自己做决策、再通过执行器改变环境的“实体”。自动驾驶车、交易机器人、智能客服都算。
- **核心特征**：和环境形成“感知 → 思考 → 行动”的闭环，而且具有自主性，不是死板执行脚本。
- **传统范式的演进**：
  1. *反射式*：恒温器式的 IF-THEN 规则。
  2. *模型式*：有内部世界模型，能“记住”环境，比如车在隧道中仍能推测前车位置。
  3. *基于目标/效用*：会规划未来状态、权衡多目标，类似导航系统。
  4. *学习型*：通过强化学习等方式自我改进，AlphaGo Zero 就是代表。
- **LLM 驱动的新范式**：预训练模型提供通用知识和推理力，可直接理解自然语言目标、拆分任务、用工具补信息、根据反馈调整计划。我们不再写死规则，而是让“大脑”自主策划。

## 2. 如何描述和分析一个智能体的任务环境？
- **PEAS 模型**：Performance（绩效指标）、Environment（环境）、Actuators（执行器）、Sensors（传感器）。比如旅行助手：绩效是“推荐准确度+用户满意度”，环境是天气/票务/景点 API，执行器是各类工具调用，传感器是 API/用户输入。
- **常见环境特性**：
  - 部分可观察：一次 API 只能拿到部分信息，因此要有记忆和探索。
  - 随机：机票价格常变，智能体要能处理不确定性。
  - 多智能体：其他用户或系统也在改变环境状态。
  - 序贯且动态：当前决策会影响后续，环境也会随时间变。

## 3. 智能体循环与 Thought-Action-Observation 规范
- **Agent Loop 三步走**：
  1. 感知：收集 Observation（用户提问、工具结果）。
  2. 思考：LLM 做推理与规划，决定下一步策略。
  3. 行动：调用工具或输出答案，环境状态发生变化。
- **为什么要结构化输出？** 为了让 LLM 的自然语言推理能驱动真实工具，通常要求模型按格式输出：
  ```text
  Thought: 解释当前分析与计划
  Action: function_name(arg="...")
  ```
  工具执行后把结果转成 `Observation: ...` 再喂回模型，形成稳定闭环。

## 4. 5 分钟旅行助手实战
- **工具层**：`get_weather` 用 wttr.in 查询天气，`get_attraction` 用 Tavily 搜索景点，并注册到 `available_tools` 字典。
- **模型层**：自定义 `AGENT_SYSTEM_PROMPT` 告诉 LLM 它的角色、工具和输出格式；`OpenAICompatibleClient` 统一适配任何兼容 OpenAI API 的模型（官方、Azure、Ollama 等）。
- **主循环**：
  1. 维护 `prompt_history`，每轮把 Thought/Action/Observation 拼接成新的 prompt。
  2. 用正则截取第一组 Thought-Action，解析函数名和参数。
  3. 调用工具，拿到 Observation；若 Action 是 `finish(answer="...")` 就结束。
- **效果**：示例中 3 轮就完成“查天气→基于天气推荐→总结回复”，展示了任务拆解、工具调用、上下文记忆和结果合成四大能力。

## 5. 协作模式与 Workflow 对比
- **智能体作为工具**：GitHub Copilot、Claude Code、Trae、Cursor 等把 AI 镶进开发流程，帮你自动补全、编辑、调试，但最终决策仍在人。
- **智能体作为协作者**：把高层目标交给 Agent，由它规划、执行、反思，甚至多智能体协作（BabyAGI、AutoGPT、CrewAI、MetaGPT、AutoGen、AgentScope、LangGraph 等），更像虚拟团队成员。
- **Workflow vs Agent**：
  - Workflow 是写死的流程图，适合固定规则（如报销审批）。
  - Agent 是目标导向的自主演员，会根据实时信息动态规划。旅行助手例子中，没有“晴天就推颐和园”的硬编码，只是根据工具反馈即时推理。

## 6. 延伸思考（选做）
- 用 PEAS 描述你心目中的“智能健身教练”，看看环境有多复杂。
- 比较电商退款用固定 Workflow 与 Agent 决策的优缺点，有没有折中方案？
- 给旅行助手加“记忆”“备选方案”“反思”会用到哪些新的状态管理技巧？
- 结合卡尼曼系统1/系统2，设计一个医疗或风控场景，思考直觉模块与推理模块如何协作。
- 为什么 LLM Agent 会产生“幻觉”？没有循环次数上限会产生什么风险？除了准确率，还能怎样评估智能体的“聪明程度”？

---
如果需要把这份总结扩展成幻灯片或进一步细化代码实现，可以在此基础上继续补充示例和图示。
