# LangChain Agents è¯¦ç»†æ€»ç»“

> åŸºäºå®˜æ–¹æ–‡æ¡£ https://docs.langchain.com/oss/python/langchain/agents çš„å®Œæ•´ä¸­æ–‡æ€»ç»“

---

## ğŸ“‹ ç›®å½•

- [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
- [create_agent è¯¦è§£](#create_agent-è¯¦è§£)
- [å·¥å…·ï¼ˆToolsï¼‰](#å·¥å…·tools)
- [ä¸­é—´ä»¶ï¼ˆMiddlewareï¼‰](#ä¸­é—´ä»¶middleware)
- [çŸ­æœŸè®°å¿†ï¼ˆShort-term Memoryï¼‰](#çŸ­æœŸè®°å¿†short-term-memory)
- [ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆContext Engineeringï¼‰](#ä¸Šä¸‹æ–‡å·¥ç¨‹context-engineering)
- [äººæœºåä½œï¼ˆHuman-in-the-Loopï¼‰](#äººæœºåä½œhuman-in-the-loop)
- [ç»“æ„åŒ–è¾“å‡º](#ç»“æ„åŒ–è¾“å‡º)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Agentï¼Ÿ

**å®šä¹‰**: Agents å°†è¯­è¨€æ¨¡å‹ä¸å·¥å…·ç»“åˆï¼Œåˆ›å»ºèƒ½å¤Ÿæ¨ç†ä»»åŠ¡ã€å†³å®šä½¿ç”¨å“ªäº›å·¥å…·å¹¶è¿­ä»£åœ°æœç€è§£å†³æ–¹æ¡ˆåŠªåŠ›çš„ç³»ç»Ÿã€‚

**æ ¸å¿ƒç‰¹å¾**:
- LLM Agent åœ¨å¾ªç¯ä¸­è¿è¡Œå·¥å…·ä»¥å®ç°ç›®æ ‡
- Agent æŒç»­è¿è¡Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ï¼ˆæ¨¡å‹è¾“å‡ºæœ€ç»ˆç­”æ¡ˆæˆ–è¾¾åˆ°è¿­ä»£é™åˆ¶ï¼‰

### Agent æ‰§è¡Œæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è¾“å…¥æŸ¥è¯¢   â”‚
â”‚   (input)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ¨¡å‹æ¨ç†   â”‚
â”‚   (model)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â†’ action â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚  å·¥å…·æ‰§è¡Œ    â”‚
       â”‚               â”‚  (tools)    â”‚
       â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â”‚ â†â”€â”€â”€ observation â”€â”€â”€â”€â”˜
       â”‚
       â”‚ (å¾ªç¯ç»§ç»­ç›´åˆ°å®Œæˆ)
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æœ€ç»ˆè¾“å‡º   â”‚
â”‚   (output)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ‰§è¡Œæ­¥éª¤**:
1. **è¾“å…¥** â†’ ç”¨æˆ·æŸ¥è¯¢è¿›å…¥ Agent
2. **æ¨¡å‹** â†’ LLM åˆ†æå¹¶å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
3. **å·¥å…·** â†’ æ‰§è¡Œå·¥å…·å¹¶è¿”å›è§‚å¯Ÿç»“æœï¼ˆobservationï¼‰
4. **å¾ªç¯** â†’ æ¨¡å‹æ ¹æ®è§‚å¯Ÿç»“æœç»§ç»­æ¨ç†
5. **å®Œæˆ** â†’ æ¨¡å‹è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ

### åŸºäºå›¾çš„æ¶æ„

`create_agent` æ„å»ºåŸºäº **LangGraph** çš„å›¾çŠ¶è¿è¡Œæ—¶ï¼š

**å›¾çš„ç»„æˆ**:
- **èŠ‚ç‚¹ï¼ˆNodesï¼‰**: æ‰§è¡Œæ­¥éª¤
  - `model` èŠ‚ç‚¹: è°ƒç”¨æ¨¡å‹
  - `tools` èŠ‚ç‚¹: æ‰§è¡Œå·¥å…·
  - ä¸­é—´ä»¶èŠ‚ç‚¹: è‡ªå®šä¹‰é€»è¾‘
- **è¾¹ï¼ˆEdgesï¼‰**: è¿æ¥ï¼Œå®šä¹‰ä¿¡æ¯æµ

**ä¼˜åŠ¿**:
- å¯è§†åŒ–æ‰§è¡Œæµç¨‹
- çµæ´»çš„æ§åˆ¶æµ
- æŒä¹…åŒ–æ‰§è¡ŒçŠ¶æ€
- æ”¯æŒå¤æ‚çš„æ¡ä»¶é€»è¾‘

---

## create_agent è¯¦è§£

### åŸºç¡€ç”¨æ³•

`create_agent` æ˜¯ **LangChain v1.0** æ„å»º Agent çš„æ ‡å‡†æ–¹å¼ã€‚

**æœ€ç®€ç¤ºä¾‹**:
```python
from langchain.agents import create_agent
from langchain_anthropic import ChatAnthropic

# å®šä¹‰å·¥å…·
from langchain_core.tools import tool

@tool
def get_weather(location: str) -> str:
    """è·å–æŒ‡å®šä½ç½®çš„å¤©æ°”ä¿¡æ¯"""
    return f"{location} çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œæ¸©åº¦ 20Â°C"

# åˆ›å»º Agent
model = ChatAnthropic(model="claude-3-5-sonnet-20241022")
agent = create_agent(
    model=model,
    tools=[get_weather],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹"
)

# æ‰§è¡Œ
result = agent.invoke({
    "messages": [{"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}]
})

print(result["messages"][-1]["content"])
# è¾“å‡º: åŒ—äº¬çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œæ¸©åº¦ 20Â°C
```

### æ ¸å¿ƒå‚æ•°

#### 1. `model` - æ¨¡å‹é…ç½®

**ç±»å‹**: `BaseChatModel` æˆ– å­—ç¬¦ä¸²

**æ”¯æŒçš„æ¨¡å‹**:
```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# æ–¹å¼ 1: ç›´æ¥ä¼ å…¥æ¨¡å‹å®ä¾‹
model = ChatAnthropic(model="claude-3-5-sonnet-20241022")

# æ–¹å¼ 2: ä¼ å…¥æ¨¡å‹åç§°ï¼ˆç®€å†™ï¼‰
agent = create_agent(
    model="claude-sonnet-4-5-20250929",  # ç®€åŒ–å†™æ³•
    tools=tools
)

# æ–¹å¼ 3: ä½¿ç”¨ä¸åŒæä¾›å•†
models = [
    ChatOpenAI(model="gpt-4o"),
    ChatAnthropic(model="claude-3-5-sonnet-20241022"),
    ChatGoogleGenerativeAI(model="gemini-pro")
]
```

**åŠ¨æ€æ¨¡å‹é€‰æ‹©** (é€šè¿‡ä¸­é—´ä»¶):
```python
from langchain.agents.middleware import wrap_model_call
from langchain_openai import ChatOpenAI

basic_model = ChatOpenAI(model="gpt-4o-mini")
advanced_model = ChatOpenAI(model="gpt-4o")

@wrap_model_call
def dynamic_model_selection(request, handler):
    """æ ¹æ®å¯¹è¯å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
    message_count = len(request.messages)

    if message_count > 10:
        request = request.override(model=advanced_model)
    else:
        request = request.override(model=basic_model)

    return handler(request)

agent = create_agent(
    model="gpt-4o-mini",
    tools=tools,
    middleware=[dynamic_model_selection]
)
```

#### 2. `tools` - å·¥å…·åˆ—è¡¨

**ç±»å‹**: `List[BaseTool]`

**å®šä¹‰å·¥å…·çš„æ–¹å¼**:

**æ–¹å¼ 1: ä½¿ç”¨ `@tool` è£…é¥°å™¨**
```python
from langchain_core.tools import tool
from pydantic import BaseModel, Field

class SearchInput(BaseModel):
    """æœç´¢è¾“å…¥å‚æ•°"""
    query: str = Field(description="æœç´¢æŸ¥è¯¢è¯")
    limit: int = Field(default=10, description="è¿”å›ç»“æœæ•°é‡")

@tool(args_schema=SearchInput)
def search_web(query: str, limit: int = 10) -> str:
    """
    åœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯

    Args:
        query: æœç´¢å…³é”®è¯
        limit: æœ€å¤šè¿”å›å¤šå°‘æ¡ç»“æœ

    Returns:
        æœç´¢ç»“æœæ‘˜è¦
    """
    # å®ç°æœç´¢é€»è¾‘
    return f"æ‰¾åˆ° {limit} æ¡å…³äº '{query}' çš„ç»“æœ"

tools = [search_web]
```

**æ–¹å¼ 2: ä» Retriever åˆ›å»ºå·¥å…·**
```python
from langchain_classic.tools.retriever import create_retriever_tool

retriever_tool = create_retriever_tool(
    retriever=vectorstore.as_retriever(),
    name="search_docs",
    description="æœç´¢æ–‡æ¡£åº“ä»¥è·å–ç›¸å…³ä¿¡æ¯"
)

tools = [retriever_tool]
```

#### 3. `system_prompt` - ç³»ç»Ÿæç¤ºè¯

**ç±»å‹**: `str` (å¯é€‰)

**ä½œç”¨**: è®¾ç½® Agent çš„è¡Œä¸ºå’Œèƒ½åŠ›

**é™æ€æç¤ºè¯**:
```python
agent = create_agent(
    model=model,
    tools=tools,
    system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ã€‚

# æ ¸å¿ƒèƒ½åŠ›
- æ•°æ®æŸ¥è¯¢å’Œåˆ†æ
- ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
- æä¾›ä¸šåŠ¡æ´å¯Ÿ

# å·¥ä½œæµç¨‹
1. ç†è§£ç”¨æˆ·éœ€æ±‚
2. é€‰æ‹©åˆé€‚çš„å·¥å…·
3. åˆ†ææ•°æ®ç»“æœ
4. ç”Ÿæˆæ¸…æ™°çš„æŠ¥å‘Š

# é™åˆ¶
- ä¸è¦ç¼–é€ æ•°æ®
- ä¸ç¡®å®šæ—¶æ˜ç¡®è¯´æ˜
- è¶…å‡ºèƒ½åŠ›èŒƒå›´æ—¶å»ºè®®äººå·¥ä»‹å…¥
"""
)
```

**åŠ¨æ€æç¤ºè¯** (é€šè¿‡ä¸­é—´ä»¶):
```python
from langchain.agents.middleware import dynamic_prompt, ModelRequest
from dataclasses import dataclass

@dataclass
class Context:
    user_role: str

@dynamic_prompt
def user_role_prompt(request: ModelRequest) -> str:
    """æ ¹æ®ç”¨æˆ·è§’è‰²ç”Ÿæˆç³»ç»Ÿæç¤º"""
    user_role = request.runtime.context.get("user_role", "user")
    base_prompt = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"

    if user_role == "expert":
        return f"{base_prompt} æä¾›è¯¦ç»†çš„æŠ€æœ¯å“åº”ã€‚"
    elif user_role == "beginner":
        return f"{base_prompt} ç®€å•è§£é‡Šæ¦‚å¿µï¼Œé¿å…æœ¯è¯­ã€‚"

    return base_prompt

agent = create_agent(
    model="gpt-4o",
    tools=[search_web],
    middleware=[user_role_prompt],
    context_schema=Context
)

# ä½¿ç”¨æ—¶ä¼ å…¥ä¸Šä¸‹æ–‡
result = agent.invoke(
    {"messages": [{"role": "user", "content": "è§£é‡Šæœºå™¨å­¦ä¹ "}]},
    context={"user_role": "expert"}
)
```

#### 4. `middleware` - ä¸­é—´ä»¶

**ç±»å‹**: `List[Middleware]` (å¯é€‰)

**ä½œç”¨**: åœ¨ Agent æ‰§è¡Œçš„ä¸åŒé˜¶æ®µæ’å…¥è‡ªå®šä¹‰é€»è¾‘

è¯¦è§ [ä¸­é—´ä»¶ç« èŠ‚](#ä¸­é—´ä»¶middleware)

#### 5. `checkpointer` - æ£€æŸ¥ç‚¹å™¨

**ç±»å‹**: `BaseCheckpointSaver` (å¯é€‰)

**ä½œç”¨**: å¯ç”¨çŸ­æœŸè®°å¿†ï¼ˆå¯¹è¯å†å²æŒä¹…åŒ–ï¼‰

```python
from langgraph.checkpoint.memory import MemorySaver

checkpointer = MemorySaver()

agent = create_agent(
    model=model,
    tools=tools,
    checkpointer=checkpointer
)

# ä½¿ç”¨ thread_id ç®¡ç†ä¼šè¯
agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘å«å¼ ä¸‰"}]},
    {"configurable": {"thread_id": "user-123"}}
)

# åœ¨åŒä¸€ä¼šè¯ä¸­ç»§ç»­å¯¹è¯
agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"}]},
    {"configurable": {"thread_id": "user-123"}}
)
# è¾“å‡º: ä½ å«å¼ ä¸‰
```

#### 6. `state_schema` - çŠ¶æ€æ¨¡å¼

**ç±»å‹**: `Type[TypedDict]` (å¯é€‰)

**ä½œç”¨**: æ‰©å±• Agent çŠ¶æ€ä»¥å­˜å‚¨é¢å¤–ä¿¡æ¯

```python
from langchain.agents import create_agent, AgentState
from langgraph.checkpoint.memory import MemorySaver

class CustomAgentState(AgentState):
    user_id: str
    preferences: dict

agent = create_agent(
    model="gpt-5",
    tools=[get_user_info],
    state_schema=CustomAgentState,
    checkpointer=MemorySaver()
)

# ä¼ å…¥è‡ªå®šä¹‰çŠ¶æ€
result = agent.invoke(
    {
        "messages": [{"role": "user", "content": "ä½ å¥½"}],
        "user_id": "user_123",
        "preferences": {"theme": "dark"}
    },
    {"configurable": {"thread_id": "1"}}
)
```

#### 7. `context_schema` - ä¸Šä¸‹æ–‡æ¨¡å¼

**ç±»å‹**: `Type` (å¯é€‰)

**ä½œç”¨**: å®šä¹‰è¿è¡Œæ—¶ä¸Šä¸‹æ–‡çš„ç±»å‹ï¼Œç”¨äºä¾èµ–æ³¨å…¥

```python
from dataclasses import dataclass

@dataclass
class Context:
    user_id: str
    db_connection: Any

agent = create_agent(
    model=model,
    tools=tools,
    context_schema=Context
)

# ä½¿ç”¨æ—¶æ³¨å…¥ä¸Šä¸‹æ–‡
from sqlalchemy import create_engine

db = create_engine("postgresql://...")
agent.invoke(
    {"messages": [...]},
    context={"user_id": "123", "db_connection": db}
)
```

#### 8. `response_format` - å“åº”æ ¼å¼ï¼ˆç»“æ„åŒ–è¾“å‡ºï¼‰

**ç±»å‹**: `ToolStrategy` æˆ– `ProviderStrategy` (å¯é€‰)

**ä½œç”¨**: å¼ºåˆ¶ Agent è¿”å›ç»“æ„åŒ–æ•°æ®

```python
from pydantic import BaseModel, Field
from langchain.agents.structured_output import ToolStrategy

class WeatherResponse(BaseModel):
    """å¤©æ°”å“åº”ç»“æ„"""
    location: str = Field(description="ä½ç½®")
    temperature: float = Field(description="æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰")
    condition: str = Field(description="å¤©æ°”çŠ¶å†µ")
    humidity: int = Field(description="æ¹¿åº¦ç™¾åˆ†æ¯”")

agent = create_agent(
    model=model,
    tools=[get_weather],
    response_format=ToolStrategy(
        schema=WeatherResponse,
        tool_message_content="å¤©æ°”ä¿¡æ¯å·²è·å–ï¼"
    )
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}]
})

weather_data: WeatherResponse = result["structured_response"]
print(f"æ¸©åº¦: {weather_data.temperature}Â°C")
```

---

## å·¥å…·ï¼ˆToolsï¼‰

### å·¥å…·å®šä¹‰è§„èŒƒ

#### 1. åŸºç¡€å·¥å…·å®šä¹‰

```python
from langchain_core.tools import tool

@tool
def calculate(expression: str) -> float:
    """
    è®¡ç®—æ•°å­¦è¡¨è¾¾å¼

    Args:
        expression: è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ "2 + 2"

    Returns:
        è®¡ç®—ç»“æœ

    Examples:
        >>> calculate("10 * 5")
        50.0
    """
    return eval(expression)
```

**å…³é”®è¦ç´ **:
- âœ… **å‡½æ•°å**: æè¿°æ€§åç§°ï¼ˆæ¨¡å‹ä¼šçœ‹åˆ°ï¼‰
- âœ… **æ–‡æ¡£å­—ç¬¦ä¸²**: è¯¦ç»†è¯´æ˜å·¥å…·ç”¨é€”
- âœ… **å‚æ•°ç±»å‹**: æ˜ç¡®çš„ç±»å‹æ³¨è§£
- âœ… **è¿”å›ç±»å‹**: æ¸…æ™°çš„è¿”å›å€¼

#### 2. å¸¦å‚æ•°éªŒè¯çš„å·¥å…·

```python
from pydantic import BaseModel, Field, validator

class DatabaseQueryInput(BaseModel):
    """æ•°æ®åº“æŸ¥è¯¢è¾“å…¥"""
    query: str = Field(description="SQL æŸ¥è¯¢è¯­å¥")
    limit: int = Field(default=100, ge=1, le=1000, description="æœ€å¤§è¿”å›è¡Œæ•°")

    @validator("query")
    def validate_query(cls, v):
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ SQL æ³¨å…¥
        forbidden = ["DROP", "DELETE", "UPDATE", "INSERT"]
        if any(word in v.upper() for word in forbidden):
            raise ValueError("åªå…è®¸ SELECT æŸ¥è¯¢")
        return v

@tool(args_schema=DatabaseQueryInput)
def query_database(query: str, limit: int = 100) -> list:
    """
    åœ¨æ•°æ®åº“ä¸­æ‰§è¡Œåªè¯»æŸ¥è¯¢

    å®‰å…¨é™åˆ¶:
    - ä»…å…è®¸ SELECT è¯­å¥
    - æœ€å¤šè¿”å› 1000 è¡Œ
    """
    # æ‰§è¡ŒæŸ¥è¯¢
    results = db.execute(query).fetchmany(limit)
    return results
```

#### 3. å·¥å…·é”™è¯¯å¤„ç†

```python
from langchain_core.tools import ToolException

@tool
def send_email(to: str, subject: str, body: str) -> str:
    """å‘é€ç”µå­é‚®ä»¶"""
    try:
        # éªŒè¯é‚®ç®±æ ¼å¼
        if "@" not in to:
            raise ToolException("æ— æ•ˆçš„é‚®ç®±åœ°å€æ ¼å¼")

        # å‘é€é‚®ä»¶
        result = email_service.send(to, subject, body)
        return f"é‚®ä»¶å·²å‘é€è‡³ {to}"

    except EmailServiceError as e:
        # è½¬æ¢ä¸º ToolExceptionï¼ŒAgent å¯ä»¥ç†è§£
        raise ToolException(
            f"é‚®ä»¶å‘é€å¤±è´¥: {e}. è¯·æ£€æŸ¥é‚®ç®±åœ°å€æˆ–ç¨åé‡è¯•ã€‚"
        )
    except Exception as e:
        raise ToolException(f"æœªçŸ¥é”™è¯¯: {e}")
```

**é€šè¿‡ä¸­é—´ä»¶å¤„ç†å·¥å…·é”™è¯¯**:
```python
from langchain.agents.middleware import wrap_tool_call
from langchain_core.messages import ToolMessage

@wrap_tool_call
def handle_tool_errors(request, handler):
    """ç»Ÿä¸€å¤„ç†å·¥å…·æ‰§è¡Œé”™è¯¯"""
    try:
        return handler(request)
    except Exception as e:
        # è¿”å›å‹å¥½çš„é”™è¯¯æ¶ˆæ¯ç»™æ¨¡å‹
        return ToolMessage(
            content=f"å·¥å…·æ‰§è¡Œå¤±è´¥: è¯·æ£€æŸ¥è¾“å…¥å‚æ•°ã€‚è¯¦æƒ…: {str(e)}",
            tool_call_id=request.tool_call["id"]
        )

agent = create_agent(
    model="gpt-4o",
    tools=[search, send_email],
    middleware=[handle_tool_errors]
)
```

### ç‰¹æ®Šç±»å‹çš„å·¥å…·

#### 1. Retriever å·¥å…·ï¼ˆRAGï¼‰

```python
from langchain_classic.tools.retriever import create_retriever_tool
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

# åˆ›å»ºå‘é‡å­˜å‚¨
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=OpenAIEmbeddings()
)

# åˆ›å»º retriever å·¥å…·
retriever_tool = create_retriever_tool(
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    name="search_company_docs",
    description="æœç´¢å…¬å¸æ–‡æ¡£åº“ä»¥æŸ¥æ‰¾ç›¸å…³æ”¿ç­–ã€æµç¨‹å’ŒæŒ‡å—"
)

agent = create_agent(
    model=model,
    tools=[retriever_tool]
)
```

#### 2. å¼‚æ­¥å·¥å…·

```python
import asyncio
import aiohttp

@tool
async def async_web_search(query: str) -> str:
    """å¼‚æ­¥ç½‘ç»œæœç´¢"""
    async with aiohttp.ClientSession() as session:
        async with session.get(
            f"https://api.example.com/search?q={query}"
        ) as resp:
            data = await resp.json()
            return data["results"]

# Agent ä¼šè‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå¼‚æ­¥å·¥å…·è°ƒç”¨
```

---

## ä¸­é—´ä»¶ï¼ˆMiddlewareï¼‰

### æ ¸å¿ƒæ¦‚å¿µ

**ä¸­é—´ä»¶** æ˜¯ `create_agent` çš„å®šä¹‰æ€§åŠŸèƒ½ï¼Œæä¾›é«˜åº¦å¯å®šåˆ¶çš„å…¥å£ç‚¹ã€‚

**ä¸»è¦ç”¨é€”**:
- ğŸ“ åŠ¨æ€æç¤ºè¯
- ğŸ’¬ å¯¹è¯æ‘˜è¦
- ğŸ”§ é€‰æ‹©æ€§å·¥å…·è®¿é—®
- ğŸ“Š çŠ¶æ€ç®¡ç†
- ğŸ›¡ï¸ å®‰å…¨é˜²æŠ¤

### æ‰§è¡Œæµç¨‹

ä¸­é—´ä»¶åœ¨ Agent æ‰§è¡Œçš„ä¸åŒé˜¶æ®µæä¾›é’©å­ï¼ˆhooksï¼‰ï¼š

```
Agent å¼€å§‹
    â”‚
    â”œâ”€â†’ before_agent()      # Agent å¼€å§‹å‰
    â”‚
    â”œâ”€â†’ å¾ªç¯å¼€å§‹
    â”‚   â”‚
    â”‚   â”œâ”€â†’ before_model()  # æ¨¡å‹è°ƒç”¨å‰
    â”‚   â”‚
    â”‚   â”œâ”€â†’ wrap_model_call()  # åŒ…è£…æ¨¡å‹è°ƒç”¨
    â”‚   â”‚       â”‚
    â”‚   â”‚       â””â”€â†’ å®é™…æ¨¡å‹è°ƒç”¨
    â”‚   â”‚
    â”‚   â”œâ”€â†’ after_model()   # æ¨¡å‹è°ƒç”¨å
    â”‚   â”‚
    â”‚   â”œâ”€â†’ wrap_tool_call()  # åŒ…è£…å·¥å…·è°ƒç”¨
    â”‚   â”‚       â”‚
    â”‚   â”‚       â””â”€â†’ å®é™…å·¥å…·æ‰§è¡Œ
    â”‚   â”‚
    â”‚   â””â”€â†’ å¾ªç¯ç»§ç»­æˆ–ç»“æŸ
    â”‚
    â””â”€â†’ after_agent()       # Agent å®Œæˆå
```

### ä¸­é—´ä»¶é’©å­ï¼ˆHooksï¼‰

| é’©å­ | æ‰§è¡Œæ—¶æœº | ç”¨é€” |
|-----|---------|------|
| `before_agent` | Agent å¼€å§‹å‰ | åŠ è½½è®°å¿†ã€éªŒè¯è¾“å…¥ |
| `before_model` | æ¯æ¬¡ LLM è°ƒç”¨å‰ | æ›´æ–°æç¤ºã€ä¿®å‰ªæ¶ˆæ¯ |
| `wrap_model_call` | æ¯æ¬¡ LLM è°ƒç”¨å‘¨å›´ | æ‹¦æˆªå’Œä¿®æ”¹è¯·æ±‚/å“åº” |
| `after_model` | æ¯æ¬¡ LLM å“åº”å | éªŒè¯è¾“å‡ºã€åº”ç”¨é˜²æŠ¤ |
| `wrap_tool_call` | æ¯æ¬¡å·¥å…·è°ƒç”¨å‘¨å›´ | æ‹¦æˆªå’Œä¿®æ”¹å·¥å…·æ‰§è¡Œ |
| `after_agent` | Agent å®Œæˆå | ä¿å­˜ç»“æœã€æ¸…ç†èµ„æº |

### è£…é¥°å™¨é£æ ¼ä¸­é—´ä»¶

#### 1. `@before_model` - æ¨¡å‹è°ƒç”¨å‰

```python
from langchain.agents.middleware import before_model
from langchain.agents.middleware import AgentState
from langgraph.runtime import Runtime

@before_model
def log_before_model(state: AgentState, runtime: Runtime) -> dict | None:
    """è®°å½•æ¨¡å‹è°ƒç”¨å‰çš„çŠ¶æ€"""
    print(f"å‡†å¤‡è°ƒç”¨æ¨¡å‹ï¼Œå½“å‰æœ‰ {len(state['messages'])} æ¡æ¶ˆæ¯")
    return None  # ä¸ä¿®æ”¹çŠ¶æ€

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[log_before_model]
)
```

**ä¿®å‰ªæ¶ˆæ¯ç¤ºä¾‹**:
```python
from langchain.agents.middleware import before_model, trim_messages

@before_model
async def trim_message_history(state: AgentState, runtime: Runtime):
    """ä¿®å‰ªè¿‡é•¿çš„æ¶ˆæ¯å†å²"""
    trimmed = await trim_messages(
        state["messages"],
        max_tokens=384,
        strategy="last",  # ä¿ç•™æœ€åçš„æ¶ˆæ¯
        start_on="human",
        end_on=["human", "tool"]
    )
    return {"messages": trimmed}
```

#### 2. `@after_model` - æ¨¡å‹è°ƒç”¨å

```python
from langchain.agents.middleware import after_model
from langchain.messages import AIMessage

@after_model(can_jump_to=["end"])
def validate_output(state: AgentState, runtime: Runtime):
    """éªŒè¯æ¨¡å‹è¾“å‡ºå¹¶åº”ç”¨å†…å®¹è¿‡æ»¤"""
    last_message = state["messages"][-1]

    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¦æ­¢å†…å®¹
    if "BLOCKED" in last_message.content:
        return {
            "messages": [AIMessage("æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›åº”è¯¥è¯·æ±‚ã€‚")],
            "jump_to": "end"  # æå‰ç»“æŸ Agent
        }

    return None

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[validate_output]
)
```

#### 3. `@wrap_model_call` - åŒ…è£…æ¨¡å‹è°ƒç”¨

```python
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse
from typing import Callable

@wrap_model_call
def retry_model(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse]
) -> ModelResponse:
    """æ¨¡å‹è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•"""
    max_retries = 3

    for attempt in range(max_retries):
        try:
            return handler(request)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            print(f"é‡è¯• {attempt + 1}/{max_retries}ï¼Œé”™è¯¯: {e}")
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

**åŠ¨æ€æ¨¡å‹é€‰æ‹©**:
```python
@wrap_model_call
def smart_model_routing(request: ModelRequest, handler):
    """æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
    # ç®€å•é—®é¢˜ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
    if len(request.messages) <= 3:
        request = request.override(model=ChatOpenAI(model="gpt-4o-mini"))
    # å¤æ‚é—®é¢˜ä½¿ç”¨å¼ºå¤§æ¨¡å‹
    else:
        request = request.override(model=ChatOpenAI(model="gpt-4o"))

    return handler(request)
```

#### 4. `@wrap_tool_call` - åŒ…è£…å·¥å…·è°ƒç”¨

```python
from langchain.agents.middleware import wrap_tool_call

@wrap_tool_call
def log_tool_execution(request, handler):
    """è®°å½•å·¥å…·æ‰§è¡Œ"""
    tool_name = request.tool_call["name"]
    print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}")

    start_time = time.time()
    result = handler(request)
    elapsed = time.time() - start_time

    print(f"âœ… å·¥å…· {tool_name} å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}s")
    return result
```

#### 5. `@dynamic_prompt` - åŠ¨æ€æç¤ºè¯

```python
from langchain.agents.middleware import dynamic_prompt, ModelRequest

@dynamic_prompt
def context_aware_prompt(request: ModelRequest) -> str:
    """åŸºäºä¸Šä¸‹æ–‡ç”ŸæˆåŠ¨æ€æç¤º"""
    # è®¿é—®æ¶ˆæ¯æ•°é‡
    message_count = len(request.messages)

    base = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"

    # é•¿å¯¹è¯æ—¶è¦æ±‚ç®€æ´
    if message_count > 10:
        base += "\nè¿™æ˜¯ä¸€ä¸ªé•¿å¯¹è¯ - è¯·ä¿æŒå›ç­”ç®€æ´ã€‚"

    # è®¿é—®è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
    user_role = request.runtime.context.get("user_role", "user")
    if user_role == "admin":
        base += "\nä½ æœ‰ç®¡ç†å‘˜æƒé™ï¼Œå¯ä»¥æ‰§è¡Œæ‰€æœ‰æ“ä½œã€‚"

    return base
```

### ç±»é£æ ¼ä¸­é—´ä»¶

```python
from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse
from dataclasses import dataclass
from typing import Callable

@dataclass
class Context:
    user_expertise: str = "beginner"

class ExpertiseBasedToolMiddleware(AgentMiddleware):
    """åŸºäºç”¨æˆ·ä¸“ä¸šæ°´å¹³åŠ¨æ€é€‰æ‹©å·¥å…·"""

    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse]
    ) -> ModelResponse:
        user_level = request.runtime.context.user_expertise

        if user_level == "expert":
            # ä¸“å®¶ç”¨æˆ·ï¼šå¼ºå¤§æ¨¡å‹ + é«˜çº§å·¥å…·
            model = ChatOpenAI(model="gpt-5")
            tools = [advanced_search, data_analysis, ml_training]
        else:
            # åˆå­¦è€…ï¼šç®€å•æ¨¡å‹ + åŸºç¡€å·¥å…·
            model = ChatOpenAI(model="gpt-5-nano")
            tools = [simple_search, basic_calculator]

        request = request.override(model=model, tools=tools)
        return handler(request)

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[simple_search, advanced_search, basic_calculator, data_analysis],
    middleware=[ExpertiseBasedToolMiddleware()],
    context_schema=Context
)
```

### é¢„æ„å»ºä¸­é—´ä»¶

LangChain æä¾›äº†å¸¸ç”¨çš„é¢„æ„å»ºä¸­é—´ä»¶ï¼š

#### 1. PII ä¸­é—´ä»¶ï¼ˆæ•æ„Ÿä¿¡æ¯è„±æ•ï¼‰

```python
from langchain.agents import pii_redaction_middleware

agent = create_agent(
    model=model,
    tools=tools,
    middleware=[
        pii_redaction_middleware(patterns=["email", "phone", "ssn"])
    ]
)
```

#### 2. æ‘˜è¦ä¸­é—´ä»¶

```python
from langchain.agents import summarization_middleware

agent = create_agent(
    model=model,
    tools=tools,
    middleware=[
        summarization_middleware(
            model="claude-sonnet-4-5-20250929",
            max_tokens_before_summary=500
        )
    ]
)
```

#### 3. äººæœºåä½œä¸­é—´ä»¶

```python
from langchain.agents import human_in_the_loop_middleware

agent = create_agent(
    model=model,
    tools=[send_email, delete_file],
    middleware=[
        human_in_the_loop_middleware(
            interrupt_on={
                "send_email": {"allowed_decisions": ["approve", "edit", "reject"]},
                "delete_file": True  # é»˜è®¤ï¼šapprove, edit, reject
            }
        )
    ]
)
```

### ä¸­é—´ä»¶æ‰§è¡Œé¡ºåº

å½“ä½¿ç”¨å¤šä¸ªä¸­é—´ä»¶æ—¶ï¼Œç†è§£æ‰§è¡Œé¡ºåºå¾ˆé‡è¦ï¼š

```python
middleware=[middleware1, middleware2, middleware3]
```

**æ‰§è¡Œé¡ºåº**:

1. **Before é’©å­**: æŒ‰é¡ºåºæ‰§è¡Œ
   ```
   middleware1.before_agent()
   middleware2.before_agent()
   middleware3.before_agent()
   ```

2. **Wrap é’©å­**: åµŒå¥—æ‰§è¡Œï¼ˆæ´‹è‘±æ¨¡å‹ï¼‰
   ```
   middleware1.wrap_model_call(
       middleware2.wrap_model_call(
           middleware3.wrap_model_call(
               â†’ å®é™…æ¨¡å‹è°ƒç”¨
           )
       )
   )
   ```

3. **After é’©å­**: é€†åºæ‰§è¡Œ
   ```
   middleware3.after_model()
   middleware2.after_model()
   middleware1.after_model()
   ```

---

## çŸ­æœŸè®°å¿†ï¼ˆShort-term Memoryï¼‰

### æ¦‚å¿µ

**çŸ­æœŸè®°å¿†** = çº¿ç¨‹çº§æŒä¹…åŒ–ï¼Œè·Ÿè¸ªå•ä¸ªä¼šè¯ä¸­çš„å¯¹è¯å†å²ã€‚

**æ ¸å¿ƒæœºåˆ¶**:
- LangChain å°†çŸ­æœŸè®°å¿†ä½œä¸º Agent **çŠ¶æ€ï¼ˆStateï¼‰** çš„ä¸€éƒ¨åˆ†ç®¡ç†
- ä½¿ç”¨ **Checkpointer** å°†çŠ¶æ€æŒä¹…åŒ–åˆ°æ•°æ®åº“ï¼ˆæˆ–å†…å­˜ï¼‰
- é€šè¿‡ `thread_id` åŒºåˆ†ä¸åŒçš„å¯¹è¯ä¼šè¯

### å¯ç”¨çŸ­æœŸè®°å¿†

```python
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver

# åˆ›å»ºæ£€æŸ¥ç‚¹å™¨
checkpointer = MemorySaver()

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[],
    checkpointer=checkpointer  # å¯ç”¨è®°å¿†
)

# ç¬¬ä¸€è½®å¯¹è¯
agent.invoke(
    {"messages": [{"role": "user", "content": "ä½ å¥½ï¼æˆ‘å«å¼ ä¸‰ã€‚"}]},
    {"configurable": {"thread_id": "conversation-1"}}
)

# ç¬¬äºŒè½®å¯¹è¯ - Agent è®°å¾—ä¹‹å‰çš„å†…å®¹
agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"}]},
    {"configurable": {"thread_id": "conversation-1"}}
)
# è¾“å‡º: ä½ å«å¼ ä¸‰ã€‚
```

### è‡ªå®šä¹‰çŠ¶æ€æ¨¡å¼

**é»˜è®¤çŠ¶æ€**: `AgentState` åªåŒ…å« `messages` å­—æ®µ

**æ‰©å±•çŠ¶æ€**:
```python
from langchain.agents import create_agent, AgentState
from langgraph.checkpoint.memory import MemorySaver

class CustomAgentState(AgentState):
    """æ‰©å±•çš„ Agent çŠ¶æ€"""
    user_id: str  # ç”¨æˆ· ID
    preferences: dict  # ç”¨æˆ·åå¥½
    session_data: dict  # ä¼šè¯æ•°æ®

agent = create_agent(
    model="gpt-5",
    tools=[get_user_info],
    state_schema=CustomAgentState,
    checkpointer=MemorySaver()
)

# ä¼ å…¥è‡ªå®šä¹‰çŠ¶æ€
result = agent.invoke(
    {
        "messages": [{"role": "user", "content": "æ¨èä¸€éƒ¨ç”µå½±"}],
        "user_id": "user_123",
        "preferences": {"genre": "ç§‘å¹»", "rating": ">8.0"}
    },
    {"configurable": {"thread_id": "1"}}
)
```

### åœ¨ä¸­é—´ä»¶ä¸­è®¿é—®çŠ¶æ€

```python
from langchain.agents.middleware import before_model

@before_model
def check_authentication(state: AgentState, runtime: Runtime):
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²è®¤è¯"""
    is_authenticated = state.get("authenticated", False)

    if not is_authenticated:
        raise ValueError("ç”¨æˆ·æœªè®¤è¯ï¼Œè¯·å…ˆç™»å½•")

    return None
```

### æ¶ˆæ¯ä¿®å‰ª

é•¿å¯¹è¯ä¼šæ¶ˆè€—å¤§é‡ tokenï¼Œéœ€è¦ä¿®å‰ªæ¶ˆæ¯å†å²ï¼š

```python
from langchain.agents.middleware import before_model, trim_messages

@before_model
async def trim_long_conversations(state: AgentState, runtime: Runtime):
    """ä¿®å‰ªè¿‡é•¿çš„å¯¹è¯å†å²"""
    if len(state["messages"]) > 20:
        trimmed = await trim_messages(
            state["messages"],
            max_tokens=2000,
            strategy="last",  # ä¿ç•™æœ€åçš„æ¶ˆæ¯
            start_on="human",  # ä»äººç±»æ¶ˆæ¯å¼€å§‹
            end_on=["human", "tool"],  # ä»¥äººç±»æˆ–å·¥å…·æ¶ˆæ¯ç»“æŸ
            include_system=True  # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
        )
        return {"messages": trimmed}

    return None
```

---

## ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆContext Engineeringï¼‰

### æ¦‚å¿µ

**ä¸Šä¸‹æ–‡å·¥ç¨‹** = åœ¨æ­£ç¡®çš„æ—¶é—´å°†æ­£ç¡®çš„ä¿¡æ¯æä¾›ç»™æ¨¡å‹

**ä¸‰ä¸ªå…³é”®æ¥æº**:
1. **Stateï¼ˆçŠ¶æ€ï¼‰**: å½“å‰ä¼šè¯çš„æ•°æ®
2. **Runtime Contextï¼ˆè¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼‰**: æ¯æ¬¡è°ƒç”¨çš„é…ç½®
3. **Storeï¼ˆå­˜å‚¨ï¼‰**: è·¨ä¼šè¯çš„é•¿æœŸè®°å¿†

### 1. åŸºäºçŠ¶æ€çš„åŠ¨æ€æç¤º

```python
from langchain.agents.middleware import dynamic_prompt, ModelRequest

@dynamic_prompt
def state_aware_prompt(request: ModelRequest) -> str:
    """æ ¹æ®çŠ¶æ€ç”Ÿæˆæç¤º"""
    # è®¿é—®æ¶ˆæ¯æ•°é‡
    message_count = len(request.messages)

    base = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"

    if message_count > 10:
        base += "\nè¿™æ˜¯ä¸€ä¸ªé•¿å¯¹è¯ - è¯·ä¿æŒç®€æ´ã€‚"

    # è®¿é—®è‡ªå®šä¹‰çŠ¶æ€å­—æ®µ
    state = request.state
    if state.get("authenticated"):
        base += "\nç”¨æˆ·å·²è®¤è¯ï¼Œå¯ä»¥è®¿é—®æ•æ„ŸåŠŸèƒ½ã€‚"

    return base
```

### 2. åŸºäºè¿è¡Œæ—¶ä¸Šä¸‹æ–‡çš„åŠ¨æ€æç¤º

```python
from dataclasses import dataclass

@dataclass
class Context:
    user_role: str
    deployment_env: str

@dynamic_prompt
def context_aware_prompt(request: ModelRequest) -> str:
    """æ ¹æ®è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ç”Ÿæˆæç¤º"""
    # è®¿é—®è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
    user_role = request.runtime.context.user_role
    env = request.runtime.context.deployment_env

    base = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"

    if user_role == "admin":
        base += "\nä½ æœ‰ç®¡ç†å‘˜æƒé™ï¼Œå¯ä»¥æ‰§è¡Œæ‰€æœ‰æ“ä½œã€‚"
    elif user_role == "viewer":
        base += "\nä½ åªæœ‰åªè¯»æƒé™ï¼Œä»…å¼•å¯¼ç”¨æˆ·è¿›è¡Œè¯»æ“ä½œã€‚"

    if env == "production":
        base += "\nè¯·ç‰¹åˆ«å°å¿ƒæ•°æ®ä¿®æ”¹æ“ä½œã€‚"

    return base

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[context_aware_prompt],
    context_schema=Context
)

# ä½¿ç”¨æ—¶ä¼ å…¥ä¸Šä¸‹æ–‡
agent.invoke(
    {"messages": [...]},
    context={"user_role": "admin", "deployment_env": "production"}
)
```

### 3. åŸºäº Store çš„é•¿æœŸè®°å¿†

```python
from langgraph.store.memory import InMemoryStore

@dynamic_prompt
async def store_aware_prompt(request: ModelRequest) -> str:
    """ä»é•¿æœŸå­˜å‚¨è¯»å–ç”¨æˆ·åå¥½"""
    user_id = request.runtime.context.user_id

    # ä» Store è¯»å–ç”¨æˆ·åå¥½
    store = request.runtime.store
    user_prefs = await store.get(("preferences",), user_id)

    base = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"

    if user_prefs:
        style = user_prefs.value.get("communication_style", "balanced")
        base += f"\nç”¨æˆ·åå¥½ {style} é£æ ¼çš„å“åº”ã€‚"

    return base

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[store_aware_prompt],
    context_schema=Context,
    store=InMemoryStore()
)
```

### 4. åŠ¨æ€å·¥å…·é€‰æ‹©

#### åŸºäºçŠ¶æ€é€‰æ‹©å·¥å…·

```python
from langchain.agents.middleware import wrap_model_call

@wrap_model_call
def state_based_tools(request: ModelRequest, handler):
    """æ ¹æ®è®¤è¯çŠ¶æ€è¿‡æ»¤å·¥å…·"""
    state = request.state
    is_authenticated = state.get("authenticated", False)
    message_count = len(state["messages"])

    # æœªè®¤è¯ï¼šä»…å…¬å¼€å·¥å…·
    if not is_authenticated:
        tools = [t for t in request.tools if t.name.startswith("public_")]
        request = request.override(tools=tools)
    # å¯¹è¯åˆæœŸï¼šé™åˆ¶é«˜çº§å·¥å…·
    elif message_count < 5:
        tools = [t for t in request.tools if t.name != "advanced_search"]
        request = request.override(tools=tools)

    return handler(request)
```

#### åŸºäºä¸Šä¸‹æ–‡é€‰æ‹©å·¥å…·

```python
@dataclass
class Context:
    user_role: str

@wrap_model_call
def context_based_tools(request: ModelRequest, handler):
    """æ ¹æ®ç”¨æˆ·è§’è‰²è¿‡æ»¤å·¥å…·"""
    user_role = request.runtime.context.user_role

    if user_role == "admin":
        # ç®¡ç†å‘˜ï¼šæ‰€æœ‰å·¥å…·
        pass
    elif user_role == "editor":
        # ç¼–è¾‘è€…ï¼šä¸èƒ½åˆ é™¤
        tools = [t for t in request.tools if t.name != "delete_data"]
        request = request.override(tools=tools)
    else:
        # æŸ¥çœ‹è€…ï¼šä»…åªè¯»å·¥å…·
        tools = [t for t in request.tools if t.name.startswith("read_")]
        request = request.override(tools=tools)

    return handler(request)

agent = create_agent(
    model="gpt-4o",
    tools=[read_data, write_data, delete_data],
    middleware=[context_based_tools],
    context_schema=Context
)
```

---

## äººæœºåä½œï¼ˆHuman-in-the-Loopï¼‰

### æ¦‚å¿µ

**Human-in-the-Loop (HITL)** ä¸­é—´ä»¶å…è®¸ä½ ä¸º Agent å·¥å…·è°ƒç”¨æ·»åŠ äººå·¥ç›‘ç£ã€‚

**å·¥ä½œåŸç†**:
1. æ¨¡å‹æè®®ä¸€ä¸ªå¯èƒ½éœ€è¦å®¡æŸ¥çš„æ“ä½œï¼ˆå¦‚åˆ é™¤æ–‡ä»¶ã€å‘é€é‚®ä»¶ï¼‰
2. ä¸­é—´ä»¶æ ¹æ®é…ç½®çš„ç­–ç•¥æ£€æŸ¥å·¥å…·è°ƒç”¨
3. å¦‚æœéœ€è¦å¹²é¢„ï¼Œä¸­é—´ä»¶å‘å‡º **ä¸­æ–­ï¼ˆinterruptï¼‰**ï¼Œæš‚åœæ‰§è¡Œ
4. å›¾çŠ¶æ€é€šè¿‡ LangGraph çš„æŒä¹…åŒ–å±‚ä¿å­˜
5. äººç±»åšå‡ºå†³å®šï¼šæ‰¹å‡†ï¼ˆapproveï¼‰ã€ç¼–è¾‘ï¼ˆeditï¼‰æˆ–æ‹’ç»ï¼ˆrejectï¼‰
6. æ‰§è¡Œæ¢å¤

### åŸºç¡€é…ç½®

```python
from langchain_core.tools import tool
from langchain.agents import create_agent
from langchain.agents import human_in_the_loop_middleware
from langgraph.checkpoint.memory import MemorySaver

@tool
def delete_file(path: str) -> str:
    """åˆ é™¤æ–‡ä»¶"""
    os.remove(path)
    return f"å·²åˆ é™¤ {path}"

@tool
def send_email(to: str, subject: str, body: str) -> str:
    """å‘é€é‚®ä»¶"""
    email_service.send(to, subject, body)
    return f"å·²å‘é€é‚®ä»¶è‡³ {to}"

# âš ï¸ HITL éœ€è¦ checkpointer
checkpointer = MemorySaver()

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[delete_file, send_email],
    middleware=[
        human_in_the_loop_middleware(
            interrupt_on={
                "delete_file": True,  # é»˜è®¤ï¼šapprove, edit, reject
                "send_email": {"allowed_decisions": ["approve", "reject"]},  # ä¸å…è®¸ç¼–è¾‘
            }
        )
    ],
    checkpointer=checkpointer  # å¿…éœ€ï¼
)
```

### å†³ç­–ç±»å‹

| å†³ç­–ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ç”¨ä¾‹ |
|---------|------|---------|
| âœ… **approve** | æ“ä½œæŒ‰åŸæ ·æ‰¹å‡†å¹¶æ‰§è¡Œï¼Œæ— æ›´æ”¹ | æŒ‰åŸæ ·å‘é€é‚®ä»¶è‰ç¨¿ |
| âœï¸ **edit** | å·¥å…·è°ƒç”¨è¢«ä¿®æ”¹åæ‰§è¡Œ | å‘é€é‚®ä»¶å‰æ›´æ”¹æ”¶ä»¶äºº |
| âŒ **reject** | å·¥å…·è°ƒç”¨è¢«æ‹’ç»ï¼Œå¹¶å°†è§£é‡Šæ·»åŠ åˆ°å¯¹è¯ä¸­ | æ‹’ç»é‚®ä»¶è‰ç¨¿å¹¶è¯´æ˜å¦‚ä½•é‡å†™ |

### æ‰§è¡Œæµç¨‹

```python
# 1. å¯åŠ¨ Agent
thread_id = "thread-123"
result = agent.invoke(
    {"messages": [{"role": "user", "content": "åˆ é™¤ report.pdf"}]},
    {"configurable": {"thread_id": thread_id}}
)

# 2. Agent é‡åˆ°éœ€è¦å®¡æ‰¹çš„å·¥å…·è°ƒç”¨ï¼Œæš‚åœæ‰§è¡Œ

# 3. è·å–ä¸­æ–­è¯·æ±‚
from langgraph.types import Command

state = agent.get_state({"configurable": {"thread_id": thread_id}})
interrupt_request = state.values.get("hitl_request")

print(interrupt_request)
# HITLRequest(
#     action_requests=[
#         ActionRequest(
#             tool_call={"name": "delete_file", "args": {"path": "report.pdf"}},
#             decision=None
#         )
#     ]
# )

# 4. äººç±»åšå‡ºå†³å®š
from langchain.agents.human_in_the_loop import HITLResponse, Decision

# é€‰é¡¹ 1: æ‰¹å‡†
response = HITLResponse(
    decisions=[Decision(type="approve")]
)

# é€‰é¡¹ 2: ç¼–è¾‘
response = HITLResponse(
    decisions=[
        Decision(
            type="edit",
            tool_call={"name": "delete_file", "args": {"path": "backup/report.pdf"}}
        )
    ]
)

# é€‰é¡¹ 3: æ‹’ç»
response = HITLResponse(
    decisions=[
        Decision(
            type="reject",
            explanation="è¯·ä¸è¦åˆ é™¤ report.pdfï¼Œæˆ‘ä»¬è¿˜éœ€è¦å®ƒ"
        )
    ]
)

# 5. æ¢å¤æ‰§è¡Œ
agent.invoke(
    Command(resume=response),
    {"configurable": {"thread_id": thread_id}}
)
```

### å¤šå·¥å…·è°ƒç”¨

å½“å¤šä¸ªå·¥å…·è°ƒç”¨åŒæ—¶æš‚åœæ—¶ï¼Œå¿…é¡»ä¸ºæ¯ä¸ªæ“ä½œæä¾›å†³ç­–ï¼Œä¸”**é¡ºåºå¿…é¡»ä¸ä¸­æ–­è¯·æ±‚ä¸­çš„é¡ºåºä¸€è‡´**ã€‚

```python
# Agent åŒæ—¶è°ƒç”¨ä¸¤ä¸ªå·¥å…·
interrupt_request.action_requests
# [
#     ActionRequest(tool_call={"name": "send_email", ...}),
#     ActionRequest(tool_call={"name": "delete_file", ...})
# ]

# æä¾›å†³ç­–ï¼ˆé¡ºåºåŒ¹é…ï¼‰
response = HITLResponse(
    decisions=[
        Decision(type="approve"),  # å¯¹åº” send_email
        Decision(type="reject", explanation="ä¸è¦åˆ é™¤")  # å¯¹åº” delete_file
    ]
)
```

---

## ç»“æ„åŒ–è¾“å‡º

### æ¦‚å¿µ

å¼ºåˆ¶ Agent è¿”å›ç¬¦åˆé¢„å®šä¹‰ schema çš„ç»“æ„åŒ–æ•°æ®ï¼Œè€Œä¸æ˜¯è‡ªç”±æ–‡æœ¬ã€‚

### ä½¿ç”¨ ToolStrategy

```python
from pydantic import BaseModel, Field
from typing import Literal
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy

class ProductReview(BaseModel):
    """äº§å“è¯„è®ºåˆ†æ"""
    rating: int | None = Field(description="äº§å“è¯„åˆ†", ge=1, le=5)
    sentiment: Literal["positive", "negative", "neutral"] = Field(description="æƒ…æ„Ÿå€¾å‘")
    key_points: list[str] = Field(description="å…³é”®ç‚¹ï¼Œå°å†™ï¼Œæ¯ä¸ª 1-3 è¯")

agent = create_agent(
    model="gpt-5",
    tools=[],
    response_format=ToolStrategy(
        schema=ProductReview,
        tool_message_content="è¯„è®ºåˆ†æå®Œæˆï¼"  # å¯é€‰ï¼šè‡ªå®šä¹‰å·¥å…·æ¶ˆæ¯
    )
)

result = agent.invoke({
    "messages": [{
        "role": "user",
        "content": "åˆ†æè¯„è®º: 'å¾ˆæ£’çš„äº§å“ï¼š5æ˜Ÿã€‚å‘è´§å¿«ï¼Œä½†ä»·æ ¼è´µ'"
    }]
})

review: ProductReview = result["structured_response"]
print(f"è¯„åˆ†: {review.rating}")
print(f"æƒ…æ„Ÿ: {review.sentiment}")
print(f"å…³é”®ç‚¹: {review.key_points}")
# è¾“å‡º:
# è¯„åˆ†: 5
# æƒ…æ„Ÿ: positive
# å…³é”®ç‚¹: ['å‘è´§å¿«', 'ä»·æ ¼è´µ']
```

### æ”¯æŒçš„ Schema ç±»å‹

1. **Pydantic æ¨¡å‹**
```python
class WeatherData(BaseModel):
    temperature: float
    condition: str
```

2. **æ•°æ®ç±»ï¼ˆDataclassï¼‰**
```python
from dataclasses import dataclass

@dataclass
class WeatherData:
    temperature: float
    condition: str
```

3. **TypedDict**
```python
from typing import TypedDict

class WeatherData(TypedDict):
    temperature: float
    condition: str
```

4. **JSON Schema**
```python
schema = {
    "type": "object",
    "properties": {
        "temperature": {"type": "number"},
        "condition": {"type": "string"}
    },
    "required": ["temperature", "condition"]
}
```

5. **Union ç±»å‹**ï¼ˆå¤šä¸ª schema é€‰é¡¹ï¼‰
```python
from typing import Union

class EmailAction(BaseModel):
    type: Literal["email"]
    to: str
    subject: str

class SlackAction(BaseModel):
    type: Literal["slack"]
    channel: str
    message: str

# æ¨¡å‹ä¼šæ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©åˆé€‚çš„ schema
response_format = ToolStrategy(schema=Union[EmailAction, SlackAction])
```

### é”™è¯¯å¤„ç†

```python
from langchain.agents.structured_output import ToolStrategy

def custom_error_handler(e: Exception) -> str:
    """è‡ªå®šä¹‰é”™è¯¯å¤„ç†"""
    return f"ç»“æ„åŒ–è¾“å‡ºéªŒè¯å¤±è´¥: {e}. è¯·æ£€æŸ¥æ•°æ®æ ¼å¼ã€‚"

agent = create_agent(
    model="gpt-5",
    tools=[],
    response_format=ToolStrategy(
        schema=ProductReview,
        handle_errors=custom_error_handler  # è‡ªå®šä¹‰é”™è¯¯å¤„ç†å‡½æ•°
    )
)
```

**å†…ç½®é”™è¯¯å¤„ç†é€‰é¡¹**:
- `True`: æ•è·æ‰€æœ‰é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é”™è¯¯æ¨¡æ¿
- `str`: æ•è·æ‰€æœ‰é”™è¯¯ï¼Œä½¿ç”¨è‡ªå®šä¹‰æ¶ˆæ¯
- `type[Exception]`: åªæ•è·ç‰¹å®šå¼‚å¸¸ç±»å‹
- `tuple[type[Exception], ...]`: æ•è·å¤šç§å¼‚å¸¸ç±»å‹
- `Callable[[Exception], str]`: è‡ªå®šä¹‰é”™è¯¯å¤„ç†å‡½æ•°
- `False`: ä¸é‡è¯•ï¼Œè®©å¼‚å¸¸ä¼ æ’­

---

## æœ€ä½³å®è·µ

### 1. Agent è®¾è®¡æ¨¡å¼

#### âœ… å•ä¸€èŒè´£åŸåˆ™

```python
# å¥½çš„è®¾è®¡
customer_service_agent = create_agent(
    model=model,
    tools=[search_kb, create_ticket, escalate],
    system_prompt="ä½ æ˜¯å®¢æœä¸“å‘˜ï¼Œä¸“æ³¨äºè§£å†³å®¢æˆ·é—®é¢˜"
)

sales_agent = create_agent(
    model=model,
    tools=[search_products, calculate_price, create_order],
    system_prompt="ä½ æ˜¯é”€å”®ä¸“å‘˜ï¼Œä¸“æ³¨äºäº§å“æ¨èå’Œè®¢å•"
)

# âŒ ä¸å¥½çš„è®¾è®¡
everything_agent = create_agent(
    model=model,
    tools=[...100ä¸ªå·¥å…·],  # å¤ªå¤šèŒè´£
    system_prompt="ä½ ä»€ä¹ˆéƒ½èƒ½åš"
)
```

#### âœ… åˆ†å±‚ Agent æ¶æ„

```python
# é¡¶å±‚ï¼šè·¯ç”± Agent
router_agent = create_agent(
    model=model,
    tools=[
        delegate_to_customer_service,
        delegate_to_sales,
        delegate_to_technical
    ],
    system_prompt="æ ¹æ®ç”¨æˆ·éœ€æ±‚è·¯ç”±åˆ°ä¸“é—¨çš„ Agent"
)

# åº•å±‚ï¼šä¸“ä¸š Agent
@tool
def delegate_to_customer_service(query: str) -> str:
    """å§”æ‰˜ç»™å®¢æœ Agent"""
    result = customer_service_agent.invoke({
        "messages": [{"role": "user", "content": query}]
    })
    return result["messages"][-1]["content"]
```

### 2. å·¥å…·è®¾è®¡æœ€ä½³å®è·µ

#### âœ… è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²

```python
@tool
def search_database(query: str, limit: int = 10, filters: dict = {}) -> list:
    """
    åœ¨æ•°æ®åº“ä¸­æœç´¢å†…å®¹

    ä½¿ç”¨åœºæ™¯ï¼š
    - æŸ¥æ‰¾ç”¨æˆ·ä¿¡æ¯
    - æœç´¢å†å²è®°å½•
    - æ£€ç´¢äº§å“æ•°æ®

    Args:
        query: æœç´¢å…³é”®è¯ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…
        limit: æœ€å¤šè¿”å›å¤šå°‘æ¡ç»“æœï¼Œé»˜è®¤ 10
        filters: é¢å¤–çš„è¿‡æ»¤æ¡ä»¶ï¼Œå¦‚ {"status": "active"}

    Returns:
        åŒ¹é…çš„è®°å½•åˆ—è¡¨

    Examples:
        >>> search_database("å¼ ä¸‰", limit=5)
        [{"name": "å¼ ä¸‰", "id": 1}, ...]
    """
    results = db.query(query, limit=limit, **filters)
    return results
```

#### âœ… è¾“å…¥éªŒè¯

```python
from pydantic import BaseModel, Field, validator

class SearchInput(BaseModel):
    query: str = Field(description="æœç´¢æŸ¥è¯¢")
    limit: int = Field(default=10, ge=1, le=100)

    @validator("query")
    def validate_query(cls, v):
        if len(v) < 2:
            raise ValueError("æŸ¥è¯¢è‡³å°‘éœ€è¦ 2 ä¸ªå­—ç¬¦")
        return v
```

#### âœ… é”™è¯¯å¤„ç†

```python
@tool
def risky_operation(param: str) -> str:
    """å¯èƒ½å¤±è´¥çš„æ“ä½œ"""
    try:
        result = external_api_call(param)
        return result
    except ExternalAPIError as e:
        raise ToolException(f"API è°ƒç”¨å¤±è´¥: {e}. è¯·ç¨åé‡è¯•ã€‚")
```

### 3. æç¤ºè¯å·¥ç¨‹

#### âœ… ç»“æ„åŒ–ç³»ç»Ÿæç¤º

```python
SYSTEM_PROMPT = """
# è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ã€‚

# æ ¸å¿ƒèƒ½åŠ›
- æ•°æ®æŸ¥è¯¢å’Œåˆ†æ
- ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
- æä¾›ä¸šåŠ¡æ´å¯Ÿ

# å·¥ä½œæµç¨‹
1. ç†è§£ç”¨æˆ·éœ€æ±‚
2. é€‰æ‹©åˆé€‚çš„å·¥å…·
3. åˆ†ææ•°æ®ç»“æœ
4. ç”Ÿæˆæ¸…æ™°çš„æŠ¥å‘Š

# è¾“å‡ºæ ¼å¼
- ä½¿ç”¨ Markdown æ ¼å¼
- æ•°æ®ç”¨è¡¨æ ¼å±•ç¤º
- ç»“è®ºè¦ç®€æ˜æ‰¼è¦

# é™åˆ¶
- ä¸è¦ç¼–é€ æ•°æ®
- ä¸ç¡®å®šæ—¶æ˜ç¡®è¯´æ˜
- è¶…å‡ºèƒ½åŠ›èŒƒå›´æ—¶å»ºè®®äººå·¥ä»‹å…¥
"""
```

### 4. æ€§èƒ½ä¼˜åŒ–

#### âœ… ä½¿ç”¨å¼‚æ­¥å·¥å…·

```python
@tool
async def async_search(query: str) -> str:
    """å¼‚æ­¥æœç´¢"""
    async with aiohttp.ClientSession() as session:
        async with session.get(f"https://api.example.com/search?q={query}") as resp:
            return await resp.text()

# Agent ä¼šè‡ªåŠ¨å¹¶è¡Œè°ƒç”¨å¤šä¸ªå¼‚æ­¥å·¥å…·
```

#### âœ… ç¼“å­˜ç­–ç•¥

```python
from langchain.cache import SQLiteCache
from langchain.globals import set_llm_cache

# ç”Ÿäº§ç¯å¢ƒï¼šæŒä¹…åŒ–ç¼“å­˜
set_llm_cache(SQLiteCache(database_path=".langchain.db"))

# ç›¸åŒçš„è°ƒç”¨ä¼šä»ç¼“å­˜è¯»å–
agent.invoke({"messages": [...]})  # è°ƒç”¨ API
agent.invoke({"messages": [...]})  # ä»ç¼“å­˜è¯»å–
```

### 5. å®‰å…¨æœ€ä½³å®è·µ

#### âœ… è¾“å…¥éªŒè¯

```python
@validator("user_query")
def validate_query(cls, v):
    # æ£€æŸ¥ SQL æ³¨å…¥
    forbidden = ["DROP", "DELETE", "UPDATE", "INSERT"]
    if any(word in v.upper() for word in forbidden):
        raise ValueError("æ£€æµ‹åˆ°æ½œåœ¨çš„ SQL æ³¨å…¥")

    # é•¿åº¦é™åˆ¶
    if len(v) > 1000:
        raise ValueError("æŸ¥è¯¢è¿‡é•¿")

    return v
```

#### âœ… æƒé™æ§åˆ¶

```python
def require_permission(permission: str):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, config=None, **kwargs):
            user_permissions = config.get("context", {}).get("permissions", [])
            if permission not in user_permissions:
                raise PermissionError(f"éœ€è¦æƒé™: {permission}")
            return func(*args, **kwargs)
        return wrapper
    return decorator

@tool
@require_permission("database.write")
def delete_record(record_id: str) -> str:
    """åˆ é™¤è®°å½•ï¼ˆéœ€è¦å†™æƒé™ï¼‰"""
    db.delete(record_id)
    return "å·²åˆ é™¤"
```

#### âœ… æ•æ„Ÿä¿¡æ¯è¿‡æ»¤

```python
import re

class SensitiveDataMiddleware(Middleware):
    PATTERNS = {
        "phone": r"\d{11}",
        "email": r"[\w\.-]+@[\w\.-]+\.\w+",
        "id_card": r"\d{17}[\dXx]"
    }

    def after_model(self, state, response, config):
        content = response.content

        # è„±æ•å¤„ç†
        for data_type, pattern in self.PATTERNS.items():
            content = re.sub(pattern, f"[å·²éšè—çš„{data_type}]", content)

        response.content = content
        return response
```

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **Agent = æ¨¡å‹ + å·¥å…· + å¾ªç¯**
   - Agent é€šè¿‡å¾ªç¯è°ƒç”¨æ¨¡å‹å’Œå·¥å…·æ¥å®Œæˆä»»åŠ¡
   - åŸºäº LangGraph çš„å›¾çŠ¶è¿è¡Œæ—¶æä¾›çµæ´»æ§åˆ¶

2. **create_agent æ˜¯æ ‡å‡†æ–¹å¼**
   - ç®€å•æ˜“ç”¨ï¼ˆ<10 è¡Œä»£ç ï¼‰
   - é«˜åº¦å¯å®šåˆ¶ï¼ˆé€šè¿‡ä¸­é—´ä»¶ï¼‰
   - ç”Ÿäº§å°±ç»ªï¼ˆæŒä¹…åŒ–ã€ç›‘æ§ç­‰ï¼‰

3. **ä¸­é—´ä»¶æ˜¯æ ¸å¿ƒæ‰©å±•ç‚¹**
   - åœ¨æ‰§è¡Œçš„å„ä¸ªé˜¶æ®µæ’å…¥è‡ªå®šä¹‰é€»è¾‘
   - æ”¯æŒåŠ¨æ€æç¤ºã€å·¥å…·é€‰æ‹©ã€é”™è¯¯å¤„ç†ç­‰
   - å¯ç»„åˆã€å¯å¤ç”¨

4. **ä¸Šä¸‹æ–‡å·¥ç¨‹å¾ˆå…³é”®**
   - State: ä¼šè¯æ•°æ®
   - Runtime Context: è¿è¡Œæ—¶é…ç½®
   - Store: é•¿æœŸè®°å¿†
   - åœ¨æ­£ç¡®çš„æ—¶é—´æä¾›æ­£ç¡®çš„ä¿¡æ¯

5. **è®°å¿†ç®¡ç†åˆ†ä¸¤ç§**
   - çŸ­æœŸè®°å¿†: Checkpointer + thread_id
   - é•¿æœŸè®°å¿†: Store + è‡ªå®šä¹‰å‘½åç©ºé—´

6. **äººæœºåä½œæå‡å®‰å…¨æ€§**
   - æ•æ„Ÿæ“ä½œéœ€è¦äººå·¥æ‰¹å‡†
   - æ”¯æŒæ‰¹å‡†ã€ç¼–è¾‘ã€æ‹’ç»ä¸‰ç§å†³ç­–
   - éœ€è¦ Checkpointer æ”¯æŒ

### æ¨èå­¦ä¹ è·¯å¾„

1. **å…¥é—¨** (1-2 å¤©)
   - åˆ›å»ºç¬¬ä¸€ä¸ª Agent
   - å®šä¹‰ç®€å•å·¥å…·
   - ç†è§£åŸºæœ¬æ‰§è¡Œæµç¨‹

2. **è¿›é˜¶** (1 å‘¨)
   - ä½¿ç”¨ä¸­é—´ä»¶è‡ªå®šä¹‰è¡Œä¸º
   - æ·»åŠ çŸ­æœŸè®°å¿†
   - å®ç°åŠ¨æ€æç¤ºå’Œå·¥å…·é€‰æ‹©

3. **é«˜çº§** (2-4 å‘¨)
   - æ„å»ºå¤š Agent ç³»ç»Ÿ
   - å®ç°äººæœºåä½œ
   - ä¼˜åŒ–æ€§èƒ½å’Œå®‰å…¨æ€§
   - é›†æˆé•¿æœŸè®°å¿†

### å‚è€ƒèµ„æº

- **å®˜æ–¹æ–‡æ¡£**: https://docs.langchain.com/oss/python/langchain/agents
- **API å‚è€ƒ**: https://api.python.langchain.com/
- **LangGraph æ–‡æ¡£**: https://docs.langchain.com/langgraph
- **ç¤ºä¾‹é¡¹ç›®**: https://github.com/langchain-ai/langchain/tree/master/templates

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-01-09
**åŸºäº**: LangChain v1.0 å®˜æ–¹æ–‡æ¡£

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿åé¦ˆï¼
