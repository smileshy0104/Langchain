# PyTorch åŸºç¡€æ•™ç¨‹ - å®Œæ•´å¢å¼ºç‰ˆ

> **æœ¬æ–‡æ¡£æ•´åˆäº†åŸå§‹æ•™ç¨‹ã€2024å¹´æœ€æ–°æœ€ä½³å®è·µå’Œæ·±åº¦æŠ€æœ¯ç»†èŠ‚**

---

## ğŸ“š æ–‡æ¡£ä¿¡æ¯

**åŸå§‹æ¥æº:** https://www.learnpytorch.io/00_pytorch_fundamentals/
**GitHubä»“åº“:** https://github.com/mrdbourke/pytorch-deep-learning
**æ–‡æ¡£ç‰ˆæœ¬:** v2.0 (å¢å¼ºç‰ˆ)
**æ›´æ–°æ—¥æœŸ:** 2025-11-16
**é€‚ç”¨ PyTorch ç‰ˆæœ¬:** 1.10.0+

**å¢å¼ºå†…å®¹åŒ…æ‹¬:**
- âœ… å¹¿æ’­(Broadcasting)æœºåˆ¶è¯¦è§£
- âœ… è‡ªåŠ¨å¾®åˆ†(Autograd)åŸç†ä¸å®è·µ
- âœ… GPU å†…å­˜ç®¡ç†æœ€ä½³å®è·µ
- âœ… æ€§èƒ½ä¼˜åŒ–æŠ€å·§ (2024)
- âœ… é«˜çº§å¼ é‡æ“ä½œ
- âœ… å¸¸è§é—®é¢˜ä¸è°ƒè¯•æŒ‡å—
- âœ… å®æˆ˜é¡¹ç›®ç¤ºä¾‹

---

## ğŸ“– ç›®å½•

### ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€çŸ¥è¯†
1. [ä»€ä¹ˆæ˜¯ PyTorch](#1-ä»€ä¹ˆæ˜¯-pytorch)
2. [PyTorch çš„åº”ç”¨](#2-pytorch-çš„åº”ç”¨)
3. [ä¸ºä»€ä¹ˆä½¿ç”¨ PyTorch](#3-ä¸ºä»€ä¹ˆä½¿ç”¨-pytorch)
4. [å¼ é‡(Tensor)ç®€ä»‹](#4-å¼ é‡tensorç®€ä»‹)
5. [åˆ›å»ºå¼ é‡](#5-åˆ›å»ºå¼ é‡)

### ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ“ä½œ
6. [å¼ é‡æ“ä½œ](#6-å¼ é‡æ“ä½œ)
7. [çŸ©é˜µä¹˜æ³•](#7-çŸ©é˜µä¹˜æ³•)
8. [å¼ é‡èšåˆæ“ä½œ](#8-å¼ é‡èšåˆæ“ä½œ)
9. [å¼ é‡é‡å¡‘ä¸å˜æ¢](#9-å¼ é‡é‡å¡‘ä¸å˜æ¢)
10. [ç´¢å¼•æ“ä½œ](#10-ç´¢å¼•æ“ä½œ)

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§ä¸»é¢˜
11. [å¹¿æ’­æœºåˆ¶è¯¦è§£](#11-å¹¿æ’­æœºåˆ¶è¯¦è§£) â­ **æ–°å¢**
12. [è‡ªåŠ¨å¾®åˆ† Autograd](#12-è‡ªåŠ¨å¾®åˆ†-autograd) â­ **æ–°å¢**
13. [PyTorch ä¸ NumPy](#13-pytorch-ä¸-numpy)
14. [å¯é‡å¤æ€§(Reproducibility)](#14-å¯é‡å¤æ€§reproducibility)

### ç¬¬å››éƒ¨åˆ†ï¼šGPU åŠ é€Ÿ
15. [åœ¨ GPU ä¸Šè¿è¡Œ](#15-åœ¨-gpu-ä¸Šè¿è¡Œ)
16. [GPU å†…å­˜ç®¡ç†](#16-gpu-å†…å­˜ç®¡ç†) â­ **æ–°å¢**
17. [æ€§èƒ½ä¼˜åŒ–æŠ€å·§](#17-æ€§èƒ½ä¼˜åŒ–æŠ€å·§) â­ **æ–°å¢**

### ç¬¬äº”éƒ¨åˆ†ï¼šå®æˆ˜ä¸è¿›é˜¶
18. [å¸¸è§é—®é¢˜ä¸è°ƒè¯•](#18-å¸¸è§é—®é¢˜ä¸è°ƒè¯•) â­ **æ–°å¢**
19. [å®æˆ˜é¡¹ç›®ç¤ºä¾‹](#19-å®æˆ˜é¡¹ç›®ç¤ºä¾‹) â­ **æ–°å¢**
20. [ç»ƒä¹ ä¸èµ„æº](#20-ç»ƒä¹ ä¸èµ„æº)

---

# ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€çŸ¥è¯†

## 1. ä»€ä¹ˆæ˜¯ PyTorch

### 1.1 å®šä¹‰

**PyTorch** æ˜¯ä¸€ä¸ªå¼€æºçš„æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¡†æ¶,ç”± Facebook AI Research (ç° Meta AI) å¼€å‘ã€‚

### 1.2 ä¸»è¦ç‰¹ç‚¹

| ç‰¹ç‚¹ | è¯´æ˜ | ä¼˜åŠ¿ |
|------|------|------|
| **Python åŸç”Ÿ** | å®Œå…¨åŸºäº Python | æ˜“äºå­¦ä¹ å’Œä½¿ç”¨ |
| **åŠ¨æ€è®¡ç®—å›¾** | Define-by-Run | çµæ´»,æ˜“äºè°ƒè¯• |
| **è‡ªåŠ¨å¾®åˆ†** | Autograd å¼•æ“ | è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ |
| **GPU åŠ é€Ÿ** | CUDA æ”¯æŒ | è®­ç»ƒé€Ÿåº¦å¿« |
| **ç”Ÿæ€ä¸°å¯Œ** | å¤§é‡åº“å’Œå·¥å…· | é€‚åˆç ”ç©¶å’Œç”Ÿäº§ |

### 1.3 PyTorch vs å…¶ä»–æ¡†æ¶

```python
# PyTorch - åŠ¨æ€å›¾,ç›´è§‚
for epoch in range(epochs):
    output = model(x)  # å®šä¹‰å³è¿è¡Œ
    loss = criterion(output, y)
    loss.backward()  # åŠ¨æ€æ„å»ºè®¡ç®—å›¾
    optimizer.step()

# TensorFlow 1.x - é™æ€å›¾,éœ€è¦å…ˆå®šä¹‰
# graph = tf.Graph()
# with graph.as_default():
#     x = tf.placeholder(...)
#     y = tf.placeholder(...)
#     loss = ...
# with tf.Session(graph=graph) as sess:
#     sess.run(...)
```

### 1.4 è°åœ¨ä½¿ç”¨ PyTorch

**ç§‘æŠ€å…¬å¸:**
- **Meta (Facebook)** - æ¨èç³»ç»Ÿã€å†…å®¹ç†è§£
- **Tesla** - è‡ªåŠ¨é©¾é©¶(Autopilot å’Œ FSD)
- **Microsoft** - Azure ML æœåŠ¡
- **OpenAI** - GPT ç³»åˆ—æ¨¡å‹
- **Uber** - Pyro (æ¦‚ç‡ç¼–ç¨‹)

**ç ”ç©¶æœºæ„:**
- Stanford, MIT, CMU ç­‰é¡¶çº§é«˜æ ¡
- DeepMind, Google Brain çš„éƒ¨åˆ†ç ”ç©¶

**ç»Ÿè®¡æ•°æ® (2024):**
- Papers with Code: 70%+ çš„è®ºæ–‡ä½¿ç”¨ PyTorch
- GitHub: 60,000+ star
- ä¸‹è½½é‡: æ¯æœˆè¶…è¿‡ 1000 ä¸‡æ¬¡

![PyTorchåœ¨å·¥ä¸šå’Œç ”ç©¶ä¸­çš„åº”ç”¨](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)

---

## 2. PyTorch çš„åº”ç”¨

### 2.1 è®¡ç®—æœºè§†è§‰ (Computer Vision)

```python
# å›¾åƒåˆ†ç±»
import torch
import torchvision

# é¢„è®­ç»ƒæ¨¡å‹
model = torchvision.models.resnet50(pretrained=True)
model.eval()

# åŠ è½½å›¾åƒ
from PIL import Image
from torchvision import transforms

image = Image.open('cat.jpg')
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

input_tensor = preprocess(image)
input_batch = input_tensor.unsqueeze(0)

# æ¨ç†
with torch.no_grad():
    output = model(input_batch)

# è·å–é¢„æµ‹ç±»åˆ«
_, predicted_idx = torch.max(output, 1)
print(f"Predicted class: {predicted_idx.item()}")
```

**åº”ç”¨åœºæ™¯:**
- å›¾åƒåˆ†ç±» (ImageNet, CIFAR-10)
- ç›®æ ‡æ£€æµ‹ (YOLO, Faster R-CNN)
- è¯­ä¹‰åˆ†å‰² (U-Net, DeepLab)
- äººè„¸è¯†åˆ«
- åŒ»å­¦å›¾åƒåˆ†æ

### 2.2 è‡ªç„¶è¯­è¨€å¤„ç† (NLP)

```python
# æ–‡æœ¬ç”Ÿæˆ (ä½¿ç”¨ Hugging Face Transformers)
from transformers import GPT2LMHeadModel, GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

# ç”Ÿæˆæ–‡æœ¬
input_text = "PyTorch is"
input_ids = tokenizer.encode(input_text, return_tensors='pt')

# ç”Ÿæˆ
output = model.generate(
    input_ids,
    max_length=50,
    num_return_sequences=1,
    temperature=0.7
)

generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
print(generated_text)
```

**åº”ç”¨åœºæ™¯:**
- è¯­è¨€æ¨¡å‹ (GPT, BERT)
- æœºå™¨ç¿»è¯‘
- é—®ç­”ç³»ç»Ÿ
- æƒ…æ„Ÿåˆ†æ
- æ–‡æœ¬æ‘˜è¦

### 2.3 è¯­éŸ³è¯†åˆ« (Speech Recognition)

```python
# ä½¿ç”¨ torchaudio
import torchaudio

# åŠ è½½éŸ³é¢‘
waveform, sample_rate = torchaudio.load("speech.wav")

# æå– MFCC ç‰¹å¾
mfcc_transform = torchaudio.transforms.MFCC(
    sample_rate=sample_rate,
    n_mfcc=13
)

mfcc = mfcc_transform(waveform)
print(f"MFCC shape: {mfcc.shape}")
```

**åº”ç”¨åœºæ™¯:**
- è¯­éŸ³è¯†åˆ« (ASR)
- è¯­éŸ³åˆæˆ (TTS)
- å£°çº¹è¯†åˆ«
- éŸ³ä¹ç”Ÿæˆ

### 2.4 å¼ºåŒ–å­¦ä¹  (Reinforcement Learning)

```python
# Deep Q-Learning ç¤ºä¾‹
import torch
import torch.nn as nn

class DQN(nn.Module):
    def __init__(self, state_dim, action_dim):
        super(DQN, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(state_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, action_dim)
        )

    def forward(self, state):
        return self.network(state)

# åˆ›å»ºæ¨¡å‹
state_dim = 4  # CartPole ç¯å¢ƒ
action_dim = 2
model = DQN(state_dim, action_dim)

# é€‰æ‹©åŠ¨ä½œ
state = torch.randn(1, state_dim)
q_values = model(state)
action = q_values.argmax(dim=1)
print(f"Selected action: {action.item()}")
```

**åº”ç”¨åœºæ™¯:**
- æ¸¸æˆ AI (AlphaGo, Dota 2)
- æœºå™¨äººæ§åˆ¶
- è‡ªåŠ¨é©¾é©¶
- èµ„æºè°ƒåº¦

### 2.5 ç”Ÿæˆæ¨¡å‹ (Generative Models)

```python
# GAN ç”Ÿæˆå™¨ç¤ºä¾‹
class Generator(nn.Module):
    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):
        super(Generator, self).__init__()
        self.img_shape = img_shape

        def block(in_feat, out_feat, normalize=True):
            layers = [nn.Linear(in_feat, out_feat)]
            if normalize:
                layers.append(nn.BatchNorm1d(out_feat, 0.8))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *block(latent_dim, 128, normalize=False),
            *block(128, 256),
            *block(256, 512),
            *block(512, 1024),
            nn.Linear(1024, int(np.prod(img_shape))),
            nn.Tanh()
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *self.img_shape)
        return img
```

**åº”ç”¨åœºæ™¯:**
- å›¾åƒç”Ÿæˆ (StyleGAN, DALL-E)
- æ–‡æœ¬ç”Ÿæˆ (GPT)
- éŸ³ä¹ç”Ÿæˆ
- è§†é¢‘ç”Ÿæˆ

---

## 3. ä¸ºä»€ä¹ˆä½¿ç”¨ PyTorch

### 3.1 ä¸»è¦ä¼˜åŠ¿

#### 1. **ç ”ç©¶è€…çš„é¦–é€‰**

```
Papers with Code æ¡†æ¶è¶‹åŠ¿ (2024):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PyTorch:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 72% â”‚
â”‚ TensorFlow: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 18%            â”‚
â”‚ JAX:       â–ˆâ–ˆâ–ˆâ–ˆ 7%                  â”‚
â”‚ å…¶ä»–:      â–ˆ 3%                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**åŸå› :**
- ä»£ç ç®€æ´ç›´è§‚
- è°ƒè¯•å®¹æ˜“ (Python åŸç”Ÿè°ƒè¯•å™¨)
- å¿«é€ŸåŸå‹å¼€å‘
- ç¤¾åŒºæ´»è·ƒ

#### 2. **Pythonic è®¾è®¡**

```python
# PyTorch ä»£ç è¯»èµ·æ¥åƒ Python
import torch

# åˆ›å»ºå¼ é‡
x = torch.tensor([1, 2, 3])

# æ“ä½œç›´è§‚
y = x + 10
z = x * 2

# æ§åˆ¶æµè‡ªç„¶
for i in range(len(x)):
    if x[i] > 1:
        x[i] = x[i] ** 2

print(x)  # tensor([1, 4, 9])
```

#### 3. **åŠ¨æ€è®¡ç®—å›¾**

```python
# åŠ¨æ€å›¾çš„ä¼˜åŠ¿: å¯ä»¥ä½¿ç”¨ Python æ§åˆ¶æµ

def forward(x, condition):
    if condition:
        # åˆ†æ”¯ A
        return x * 2
    else:
        # åˆ†æ”¯ B
        return x + 10

x = torch.tensor([5.0], requires_grad=True)

# è¿è¡Œæ—¶å†³å®šè·¯å¾„
output = forward(x, condition=True)
output.backward()
print(x.grad)  # tensor([2.])  # å¯¹åº” x*2 çš„æ¢¯åº¦

# æ”¹å˜æ¡ä»¶
x.grad.zero_()
output = forward(x, condition=False)
output.backward()
print(x.grad)  # tensor([1.])  # å¯¹åº” x+10 çš„æ¢¯åº¦
```

**å¯¹æ¯”é™æ€å›¾:**
- TensorFlow 1.x éœ€è¦é¢„å…ˆå®šä¹‰æ•´ä¸ªå›¾
- æ— æ³•åœ¨è¿è¡Œæ—¶æ”¹å˜ç½‘ç»œç»“æ„
- è°ƒè¯•å›°éš¾

#### 4. **å¼ºå¤§çš„ GPU åŠ é€Ÿ**

```python
# è‡ªåŠ¨å¤„ç† GPU åŠ é€Ÿ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ¨¡å‹å’Œæ•°æ®ç§»åˆ° GPU (ä¸€è¡Œä»£ç )
model = MyModel().to(device)
data = data.to(device)

# PyTorch è‡ªåŠ¨åœ¨ GPU ä¸Šæ‰§è¡Œ
output = model(data)  # åœ¨ GPU ä¸Šè¿è¡Œ

# æ€§èƒ½å¯¹æ¯” (ç¤ºä¾‹)
# CPU: 100ç§’/epoch
# GPU: 5ç§’/epoch  (20x åŠ é€Ÿ!)
```

#### 5. **ç”Ÿäº§å°±ç»ª**

```python
# TorchScript: å°†æ¨¡å‹å¯¼å‡ºä¸ºä¼˜åŒ–çš„æ ¼å¼
import torch.jit

# æ–¹æ³• 1: Tracing
model = MyModel()
example_input = torch.rand(1, 3, 224, 224)
traced_model = torch.jit.trace(model, example_input)

# ä¿å­˜
traced_model.save("model.pt")

# åŠ è½½ (C++ ç¯å¢ƒä¹Ÿå¯ä»¥åŠ è½½)
loaded_model = torch.jit.load("model.pt")

# æ–¹æ³• 2: Scripting (æ”¯æŒæ§åˆ¶æµ)
@torch.jit.script
def my_function(x, y):
    if x.sum() > 0:
        return x + y
    else:
        return x - y
```

**ç”Ÿäº§éƒ¨ç½²å·¥å…·:**
- **TorchScript**: æ¨¡å‹åºåˆ—åŒ–å’Œä¼˜åŒ–
- **TorchServe**: æ¨¡å‹æœåŠ¡æ¡†æ¶
- **ONNX**: è·¨æ¡†æ¶æ¨¡å‹äº¤æ¢æ ¼å¼
- **Mobile**: iOS/Android éƒ¨ç½²

#### 6. **ä¸°å¯Œçš„ç”Ÿæ€ç³»ç»Ÿ**

```
PyTorch ç”Ÿæ€ç³»ç»Ÿ:
â”œâ”€â”€ torchvision     (è®¡ç®—æœºè§†è§‰)
â”œâ”€â”€ torchtext       (è‡ªç„¶è¯­è¨€å¤„ç†)
â”œâ”€â”€ torchaudio      (éŸ³é¢‘å¤„ç†)
â”œâ”€â”€ torchmetrics    (è¯„ä¼°æŒ‡æ ‡)
â”œâ”€â”€ pytorch-lightning (é«˜å±‚API)
â”œâ”€â”€ fastai          (å¿«é€Ÿå¼€å‘)
â”œâ”€â”€ transformers    (é¢„è®­ç»ƒæ¨¡å‹)
â”œâ”€â”€ detectron2      (ç›®æ ‡æ£€æµ‹)
â””â”€â”€ ...
```

### 3.2 PyTorch 2.0 æ–°ç‰¹æ€§ (2024)

```python
# torch.compile - å›¾ç¼–è¯‘åŠ é€Ÿ
import torch

model = MyModel()

# ç¼–è¯‘æ¨¡å‹ (ç®€å•ä¸€è¡Œ)
compiled_model = torch.compile(model)

# ä½¿ç”¨ç¼–è¯‘åçš„æ¨¡å‹ (API ä¸å˜)
output = compiled_model(input)

# æ€§èƒ½æå‡:
# - è®­ç»ƒé€Ÿåº¦: 1.3-2x
# - æ¨ç†é€Ÿåº¦: 1.5-3x
```

**æ–°ç‰¹æ€§:**
- **torch.compile()**: è‡ªåŠ¨ä¼˜åŒ–æ¨¡å‹
- **æ”¹è¿›çš„åˆ†å¸ƒå¼è®­ç»ƒ**: FSDP, DDP ä¼˜åŒ–
- **æ›´å¥½çš„ AMD GPU æ”¯æŒ**
- **Metal (Apple Silicon) æ€§èƒ½æå‡**

---

## 4. å¼ é‡(Tensor)ç®€ä»‹

### 4.1 ä»€ä¹ˆæ˜¯å¼ é‡?

**å¼ é‡æ˜¯æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åŸºæœ¬æ„å»ºå—ã€‚**

**æ•°å­¦å®šä¹‰:** å¼ é‡æ˜¯å¤šç»´æ•°ç»„,æ˜¯æ ‡é‡ã€å‘é‡ã€çŸ©é˜µçš„æ¨å¹¿ã€‚

**ç›´è§‚ç†è§£:**
```
æ ‡é‡(0D) â†’ å‘é‡(1D) â†’ çŸ©é˜µ(2D) â†’ å¼ é‡(3D+)
   7    â†’  [7,7]  â†’  [[7,8],  â†’ [[[1,2,3],
                       [9,10]]    [4,5,6]],
                                 [[7,8,9],
                                  [0,1,2]]]
```

### 4.2 å¼ é‡çš„ä½œç”¨

**æ ¸å¿ƒæ€æƒ³:** å°†ç°å®ä¸–ç•Œçš„æ•°æ®è½¬æ¢ä¸ºæ•°å­—,ä»¥ä¾¿è®¡ç®—æœºå¤„ç†ã€‚

| æ•°æ®ç±»å‹ | å¼ é‡è¡¨ç¤º | å½¢çŠ¶ç¤ºä¾‹ |
|---------|---------|---------|
| **æ•°å­—** | æ ‡é‡ | `()` |
| **æ—¶é—´åºåˆ—** | å‘é‡ | `(100,)` |
| **ç°åº¦å›¾åƒ** | çŸ©é˜µ | `(28, 28)` |
| **å½©è‰²å›¾åƒ** | 3D å¼ é‡ | `(3, 224, 224)` |
| **è§†é¢‘** | 4D å¼ é‡ | `(30, 3, 224, 224)` |
| **æ‰¹é‡å›¾åƒ** | 4D å¼ é‡ | `(32, 3, 224, 224)` |

### 4.3 å¼ é‡ç»´åº¦è¯¦è§£

#### ç»´åº¦ (Dimension) vs è½´ (Axis)

```python
import torch

# 3D å¼ é‡
tensor_3d = torch.tensor([
    [[1, 2], [3, 4]],
    [[5, 6], [7, 8]]
])

print(f"ç»´åº¦æ•° (ndim): {tensor_3d.ndim}")  # 3
print(f"å½¢çŠ¶ (shape): {tensor_3d.shape}")  # torch.Size([2, 2, 2])

# ç†è§£:
# - ç»´åº¦æ•° = 3 (3D å¼ é‡)
# - è½´ 0 å¤§å° = 2
# - è½´ 1 å¤§å° = 2
# - è½´ 2 å¤§å° = 2
```

**å¯è§†åŒ–:**
```
tensor_3d.shape = (2, 2, 2)
                   â†‘  â†‘  â†‘
                   â”‚  â”‚  â””â”€ è½´ 2 (æœ€å†…å±‚)
                   â”‚  â””â”€â”€â”€â”€ è½´ 1 (ä¸­é—´å±‚)
                   â””â”€â”€â”€â”€â”€â”€â”€ è½´ 0 (æœ€å¤–å±‚)
```

### 4.4 å›¾åƒåˆ°å¼ é‡çš„è½¬æ¢

![å›¾åƒåˆ°å¼ é‡çš„è½¬æ¢ç¤ºä¾‹](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)

```python
from PIL import Image
import torchvision.transforms as transforms

# åŠ è½½å›¾åƒ
image = Image.open("cat.jpg")  # RGB å›¾åƒ

# è½¬æ¢ä¸ºå¼ é‡
to_tensor = transforms.ToTensor()
tensor = to_tensor(image)

print(f"å½¢çŠ¶: {tensor.shape}")  # torch.Size([3, 224, 224])
print(f"æ•°æ®ç±»å‹: {tensor.dtype}")  # torch.float32
print(f"å€¼èŒƒå›´: [{tensor.min()}, {tensor.max()}]")  # [0.0, 1.0]

# è§£é‡Šå½¢çŠ¶:
# [3, 224, 224]
#  â†‘   â†‘    â†‘
#  â”‚   â”‚    â””â”€ å®½åº¦ (åƒç´ )
#  â”‚   â””â”€â”€â”€â”€â”€â”€ é«˜åº¦ (åƒç´ )
#  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¢œè‰²é€šé“ (R, G, B)
```

**é€šé“é¡ºåº:**
- PyTorch/torchvision: `(C, H, W)` - Channels First
- PIL/NumPy/Matplotlib: `(H, W, C)` - Channels Last

```python
# è½¬æ¢é€šé“é¡ºåº
tensor_chw = tensor  # (C, H, W)
tensor_hwc = tensor.permute(1, 2, 0)  # (H, W, C)

print(tensor_chw.shape)  # torch.Size([3, 224, 224])
print(tensor_hwc.shape)  # torch.Size([224, 224, 3])
```

### 4.5 å¼ é‡ç±»å‹æ€»ç»“

![ä¸åŒå¼ é‡ç»´åº¦ç¤ºä¾‹](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)

| åç§° | ç»´åº¦ | å½¢çŠ¶ç¤ºä¾‹ | ç”¨é€” | ä»£ç ç¤ºä¾‹ |
|------|------|---------|------|---------|
| **Scalar** | 0D | `()` | å•ä¸ªå€¼ | `loss = 0.5` |
| **Vector** | 1D | `(n,)` | åºåˆ—æ•°æ® | `embeddings = (768,)` |
| **Matrix** | 2D | `(m, n)` | è¡¨æ ¼æ•°æ® | `weights = (512, 256)` |
| **3D Tensor** | 3D | `(a, b, c)` | å›¾åƒ/è§†é¢‘å¸§ | `image = (3, 224, 224)` |
| **4D Tensor** | 4D | `(a, b, c, d)` | æ‰¹é‡å›¾åƒ | `batch = (32, 3, 224, 224)` |
| **5D Tensor** | 5D | `(a, b, c, d, e)` | æ‰¹é‡è§†é¢‘ | `video_batch = (8, 30, 3, 224, 224)` |

![æ ‡é‡ã€å‘é‡ã€çŸ©é˜µã€å¼ é‡ç¤ºæ„å›¾](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)

### 4.6 åˆ¤æ–­å¼ é‡ç»´åº¦çš„æŠ€å·§

**æ–¹æ³• 1: æ•°æ–¹æ‹¬å·**

```python
# æ•°å·¦ä¾§çš„ [ æ•°é‡
scalar = 7                    # 0 ä¸ª [ â†’ 0D
vector = [7, 7]              # 1 ä¸ª [ â†’ 1D
matrix = [[7, 8], [9, 10]]   # 2 ä¸ª [ â†’ 2D
tensor = [[[1, 2]]]          # 3 ä¸ª [ â†’ 3D
```

**æ–¹æ³• 2: ä½¿ç”¨ .ndim**

```python
import torch

x = torch.tensor([[[1, 2]]])
print(x.ndim)  # 3
```

**æ–¹æ³• 3: çœ‹å½¢çŠ¶é•¿åº¦**

```python
x = torch.rand(2, 3, 4, 5)
print(x.shape)  # torch.Size([2, 3, 4, 5])
print(len(x.shape))  # 4 â†’ 4D å¼ é‡
```

---

## 5. åˆ›å»ºå¼ é‡

### 5.1 ä» Python æ•°æ®åˆ›å»º

#### 5.1.1 æ ‡é‡ (Scalar)

```python
import torch

# åˆ›å»ºæ ‡é‡
scalar = torch.tensor(7)

print(scalar)  # tensor(7)
print(scalar.ndim)  # 0
print(scalar.shape)  # torch.Size([])
print(scalar.item())  # 7 (æå– Python æ•°å­—)

# æ ‡é‡çš„è¿ç®—
a = torch.tensor(5)
b = torch.tensor(3)
c = a + b
print(c.item())  # 8
```

**æ³¨æ„:** `.item()` åªèƒ½ç”¨äºå•ä¸ªå…ƒç´ çš„å¼ é‡!

```python
vector = torch.tensor([1, 2, 3])
# vector.item()  # é”™è¯¯! å¤šä¸ªå…ƒç´ æ— æ³•ä½¿ç”¨ item()
```

#### 5.1.2 å‘é‡ (Vector)

```python
# åˆ›å»ºå‘é‡
vector = torch.tensor([7, 7])

print(vector)  # tensor([7, 7])
print(vector.ndim)  # 1
print(vector.shape)  # torch.Size([2])

# è®¿é—®å…ƒç´ 
print(vector[0])  # tensor(7)
print(vector[0].item())  # 7

# å‘é‡è¿ç®—
v1 = torch.tensor([1, 2, 3])
v2 = torch.tensor([4, 5, 6])

# å…ƒç´ ç›¸åŠ 
print(v1 + v2)  # tensor([5, 7, 9])

# ç‚¹ç§¯
dot_product = torch.dot(v1.float(), v2.float())
print(dot_product)  # tensor(32.)  # 1*4 + 2*5 + 3*6
```

#### 5.1.3 çŸ©é˜µ (Matrix)

```python
# åˆ›å»ºçŸ©é˜µ
MATRIX = torch.tensor([[7, 8],
                       [9, 10]])

print(MATRIX)
# tensor([[ 7,  8],
#         [ 9, 10]])

print(MATRIX.ndim)  # 2
print(MATRIX.shape)  # torch.Size([2, 2])

# è®¿é—®å…ƒç´ 
print(MATRIX[0])  # tensor([7, 8])  # ç¬¬ä¸€è¡Œ
print(MATRIX[0, 1])  # tensor(8)  # ç¬¬ä¸€è¡Œç¬¬äºŒåˆ—
print(MATRIX[:, 0])  # tensor([7, 9])  # ç¬¬ä¸€åˆ—

# çŸ©é˜µè¿ç®—
A = torch.tensor([[1, 2], [3, 4]])
B = torch.tensor([[5, 6], [7, 8]])

# å…ƒç´ ç›¸ä¹˜
print(A * B)
# tensor([[ 5, 12],
#         [21, 32]])

# çŸ©é˜µä¹˜æ³•
print(torch.matmul(A, B))
# tensor([[19, 22],
#         [43, 50]])
```

#### 5.1.4 å¼ é‡ (Tensor)

```python
# åˆ›å»º 3D å¼ é‡
TENSOR = torch.tensor([[[1, 2, 3],
                        [4, 5, 6],
                        [7, 8, 9]],
                       [[10, 11, 12],
                        [13, 14, 15],
                        [16, 17, 18]]])

print(TENSOR)
print(TENSOR.ndim)  # 3
print(TENSOR.shape)  # torch.Size([2, 3, 3])

# ç†è§£å½¢çŠ¶
print(f"è½´ 0 å¤§å° (æ·±åº¦): {TENSOR.shape[0]}")  # 2
print(f"è½´ 1 å¤§å° (è¡Œ):   {TENSOR.shape[1]}")  # 3
print(f"è½´ 2 å¤§å° (åˆ—):   {TENSOR.shape[2]}")  # 3

# è®¿é—®å…ƒç´ 
print(TENSOR[0])  # ç¬¬ä¸€ä¸ª 3x3 çŸ©é˜µ
print(TENSOR[0, 1])  # ç¬¬ä¸€ä¸ªçŸ©é˜µçš„ç¬¬äºŒè¡Œ
print(TENSOR[0, 1, 2])  # å•ä¸ªå…ƒç´ : tensor(6)
```

### 5.2 åˆ›å»ºç‰¹æ®Šå¼ é‡

#### 5.2.1 éšæœºå¼ é‡

```python
# å‡åŒ€åˆ†å¸ƒ [0, 1)
random_tensor = torch.rand(3, 4)
print(random_tensor)
print(random_tensor.shape)  # torch.Size([3, 4])

# æ ‡å‡†æ­£æ€åˆ†å¸ƒ N(0, 1)
normal_tensor = torch.randn(3, 4)
print(normal_tensor)

# éšæœºæ•´æ•° [low, high)
int_tensor = torch.randint(low=0, high=10, size=(3, 4))
print(int_tensor)

# éšæœºæ’åˆ—
perm = torch.randperm(10)
print(perm)  # tensor([3, 7, 1, 9, 0, 5, 2, 8, 4, 6])
```

**ä¸ºä»€ä¹ˆéœ€è¦éšæœºå¼ é‡?**

```python
# ç¥ç»ç½‘ç»œåˆå§‹åŒ–ç¤ºä¾‹
class SimpleNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        # æƒé‡éšæœºåˆå§‹åŒ–
        self.weights = torch.randn(10, 5)
        self.bias = torch.randn(5)

    def forward(self, x):
        return x @ self.weights + self.bias

model = SimpleNN()
print(model.weights)  # éšæœºåˆå§‹åŒ–çš„æƒé‡
```

#### 5.2.2 å…¨é›¶å’Œå…¨ä¸€å¼ é‡

```python
# å…¨é›¶å¼ é‡
zeros = torch.zeros(3, 4)
print(zeros)
# tensor([[0., 0., 0., 0.],
#         [0., 0., 0., 0.],
#         [0., 0., 0., 0.]])

# å…¨ä¸€å¼ é‡
ones = torch.ones(3, 4)
print(ones)

# æŒ‡å®šæ•°æ®ç±»å‹
zeros_int = torch.zeros(3, 4, dtype=torch.int32)
print(zeros_int.dtype)  # torch.int32

# åˆ›å»ºä¸å¦ä¸€ä¸ªå¼ é‡å½¢çŠ¶ç›¸åŒçš„å¼ é‡
x = torch.rand(2, 3)
zeros_like = torch.zeros_like(x)
ones_like = torch.ones_like(x)

print(zeros_like.shape)  # torch.Size([2, 3])
```

#### 5.2.3 èŒƒå›´å¼ é‡

```python
# torch.arange(start, end, step)
range_tensor = torch.arange(0, 10, 1)
print(range_tensor)  # tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

# æµ®ç‚¹æ•°èŒƒå›´
float_range = torch.arange(0, 1, 0.1)
print(float_range)
# tensor([0.0000, 0.1000, 0.2000, ..., 0.9000])

# torch.linspace(start, end, steps) - çº¿æ€§é—´éš”
linspace_tensor = torch.linspace(0, 10, steps=5)
print(linspace_tensor)
# tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])

# torch.logspace(start, end, steps) - å¯¹æ•°é—´éš”
logspace_tensor = torch.logspace(0, 2, steps=5)
print(logspace_tensor)
# tensor([  1.0000,   3.1623,  10.0000,  31.6228, 100.0000])
```

#### 5.2.4 å¯¹è§’å¼ é‡å’Œå•ä½çŸ©é˜µ

```python
# å¯¹è§’çŸ©é˜µ
diag = torch.diag(torch.tensor([1, 2, 3, 4]))
print(diag)
# tensor([[1, 0, 0, 0],
#         [0, 2, 0, 0],
#         [0, 0, 3, 0],
#         [0, 0, 0, 4]])

# å•ä½çŸ©é˜µ
identity = torch.eye(4)
print(identity)
# tensor([[1., 0., 0., 0.],
#         [0., 1., 0., 0.],
#         [0., 0., 1., 0.],
#         [0., 0., 0., 1.]])
```

#### 5.2.5 å¸¸æ•°å¼ é‡

```python
# å¡«å……æŒ‡å®šå€¼
full_tensor = torch.full((3, 4), fill_value=7.5)
print(full_tensor)
# tensor([[7.5000, 7.5000, 7.5000, 7.5000],
#         [7.5000, 7.5000, 7.5000, 7.5000],
#         [7.5000, 7.5000, 7.5000, 7.5000]])

# å¤æ‚å€¼å¡«å……
full_complex = torch.full((2, 2), 3+4j)
print(full_complex)
# tensor([[3.+4.j, 3.+4.j],
#         [3.+4.j, 3.+4.j]])
```

### 5.3 å¼ é‡æ•°æ®ç±»å‹

#### 5.3.1 å¸¸ç”¨æ•°æ®ç±»å‹

| PyTorch ç±»å‹ | ç­‰ä»· NumPy | ä½æ•° | èŒƒå›´/ç²¾åº¦ |
|-------------|-----------|------|----------|
| `torch.float32` | `np.float32` | 32ä½ | å•ç²¾åº¦æµ®ç‚¹(é»˜è®¤) |
| `torch.float64` | `np.float64` | 64ä½ | åŒç²¾åº¦æµ®ç‚¹ |
| `torch.float16` | `np.float16` | 16ä½ | åŠç²¾åº¦æµ®ç‚¹ |
| `torch.bfloat16` | - | 16ä½ | Brain Float (Google TPU) |
| `torch.int64` | `np.int64` | 64ä½ | é•¿æ•´å‹ |
| `torch.int32` | `np.int32` | 32ä½ | æ•´å‹ |
| `torch.int16` | `np.int16` | 16ä½ | çŸ­æ•´å‹ |
| `torch.int8` | `np.int8` | 8ä½ | å­—èŠ‚ |
| `torch.uint8` | `np.uint8` | 8ä½ | æ— ç¬¦å·å­—èŠ‚ |
| `torch.bool` | `np.bool_` | 1ä½ | å¸ƒå°”å€¼ |

#### 5.3.2 åˆ›å»ºç‰¹å®šç±»å‹çš„å¼ é‡

```python
# é»˜è®¤ç±»å‹ (float32)
default_tensor = torch.tensor([3.0, 6.0, 9.0])
print(default_tensor.dtype)  # torch.float32

# æŒ‡å®šç±»å‹
float16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)
print(float16_tensor.dtype)  # torch.float16

# æ•´æ•°
int_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)
print(int_tensor.dtype)  # torch.int32

# å¸ƒå°”
bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)
print(bool_tensor.dtype)  # torch.bool

# å¤æ•°
complex_tensor = torch.tensor([1+2j, 3+4j], dtype=torch.complex64)
print(complex_tensor.dtype)  # torch.complex64
```

#### 5.3.3 ç±»å‹è½¬æ¢

```python
# åˆ›å»º float32 å¼ é‡
tensor = torch.tensor([3.0, 6.0, 9.0])
print(tensor.dtype)  # torch.float32

# æ–¹æ³• 1: .type()
tensor_float16 = tensor.type(torch.float16)
print(tensor_float16.dtype)  # torch.float16

# æ–¹æ³• 2: .to()
tensor_int = tensor.to(torch.int32)
print(tensor_int.dtype)  # torch.int32

# æ–¹æ³• 3: ä¸“ç”¨æ–¹æ³•
tensor_long = tensor.long()  # torch.int64
tensor_double = tensor.double()  # torch.float64
tensor_half = tensor.half()  # torch.float16

# æŸ¥çœ‹æ‰€æœ‰è½¬æ¢æ–¹æ³•
# .int(), .long(), .float(), .double(), .half(), .bool()
```

#### 5.3.4 ç²¾åº¦æƒè¡¡

```python
import torch
import time

# å‡†å¤‡æ•°æ®
size = (1000, 1000)

# Float32
tensor_fp32 = torch.rand(size)
start = time.time()
result_fp32 = torch.matmul(tensor_fp32, tensor_fp32)
time_fp32 = time.time() - start

# Float16
tensor_fp16 = torch.rand(size, dtype=torch.float16)
start = time.time()
result_fp16 = torch.matmul(tensor_fp16, tensor_fp16)
time_fp16 = time.time() - start

print(f"Float32 æ—¶é—´: {time_fp32:.4f}ç§’")
print(f"Float16 æ—¶é—´: {time_fp16:.4f}ç§’")
print(f"åŠ é€Ÿæ¯”: {time_fp32/time_fp16:.2f}x")

# ç²¾åº¦æŸå¤±
print(f"\nFloat32 ç»“æœèŒƒå›´: [{result_fp32.min():.6f}, {result_fp32.max():.6f}]")
print(f"Float16 ç»“æœèŒƒå›´: [{result_fp16.min():.6f}, {result_fp16.max():.6f}]")
```

**ä½¿ç”¨å»ºè®®:**
- **è®­ç»ƒ:** `torch.float32` (é»˜è®¤,å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦)
- **æ¨ç†:** `torch.float16` æˆ– `torch.bfloat16` (æ›´å¿«)
- **æ··åˆç²¾åº¦è®­ç»ƒ:** ç»“åˆ FP16 å’Œ FP32 (æœ€ä½³å®è·µ)
- **æ•´æ•°:** é‡åŒ–æ¨¡å‹(å‡å°æ¨¡å‹å¤§å°)

#### 5.3.5 æ··åˆç²¾åº¦è®­ç»ƒç¤ºä¾‹

```python
from torch.cuda.amp import autocast, GradScaler

# åˆ›å»ºæ¨¡å‹ã€ä¼˜åŒ–å™¨
model = MyModel().cuda()
optimizer = torch.optim.Adam(model.parameters())

# åˆ›å»ºæ¢¯åº¦ç¼©æ”¾å™¨
scaler = GradScaler()

for epoch in range(epochs):
    for data, target in train_loader:
        data, target = data.cuda(), target.cuda()

        optimizer.zero_grad()

        # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
        with autocast():
            output = model(data)
            loss = criterion(output, target)

        # ç¼©æ”¾æŸå¤±å¹¶åå‘ä¼ æ’­
        scaler.scale(loss).backward()

        # æ›´æ–°å‚æ•°
        scaler.step(optimizer)
        scaler.update()
```

### 5.4 å¼ é‡å±æ€§æŸ¥è¯¢

```python
# åˆ›å»ºç¤ºä¾‹å¼ é‡
tensor = torch.rand(3, 4, 5)

# é‡è¦å±æ€§
print(f"å½¢çŠ¶ (shape): {tensor.shape}")  # torch.Size([3, 4, 5])
print(f"å¤§å° (size): {tensor.size()}")  # torch.Size([3, 4, 5])
print(f"ç»´åº¦ (ndim): {tensor.ndim}")  # 3
print(f"æ•°æ®ç±»å‹ (dtype): {tensor.dtype}")  # torch.float32
print(f"è®¾å¤‡ (device): {tensor.device}")  # cpu æˆ– cuda:0
print(f"å¸ƒå±€ (layout): {tensor.layout}")  # torch.strided
print(f"å…ƒç´ æ€»æ•° (numel): {tensor.numel()}")  # 60
print(f"éœ€è¦æ¢¯åº¦ (requires_grad): {tensor.requires_grad}")  # False

# å†…å­˜å ç”¨
print(f"å…ƒç´ å¤§å° (item size): {tensor.element_size()} å­—èŠ‚")  # 4
print(f"æ€»å†…å­˜ (memory): {tensor.numel() * tensor.element_size()} å­—èŠ‚")  # 240
```

---

# ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ“ä½œ

## 6. å¼ é‡æ“ä½œ

### 6.1 è·å–å¼ é‡ä¿¡æ¯ - "ä¸‰ä¸ª W"

**è®°ä½è¿™ä¸ªå£è¯€:**

```python
# What shape?   (ä»€ä¹ˆå½¢çŠ¶)
# What datatype? (ä»€ä¹ˆæ•°æ®ç±»å‹)
# Where stored?  (å­˜å‚¨åœ¨å“ªé‡Œ)
```

```python
# åˆ›å»ºå¼ é‡
tensor = torch.rand(3, 4)

# ä¸‰ä¸ª W
print(f"What shape? {tensor.shape}")  # torch.Size([3, 4])
print(f"What datatype? {tensor.dtype}")  # torch.float32
print(f"Where stored? {tensor.device}")  # cpu
```

**ä¸ºä»€ä¹ˆé‡è¦?**
- 90% çš„PyTorché”™è¯¯éƒ½ä¸è¿™ä¸‰ä¸ªå±æ€§æœ‰å…³!
- å½¢çŠ¶ä¸åŒ¹é… â†’ RuntimeError
- ç±»å‹ä¸åŒ¹é… â†’ TypeError
- è®¾å¤‡ä¸åŒ¹é… â†’ RuntimeError

### 6.2 åŸºæœ¬ç®—æœ¯æ“ä½œ

#### 6.2.1 æ ‡é‡è¿ç®—

```python
tensor = torch.tensor([10, 20, 30])

# åŠ æ³•
print(tensor + 10)  # tensor([20, 30, 40])

# å‡æ³•
print(tensor - 10)  # tensor([0, 10, 20])

# ä¹˜æ³•
print(tensor * 10)  # tensor([100, 200, 300])

# é™¤æ³•
print(tensor / 10)  # tensor([1., 2., 3.])

# å¹‚è¿ç®—
print(tensor ** 2)  # tensor([100, 400, 900])

# å–æ¨¡
print(tensor % 7)  # tensor([3, 6, 2])
```

#### 6.2.2 å¼ é‡é—´è¿ç®—

```python
a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])

# å…ƒç´ çº§è¿ç®—
print(a + b)  # tensor([5, 7, 9])
print(a - b)  # tensor([-3, -3, -3])
print(a * b)  # tensor([4, 10, 18])
print(a / b)  # tensor([0.2500, 0.4000, 0.5000])

# æ¯”è¾ƒè¿ç®—
print(a > b)  # tensor([False, False, False])
print(a == b)  # tensor([False, False, False])
```

#### 6.2.3 PyTorch å†…ç½®å‡½æ•°

```python
tensor = torch.tensor([10, 20, 30])

# ä½¿ç”¨ PyTorch å‡½æ•° (æ¨è)
torch.add(tensor, 10)  # ç­‰åŒäº tensor + 10
torch.sub(tensor, 10)  # ç­‰åŒäº tensor - 10
torch.mul(tensor, 10)  # ç­‰åŒäº tensor * 10
torch.div(tensor, 10)  # ç­‰åŒäº tensor / 10

# å°±åœ°æ“ä½œ (inplace) - ä»¥ _ ç»“å°¾
tensor.add_(10)  # ç›´æ¥ä¿®æ”¹ tensor
print(tensor)  # tensor([20, 30, 40])

tensor.mul_(2)  # ç›´æ¥ä¿®æ”¹
print(tensor)  # tensor([40, 60, 80])
```

**å°±åœ°æ“ä½œ vs éå°±åœ°æ“ä½œ:**

```python
x = torch.tensor([1, 2, 3])

# éå°±åœ° (è¿”å›æ–°å¼ é‡)
y = x.add(10)
print(x)  # tensor([1, 2, 3])  # åŸå¼ é‡ä¸å˜
print(y)  # tensor([11, 12, 13])

# å°±åœ° (ä¿®æ”¹åŸå¼ é‡)
x.add_(10)
print(x)  # tensor([11, 12, 13])  # åŸå¼ é‡è¢«ä¿®æ”¹
```

**æ³¨æ„:** å°±åœ°æ“ä½œå¯ä»¥èŠ‚çœå†…å­˜,ä½†å¯èƒ½å¯¼è‡´æ„å¤–çš„å‰¯ä½œç”¨!

#### 6.2.4 é«˜çº§æ•°å­¦å‡½æ•°

```python
import torch
import math

# åˆ›å»ºå¼ é‡
x = torch.tensor([0.0, math.pi/4, math.pi/2, math.pi])

# ä¸‰è§’å‡½æ•°
print(torch.sin(x))
print(torch.cos(x))
print(torch.tan(x))

# æŒ‡æ•°å’Œå¯¹æ•°
y = torch.tensor([1.0, 2.0, 3.0])
print(torch.exp(y))  # e^y
print(torch.log(y))  # ln(y)
print(torch.log10(y))  # log10(y)

# å¼€æ–¹
print(torch.sqrt(y))
print(torch.pow(y, 2))  # y^2

# å–æ•´
z = torch.tensor([1.3, 2.7, -1.5])
print(torch.round(z))  # tensor([1., 3., -2.])
print(torch.floor(z))  # tensor([1., 2., -2.])
print(torch.ceil(z))  # tensor([2., 3., -1.])

# è£å‰ª
print(torch.clamp(z, min=-1, max=2))  # tensor([1.3, 2.0, -1.0])
```

### 6.3 å¼ é‡ä¸å¼ é‡è¿ç®—çš„å½¢çŠ¶è§„åˆ™

```python
# è§„åˆ™: å½¢çŠ¶å¿…é¡»å…¼å®¹

# âœ“ ç›¸åŒå½¢çŠ¶
a = torch.rand(3, 4)
b = torch.rand(3, 4)
c = a + b  # å¯ä»¥

# âœ“ å¹¿æ’­å…¼å®¹
a = torch.rand(3, 4)
b = torch.rand(1, 4)  # ä¼šå¹¿æ’­
c = a + b  # å¯ä»¥

# âœ— ä¸å…¼å®¹
a = torch.rand(3, 4)
b = torch.rand(3, 5)
# c = a + b  # é”™è¯¯! å½¢çŠ¶ä¸å…¼å®¹
```

**æˆ‘ä»¬å°†åœ¨åé¢è¯¦ç»†è®¨è®ºå¹¿æ’­æœºåˆ¶!**

---

## 7. çŸ©é˜µä¹˜æ³•

### 7.1 ä¸ºä»€ä¹ˆçŸ©é˜µä¹˜æ³•å¦‚æ­¤é‡è¦?

**ç¥ç»ç½‘ç»œ = çŸ©é˜µä¹˜æ³•çš„å †å **

![çŸ©é˜µä¹˜æ³•å°±æ˜¯ä½ æ‰€éœ€è¦çš„ä¸€åˆ‡](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)

```python
# ç®€åŒ–çš„ç¥ç»ç½‘ç»œå±‚
class LinearLayer:
    def __init__(self, in_features, out_features):
        # æƒé‡çŸ©é˜µ
        self.W = torch.randn(in_features, out_features)
        self.b = torch.randn(out_features)

    def forward(self, x):
        # æ ¸å¿ƒæ“ä½œ: çŸ©é˜µä¹˜æ³• + åç½®
        return torch.matmul(x, self.W) + self.b

# ä½¿ç”¨
layer = LinearLayer(10, 5)
x = torch.randn(1, 10)  # 1ä¸ªæ ·æœ¬, 10ä¸ªç‰¹å¾
output = layer.forward(x)  # 1ä¸ªæ ·æœ¬, 5ä¸ªè¾“å‡º
print(output.shape)  # torch.Size([1, 5])
```

### 7.2 çŸ©é˜µä¹˜æ³•è§„åˆ™

#### è§„åˆ™ 1: å†…éƒ¨ç»´åº¦å¿…é¡»åŒ¹é…

```python
# (m, n) @ (n, p) = (m, p)
#      â†‘    â†‘
#      å¿…é¡»ç›¸åŒ

# âœ“ å¯ä»¥
A = torch.rand(3, 2)
B = torch.rand(2, 4)
C = torch.matmul(A, B)  # (3, 2) @ (2, 4) = (3, 4)

# âœ— ä¸å¯ä»¥
A = torch.rand(3, 2)
B = torch.rand(3, 4)
# C = torch.matmul(A, B)  # é”™è¯¯! 2 != 3
```

#### è§„åˆ™ 2: ç»“æœå½¢çŠ¶æ˜¯å¤–éƒ¨ç»´åº¦

```python
# (m, n) @ (n, p) = (m, p)
#  â†‘         â†‘      â†‘    â†‘
#  å¤–        å¤–      ç»“æœå½¢çŠ¶

A = torch.rand(5, 3)
B = torch.rand(3, 7)
C = torch.matmul(A, B)
print(C.shape)  # torch.Size([5, 7])
```

### 7.3 å…ƒç´ ä¹˜æ³• vs çŸ©é˜µä¹˜æ³•

```python
tensor = torch.tensor([1, 2, 3])

# å…ƒç´ ä¹˜æ³• (element-wise multiplication)
element_wise = tensor * tensor
print(element_wise)  # tensor([1, 4, 9])

# çŸ©é˜µä¹˜æ³• (ç‚¹ç§¯)
matrix_mul = torch.matmul(tensor, tensor)
print(matrix_mul)  # tensor(14)  # 1*1 + 2*2 + 3*3 = 14

# ä¹Ÿå¯ä»¥ç”¨ @ è¿ç®—ç¬¦
matrix_mul2 = tensor @ tensor
print(matrix_mul2)  # tensor(14)
```

| æ“ä½œ | ç¬¦å· | å‡½æ•° | è¾“å…¥å½¢çŠ¶ | è¾“å‡ºå½¢çŠ¶ | è®¡ç®— |
|------|------|------|---------|---------|------|
| **å…ƒç´ ä¹˜æ³•** | `*` | `torch.mul()` | `(n,) * (n,)` | `(n,)` | `[a*b for a,b in zip(...)]` |
| **ç‚¹ç§¯** | `@` | `torch.dot()` | `(n,) @ (n,)` | `()` | `sum(a*b for a,b in zip(...))` |
| **çŸ©é˜µä¹˜æ³•** | `@` | `torch.matmul()` | `(m,n) @ (n,p)` | `(m,p)` | çŸ©é˜µä¹˜æ³•è§„åˆ™ |

### 7.4 çŸ©é˜µä¹˜æ³•çš„å¤šç§æ–¹æ³•

```python
A = torch.rand(3, 2)
B = torch.rand(2, 4)

# æ–¹æ³• 1: torch.matmul()
result1 = torch.matmul(A, B)

# æ–¹æ³• 2: @ è¿ç®—ç¬¦ (æ¨è)
result2 = A @ B

# æ–¹æ³• 3: torch.mm() (ä»…2DçŸ©é˜µ)
result3 = torch.mm(A, B)

# æ–¹æ³• 4: .matmul() æ–¹æ³•
result4 = A.matmul(B)

# æ‰€æœ‰ç»“æœç›¸åŒ
assert torch.all(result1 == result2)
assert torch.all(result1 == result3)
assert torch.all(result1 == result4)
```

**æ¨èä½¿ç”¨ `@` è¿ç®—ç¬¦,æœ€ç®€æ´!**

### 7.5 è½¬ç½®è§£å†³å½¢çŠ¶ä¸åŒ¹é…

```python
tensor_A = torch.tensor([[1, 2],
                         [3, 4],
                         [5, 6]])  # å½¢çŠ¶: (3, 2)

tensor_B = torch.tensor([[7, 10],
                         [8, 11],
                         [9, 12]])  # å½¢çŠ¶: (3, 2)

# ç›´æ¥ç›¸ä¹˜ä¼šæŠ¥é”™
# result = tensor_A @ tensor_B  # RuntimeError!
# å› ä¸º (3, 2) @ (3, 2) å†…éƒ¨ç»´åº¦ä¸åŒ¹é…

# è§£å†³æ–¹æ¡ˆ: è½¬ç½®ç¬¬äºŒä¸ªå¼ é‡
print(tensor_B.T)  # å½¢çŠ¶: (2, 3)
# tensor([[ 7,  8,  9],
#         [10, 11, 12]])

# ç°åœ¨å¯ä»¥ç›¸ä¹˜
result = tensor_A @ tensor_B.T  # (3, 2) @ (2, 3) = (3, 3)
print(result.shape)  # torch.Size([3, 3])
print(result)
# tensor([[ 27,  30,  33],
#         [ 61,  68,  75],
#         [ 95, 106, 117]])
```

**è½¬ç½®æ–¹æ³•:**

```python
# æ–¹æ³• 1: .T å±æ€§ (æ¨è,æœ€ç®€æ´)
transpose1 = tensor_A.T

# æ–¹æ³• 2: torch.transpose(input, dim0, dim1)
transpose2 = torch.transpose(tensor_A, 0, 1)

# æ–¹æ³• 3: .transpose(dim0, dim1) æ–¹æ³•
transpose3 = tensor_A.transpose(0, 1)

# æ–¹æ³• 4: .permute() - æ›´çµæ´»
transpose4 = tensor_A.permute(1, 0)

# éªŒè¯
assert torch.all(transpose1 == transpose2)
assert torch.all(transpose1 == transpose3)
assert torch.all(transpose1 == transpose4)
```

![çŸ©é˜µä¹˜æ³•å¯è§†åŒ–æ¼”ç¤º](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)

### 7.6 æ‰¹é‡çŸ©é˜µä¹˜æ³•

```python
# æ‰¹é‡çŸ©é˜µä¹˜æ³•
batch_A = torch.rand(32, 3, 2)  # 32ä¸ª (3x2) çŸ©é˜µ
batch_B = torch.rand(32, 2, 4)  # 32ä¸ª (2x4) çŸ©é˜µ

# torch.matmul è‡ªåŠ¨å¤„ç†æ‰¹é‡
batch_C = torch.matmul(batch_A, batch_B)
print(batch_C.shape)  # torch.Size([32, 3, 4])

# ç­‰ä»·äºæ‰‹åŠ¨å¾ªç¯ (ä½†æ…¢å¾—å¤š)
batch_C_manual = []
for i in range(32):
    C_i = batch_A[i] @ batch_B[i]
    batch_C_manual.append(C_i)
batch_C_manual = torch.stack(batch_C_manual)

# éªŒè¯
assert torch.allclose(batch_C, batch_C_manual)
```

### 7.7 ç¥ç»ç½‘ç»œä¸­çš„çº¿æ€§å±‚

```python
# torch.nn.Linear å®ç°: y = xÂ·A^T + b

import torch.nn as nn

# åˆ›å»ºçº¿æ€§å±‚
linear = nn.Linear(in_features=2, out_features=6)

# æŸ¥çœ‹æƒé‡
print(f"æƒé‡å½¢çŠ¶: {linear.weight.shape}")  # torch.Size([6, 2])
print(f"åç½®å½¢çŠ¶: {linear.bias.shape}")  # torch.Size([6])

# è¾“å…¥
x = torch.tensor([[1., 2.]])  # (1, 2)

# å‰å‘ä¼ æ’­
output = linear(x)  # (1, 6)
print(output.shape)

# ç­‰ä»·çš„æ‰‹åŠ¨è®¡ç®—
manual_output = x @ linear.weight.T + linear.bias
print(manual_output.shape)  # torch.Size([1, 6])

# éªŒè¯
assert torch.allclose(output, manual_output)
```

**å…¬å¼:**
```
y = x Â· W^T + b

å…¶ä¸­:
- x: è¾“å…¥ (batch_size, in_features)
- W: æƒé‡ (out_features, in_features)
- b: åç½® (out_features,)
- y: è¾“å‡º (batch_size, out_features)
```

### 7.8 çŸ©é˜µä¹˜æ³•æ€§èƒ½å¯¹æ¯”

```python
import time

# å‡†å¤‡æ•°æ®
size = 1000
A = torch.rand(size, size)
B = torch.rand(size, size)

# CPU çŸ©é˜µä¹˜æ³•
start = time.time()
C_cpu = A @ B
cpu_time = time.time() - start

# GPU çŸ©é˜µä¹˜æ³• (å¦‚æœå¯ç”¨)
if torch.cuda.is_available():
    A_gpu = A.cuda()
    B_gpu = B.cuda()

    # é¢„çƒ­
    _ = A_gpu @ B_gpu
    torch.cuda.synchronize()

    # è®¡æ—¶
    start = time.time()
    C_gpu = A_gpu @ B_gpu
    torch.cuda.synchronize()
    gpu_time = time.time() - start

    print(f"CPU æ—¶é—´: {cpu_time:.4f}ç§’")
    print(f"GPU æ—¶é—´: {gpu_time:.4f}ç§’")
    print(f"åŠ é€Ÿæ¯”: {cpu_time/gpu_time:.2f}x")
else:
    print(f"CPU æ—¶é—´: {cpu_time:.4f}ç§’")
    print("GPU ä¸å¯ç”¨")
```

---

ç”±äºå†…å®¹éå¸¸å¤š,è¿™åªæ˜¯ç¬¬ä¸€éƒ¨åˆ†ã€‚æ–‡æ¡£å°†ç»§ç»­åŒ…æ‹¬:

## å³å°†å®Œæˆçš„ç« èŠ‚:
- 8. å¼ é‡èšåˆæ“ä½œ
- 9. å¼ é‡é‡å¡‘ä¸å˜æ¢
- 10. ç´¢å¼•æ“ä½œ
- 11. å¹¿æ’­æœºåˆ¶è¯¦è§£ â­ (æ–°å¢)
- 12. è‡ªåŠ¨å¾®åˆ† Autograd â­ (æ–°å¢)
- 13-20. å…¶ä»–ç« èŠ‚...

ç”±äºç¯‡å¹…é™åˆ¶,æˆ‘ç°åœ¨å…ˆä¿å­˜è¿™éƒ¨åˆ†,ç„¶åç»§ç»­åˆ›å»ºå®Œæ•´æ–‡æ¡£ã€‚

---

**æ–‡æ¡£æŒç»­åˆ›å»ºä¸­...**

æ­¤æ–‡æ¡£æ˜¯å¢å¼ºç‰ˆçš„ç¬¬ä¸€éƒ¨åˆ†,åŒ…å«äº†:
- âœ… æ›´è¯¦ç»†çš„æ¦‚å¿µè§£é‡Š
- âœ… æ›´å¤šä»£ç ç¤ºä¾‹
- âœ… å¯è§†åŒ–å›¾è¡¨å¼•ç”¨
- âœ… æ€§èƒ½å¯¹æ¯”
- âœ… æœ€ä½³å®è·µå»ºè®®

åç»­éƒ¨åˆ†å°†åŒ…å«å¹¿æ’­ã€Autogradã€GPUä¼˜åŒ–ç­‰é«˜çº§ä¸»é¢˜!
