#!/usr/bin/env python3
"""
æ¼”ç¤ºçˆ¬å–å•ä¸ªé¡µé¢å¹¶ç”ŸæˆMarkdown

ä½¿ç”¨æ–¹æ³•:
    python scripts/demo_crawl_single.py
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from crawlers import DocsCrawler


def demo_crawl():
    """æ¼”ç¤ºçˆ¬å–å•ä¸ªæ–‡æ¡£é¡µé¢"""
    print("=" * 70)
    print("æ¼”ç¤ºçˆ¬å–é­”æ­ç¤¾åŒºé¡µé¢å¹¶ç”ŸæˆMarkdown")
    print("=" * 70)

    # åˆ›å»ºçˆ¬è™«
    crawler = DocsCrawler(output_dir="data/demo_crawl", rate_limit=2.0)
    crawler.max_depth = 0  # åªçˆ¬å–ä¸€ä¸ªé¡µé¢

    print("\næ­£åœ¨çˆ¬å–é­”æ­ç¤¾åŒºé¦–é¡µ...")
    print("URL: https://www.modelscope.cn/docs/overview")

    try:
        # çˆ¬å–é¡µé¢
        documents = crawler.crawl()

        print("\n" + "=" * 70)
        print("âœ… çˆ¬å–å®Œæˆ!")
        print("=" * 70)

        if documents:
            print(f"\nğŸ“Š çˆ¬å–äº† {len(documents)} ä¸ªæ–‡æ¡£")

            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
            print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")

            # JSONæ–‡ä»¶
            json_files = list(Path("data/demo_crawl").glob("*.json"))
            if json_files:
                print(f"\nJSONæ ¼å¼ ({len(json_files)} ä¸ªæ–‡ä»¶):")
                for f in json_files:
                    if f.name != "checkpoint.json":
                        size = f.stat().st_size
                        print(f"   âœ“ {f.name} ({size} å­—èŠ‚)")

            # Markdownæ–‡ä»¶
            md_dir = Path("data/demo_crawl/markdown")
            if md_dir.exists():
                md_files = list(md_dir.glob("*.md"))
                if md_files:
                    print(f"\nMarkdownæ ¼å¼ ({len(md_files)} ä¸ªæ–‡ä»¶):")
                    for f in md_files:
                        size = f.stat().st_size
                        print(f"   âœ“ {f.name} ({size} å­—èŠ‚)")

                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªMarkdownæ–‡ä»¶çš„å†…å®¹
                    if md_files:
                        print(f"\nğŸ“„ {md_files[0].name} å†…å®¹é¢„è§ˆ:")
                        print("-" * 70)
                        with open(md_files[0], 'r', encoding='utf-8') as f:
                            content = f.read()
                            lines = content.split('\n')[:30]
                            print('\n'.join(lines))
                            if len(content.split('\n')) > 30:
                                print("\n... (å†…å®¹è¾ƒé•¿ï¼Œä»…æ˜¾ç¤ºå‰30è¡Œ)")
                        print("-" * 70)

                        print(f"\nğŸ’¡ å®Œæ•´æ–‡ä»¶è·¯å¾„:")
                        print(f"   JSON: {Path('data/demo_crawl').absolute()}")
                        print(f"   Markdown: {md_dir.absolute()}")
        else:
            print("\nâš ï¸  æœªçˆ¬å–åˆ°æ–‡æ¡£")

    except Exception as e:
        print(f"\nâŒ çˆ¬å–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    demo_crawl()
