#!/usr/bin/env python3
"""
çˆ¬å–å¹¶å¤„ç†é­”æ­ç¤¾åŒºæ•°æ®

ä½¿ç”¨æ–¹æ³•:
    python scripts/crawl_and_process.py --all
    python scripts/crawl_and_process.py --docs --learn
    python scripts/crawl_and_process.py --process-only
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from crawlers import DocsCrawler, LearnCrawler, GitHubCrawler, CatalogCrawler
from crawlers.data_processor import DataProcessor


def crawl_docs(output_dir: str = "data/crawled"):
    """çˆ¬å–å®˜æ–¹æ–‡æ¡£"""
    print("\n" + "ğŸŒ" * 35)
    crawler = DocsCrawler(output_dir=f"{output_dir}/docs")
    crawler.crawl()


def crawl_learn(output_dir: str = "data/crawled"):
    """çˆ¬å–ç ”ä¹ ç¤¾"""
    print("\n" + "ğŸŒ" * 35)
    crawler = LearnCrawler(output_dir=f"{output_dir}/learn")
    crawler.crawl()


def crawl_github(output_dir: str = "data/crawled"):
    """çˆ¬å–GitHubä»“åº“"""
    print("\n" + "ğŸŒ" * 35)
    crawler = GitHubCrawler(output_dir=f"{output_dir}/github")
    crawler.crawl()


def crawl_catalog(output_dir: str = "data/crawled"):
    """çˆ¬å–èµ„æºç›®å½•"""
    print("\n" + "ğŸŒ" * 35)
    crawler = CatalogCrawler(output_dir=f"{output_dir}/catalog")
    crawler.crawl()


def process_data(crawled_dir: str = "data/crawled", processed_dir: str = "data/processed"):
    """å¤„ç†æ•°æ®"""
    print("\n" + "âš™ï¸" * 35)
    processor = DataProcessor(crawled_data_dir=crawled_dir, processed_data_dir=processed_dir)
    processor.process_all()
    processor.export_for_ingestion()


def main():
    parser = argparse.ArgumentParser(description="çˆ¬å–å¹¶å¤„ç†é­”æ­ç¤¾åŒºæ•°æ®")

    # çˆ¬å–é€‰é¡¹
    parser.add_argument("--all", action="store_true", help="çˆ¬å–æ‰€æœ‰æ•°æ®æº")
    parser.add_argument("--docs", action="store_true", help="çˆ¬å–å®˜æ–¹æ–‡æ¡£")
    parser.add_argument("--learn", action="store_true", help="çˆ¬å–ç ”ä¹ ç¤¾")
    parser.add_argument("--github", action="store_true", help="çˆ¬å–GitHubä»“åº“")
    parser.add_argument("--catalog", action="store_true", help="çˆ¬å–èµ„æºç›®å½•")

    # å¤„ç†é€‰é¡¹
    parser.add_argument("--process", action="store_true", help="å¤„ç†çˆ¬å–çš„æ•°æ®")
    parser.add_argument("--process-only", action="store_true", help="åªå¤„ç†æ•°æ®(ä¸çˆ¬å–)")

    # ç›®å½•é€‰é¡¹
    parser.add_argument("--output-dir", default="data/crawled", help="çˆ¬å–æ•°æ®è¾“å‡ºç›®å½•")
    parser.add_argument("--processed-dir", default="data/processed", help="å¤„ç†åæ•°æ®è¾“å‡ºç›®å½•")

    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•é€‰é¡¹ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not any([args.all, args.docs, args.learn, args.github, args.catalog, args.process_only]):
        parser.print_help()
        return

    print("=" * 70)
    print("é­”æ­ç¤¾åŒºæ•°æ®çˆ¬å–ä¸å¤„ç†")
    print("=" * 70)

    # çˆ¬å–é˜¶æ®µ
    if not args.process_only:
        if args.all or args.docs:
            try:
                crawl_docs(args.output_dir)
            except KeyboardInterrupt:
                print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ docs çˆ¬å–")
            except Exception as e:
                print(f"\nâŒ docs çˆ¬å–å¤±è´¥: {e}")

        if args.all or args.learn:
            try:
                crawl_learn(args.output_dir)
            except KeyboardInterrupt:
                print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ learn çˆ¬å–")
            except Exception as e:
                print(f"\nâŒ learn çˆ¬å–å¤±è´¥: {e}")

        if args.all or args.github:
            try:
                crawl_github(args.output_dir)
            except KeyboardInterrupt:
                print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ github çˆ¬å–")
            except Exception as e:
                print(f"\nâŒ github çˆ¬å–å¤±è´¥: {e}")

        if args.all or args.catalog:
            try:
                crawl_catalog(args.output_dir)
            except KeyboardInterrupt:
                print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ catalog çˆ¬å–")
            except Exception as e:
                print(f"\nâŒ catalog çˆ¬å–å¤±è´¥: {e}")

    # å¤„ç†é˜¶æ®µ
    if args.process or args.process_only or args.all:
        try:
            process_data(args.output_dir, args.processed_dir)
        except Exception as e:
            print(f"\nâŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 70)
    print("âœ… å®Œæˆ!")
    print("=" * 70)


if __name__ == "__main__":
    main()
