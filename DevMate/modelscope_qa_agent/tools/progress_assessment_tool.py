"""å¯¹è¯è¿›åº¦è¯„ä¼°å·¥å…·

å®ç° Phase 4.4 å¯¹è¯è¿›åº¦è¯„ä¼°åŠŸèƒ½:
- è¯„ä¼°é—®é¢˜è§£å†³è¿›åº¦
- æ€»ç»“å·²å°è¯•çš„æ–¹æ³•
- è¯†åˆ«å·²æ’é™¤çš„å¯èƒ½æ€§
- å»ºè®®åç»­è¡ŒåŠ¨ï¼ˆç»§ç»­æ’æŸ¥ã€è½¬å‘å…¶ä»–è·¯å¾„ã€å¯»æ±‚äººå·¥æ”¯æŒï¼‰

Author: Claude Code
Created: 2025-12-01
"""

from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_community.chat_models import ChatTongyi


class ProgressAssessment(BaseModel):
    """è¿›åº¦è¯„ä¼°ç»“æœæ¨¡å‹

    ç”¨äºè®°å½•å¯¹è¯è¿›åº¦è¯„ä¼°çš„ç»“æœï¼ŒåŒ…æ‹¬å°è¯•çš„æ–¹æ³•ã€æ’é™¤çš„å¯èƒ½æ€§å’Œå»ºè®®ã€‚
    """

    # è¯„ä¼°æŒ‡æ ‡
    turn_count: int = Field(description="å¯¹è¯è½®æ¬¡")
    problem_resolved: bool = Field(description="é—®é¢˜æ˜¯å¦å·²è§£å†³")
    confidence_score: float = Field(ge=0, le=1, description="è§£å†³ç½®ä¿¡åº¦ (0-1)")

    # è¿›åº¦æ€»ç»“
    attempted_solutions: List[str] = Field(
        default_factory=list,
        description="å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆåˆ—è¡¨"
    )
    excluded_causes: List[str] = Field(
        default_factory=list,
        description="å·²æ’é™¤çš„å¯èƒ½åŸå› åˆ—è¡¨"
    )
    remaining_options: List[str] = Field(
        default_factory=list,
        description="å‰©ä½™å¯å°è¯•çš„é€‰é¡¹"
    )

    # å»ºè®®
    recommendation: str = Field(description="åç»­å»ºè®® (continue/pivot/escalate)")
    recommendation_reason: str = Field(description="å»ºè®®ç†ç”±")
    next_steps: List[str] = Field(
        default_factory=list,
        description="å»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨"
    )

    # æ˜¯å¦éœ€è¦äººå·¥æ”¯æŒ
    needs_human_support: bool = Field(
        default=False,
        description="æ˜¯å¦å»ºè®®è½¬å‘äººå·¥æ”¯æŒ"
    )

    model_config = {
        "json_schema_extra": {
            "example": {
                "turn_count": 6,
                "problem_resolved": False,
                "confidence_score": 0.3,
                "attempted_solutions": [
                    "é™ä½å­¦ä¹ ç‡åˆ° 0.0001",
                    "è°ƒæ•´ batch_size åˆ° 16",
                    "å¯ç”¨æ¢¯åº¦è£å‰ª"
                ],
                "excluded_causes": [
                    "å­¦ä¹ ç‡è¿‡é«˜ï¼ˆå·²è°ƒæ•´ï¼‰",
                    "æ˜¾å­˜ä¸è¶³ï¼ˆå·²ä¼˜åŒ–ï¼‰"
                ],
                "remaining_options": [
                    "æ£€æŸ¥æ•°æ®è´¨é‡",
                    "æ›´æ¢ä¼˜åŒ–å™¨",
                    "è°ƒæ•´æ¨¡å‹æ¶æ„"
                ],
                "recommendation": "pivot",
                "recommendation_reason": "å·²å°è¯•å¸¸è§„è¶…å‚æ•°è°ƒæ•´ï¼Œå»ºè®®ä»æ•°æ®è´¨é‡è§’åº¦æ’æŸ¥",
                "next_steps": [
                    "æ£€æŸ¥è®­ç»ƒæ•°æ®æ ‡æ³¨å‡†ç¡®æ€§",
                    "éªŒè¯æ•°æ®é¢„å¤„ç†æµç¨‹",
                    "å°è¯•ä½¿ç”¨ä¸åŒçš„æ•°æ®é›†å­é›†"
                ],
                "needs_human_support": False
            }
        }
    }


class ProgressAssessmentTool:
    """å¯¹è¯è¿›åº¦è¯„ä¼°å·¥å…·

    åŸºäºå¯¹è¯å†å²è¯„ä¼°é—®é¢˜è§£å†³è¿›åº¦ï¼Œæä¾›åç»­è¡ŒåŠ¨å»ºè®®ã€‚

    Attributes:
        llm: ChatTongyi LLM å®¢æˆ·ç«¯
        turn_threshold: è§¦å‘ä¸»åŠ¨æ€»ç»“çš„è½®æ¬¡é˜ˆå€¼ï¼ˆé»˜è®¤ 5ï¼‰

    Example:
        >>> tool = ProgressAssessmentTool(llm_api_key="sk-xxx")
        >>> assessment = tool.assess_progress(messages, turn_count=6)
        >>> if assessment.needs_human_support:
        ...     print("å»ºè®®å¯»æ±‚äººå·¥æ”¯æŒ")
    """

    def __init__(
        self,
        llm_api_key: str,
        model: str = "qwen-plus",
        temperature: float = 0.3,
        turn_threshold: int = 5
    ):
        """åˆå§‹åŒ–è¿›åº¦è¯„ä¼°å·¥å…·

        Args:
            llm_api_key: é€šä¹‰åƒé—® API å¯†é’¥
            model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ qwen-plusï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆé»˜è®¤ 0.3ï¼‰
            turn_threshold: è§¦å‘ä¸»åŠ¨æ€»ç»“çš„è½®æ¬¡é˜ˆå€¼ï¼ˆé»˜è®¤ 5ï¼‰

        Raises:
            ValueError: å¦‚æœ API å¯†é’¥ä¸ºç©º
        """
        if not llm_api_key or not llm_api_key.strip():
            raise ValueError("llm_api_key ä¸èƒ½ä¸ºç©º")

        self.llm = ChatTongyi(
            model=model,
            temperature=temperature,
            dashscope_api_key=llm_api_key
        )

        self.turn_threshold = turn_threshold

        print(f"âœ… ProgressAssessmentTool åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - è½®æ¬¡é˜ˆå€¼: {turn_threshold}")

    def should_assess(self, turn_count: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›è¡Œè¿›åº¦è¯„ä¼°

        Args:
            turn_count: å½“å‰å¯¹è¯è½®æ¬¡

        Returns:
            bool: å¦‚æœè½®æ¬¡ >= é˜ˆå€¼ï¼Œè¿”å› True

        Example:
            >>> tool.should_assess(6)  # True
            >>> tool.should_assess(3)  # False
        """
        return turn_count >= self.turn_threshold

    def assess_progress(
        self,
        messages: List[BaseMessage],
        turn_count: int,
        current_question: str = ""
    ) -> ProgressAssessment:
        """è¯„ä¼°å¯¹è¯è¿›åº¦

        åŸºäºå¯¹è¯å†å²åˆ†æé—®é¢˜è§£å†³è¿›åº¦ï¼Œç”Ÿæˆè¯„ä¼°æŠ¥å‘Šã€‚

        Args:
            messages: å¯¹è¯æ¶ˆæ¯å†å²
            turn_count: å½“å‰å¯¹è¯è½®æ¬¡
            current_question: å½“å‰é—®é¢˜ï¼ˆå¯é€‰ï¼‰

        Returns:
            ProgressAssessment: è¿›åº¦è¯„ä¼°ç»“æœ

        Example:
            >>> messages = [
            ...     HumanMessage(content="æ¨¡å‹è®­ç»ƒ loss ä¸ä¸‹é™"),
            ...     AIMessage(content="å»ºè®®é™ä½å­¦ä¹ ç‡"),
            ...     HumanMessage(content="é™ä½äº†è¿˜æ˜¯ä¸è¡Œ")
            ... ]
            >>> assessment = tool.assess_progress(messages, turn_count=6)
            >>> print(assessment.recommendation)  # "pivot"
        """
        print(f"\nğŸ“Š å¼€å§‹è¯„ä¼°å¯¹è¯è¿›åº¦ (è½®æ¬¡: {turn_count})")

        # æ„å»ºå¯¹è¯å†å²æ‘˜è¦
        conversation_summary = self._build_conversation_summary(messages)

        # ä½¿ç”¨ LLM åˆ†æè¿›åº¦
        try:
            assessment_result = self._generate_assessment(
                conversation_summary,
                turn_count,
                current_question
            )

            print(f"âœ… è¿›åº¦è¯„ä¼°å®Œæˆ")
            print(f"   - é—®é¢˜è§£å†³: {assessment_result.problem_resolved}")
            print(f"   - ç½®ä¿¡åº¦: {assessment_result.confidence_score:.2f}")
            print(f"   - å»ºè®®: {assessment_result.recommendation}")

            return assessment_result

        except Exception as e:
            print(f"âš ï¸  è¿›åº¦è¯„ä¼°å¤±è´¥: {e}")
            # è¿”å›é™çº§è¯„ä¼°
            return self._create_fallback_assessment(turn_count)

    def _build_conversation_summary(self, messages: List[BaseMessage]) -> str:
        """æ„å»ºå¯¹è¯å†å²æ‘˜è¦

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨

        Returns:
            str: æ ¼å¼åŒ–çš„å¯¹è¯æ‘˜è¦
        """
        summary_lines = []

        for i, msg in enumerate(messages, 1):
            if isinstance(msg, HumanMessage):
                summary_lines.append(f"[ç¬¬{i}è½®] ç”¨æˆ·: {msg.content[:200]}")
            elif isinstance(msg, AIMessage):
                # æå–ä¸»è¦å†…å®¹ï¼ˆé¿å…è¿‡é•¿ï¼‰
                content = msg.content[:300]
                summary_lines.append(f"[ç¬¬{i}è½®] Agent: {content}...")

        return "\n".join(summary_lines)

    def _generate_assessment(
        self,
        conversation_summary: str,
        turn_count: int,
        current_question: str
    ) -> ProgressAssessment:
        """ä½¿ç”¨ LLM ç”Ÿæˆè¿›åº¦è¯„ä¼°

        Args:
            conversation_summary: å¯¹è¯å†å²æ‘˜è¦
            turn_count: å¯¹è¯è½®æ¬¡
            current_question: å½“å‰é—®é¢˜

        Returns:
            ProgressAssessment: è¯„ä¼°ç»“æœ
        """
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå¯¹è¯è¿›åº¦è¯„ä¼°ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹å¯¹è¯å†å²ï¼Œè¯„ä¼°é—®é¢˜è§£å†³çš„è¿›åº¦ã€‚

**å¯¹è¯è½®æ¬¡**: {turn_count}

**å¯¹è¯å†å²**:
{conversation_summary}

**å½“å‰é—®é¢˜**: {current_question if current_question else "æ— "}

**è¯„ä¼°ä»»åŠ¡**:
1. åˆ¤æ–­é—®é¢˜æ˜¯å¦å·²è§£å†³ï¼ˆtrue/falseï¼‰
2. è¯„ä¼°è§£å†³ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
3. æ€»ç»“å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
4. åˆ—å‡ºå·²æ’é™¤çš„å¯èƒ½åŸå› 
5. åˆ—å‡ºå‰©ä½™å¯å°è¯•çš„é€‰é¡¹
6. æä¾›åç»­å»ºè®®:
   - "continue": ç»§ç»­å½“å‰æ’æŸ¥è·¯å¾„
   - "pivot": è½¬å‘å…¶ä»–æ’æŸ¥è§’åº¦
   - "escalate": å»ºè®®äººå·¥æ”¯æŒ
7. è¯´æ˜å»ºè®®ç†ç”±
8. åˆ—å‡ºå»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨

**è¾“å‡ºæ ¼å¼**: è¯·ä»¥è‡ªç„¶è¯­è¨€æè¿°ä½ çš„è¯„ä¼°ï¼ŒåŒ…å«ä»¥ä¸Šæ‰€æœ‰è¦ç‚¹ã€‚
"""

        # è°ƒç”¨ LLM
        response = self.llm.invoke(prompt)
        assessment_text = response.content

        # è§£æ LLM å“åº”ï¼ˆç®€åŒ–ç‰ˆæœ¬ - æå–å…³é”®ä¿¡æ¯ï¼‰
        return self._parse_assessment_response(assessment_text, turn_count)

    def _parse_assessment_response(
        self,
        assessment_text: str,
        turn_count: int
    ) -> ProgressAssessment:
        """è§£æ LLM çš„è¯„ä¼°å“åº”

        Args:
            assessment_text: LLM ç”Ÿæˆçš„è¯„ä¼°æ–‡æœ¬
            turn_count: å¯¹è¯è½®æ¬¡

        Returns:
            ProgressAssessment: ç»“æ„åŒ–çš„è¯„ä¼°ç»“æœ
        """
        # ç®€åŒ–å®ç°ï¼šåŸºäºå…³é”®è¯å’Œå¯å‘å¼è§„åˆ™è§£æ

        # åˆ¤æ–­é—®é¢˜æ˜¯å¦è§£å†³
        problem_resolved = any(keyword in assessment_text for keyword in [
            "é—®é¢˜å·²è§£å†³", "æˆåŠŸè§£å†³", "å·²ç»è§£å†³", "è§£å†³äº†"
        ])

        # è¯„ä¼°ç½®ä¿¡åº¦ï¼ˆåŸºäºè½®æ¬¡å’Œè§£å†³çŠ¶æ€ï¼‰
        if problem_resolved:
            confidence_score = 0.9
        elif turn_count >= 8:
            confidence_score = 0.2  # å¤šè½®æœªè§£å†³ï¼Œç½®ä¿¡åº¦ä½
        elif turn_count >= 6:
            confidence_score = 0.4
        else:
            confidence_score = 0.6

        # æå–å°è¯•çš„æ–¹æ¡ˆï¼ˆç®€åŒ–ï¼‰
        attempted_solutions = []
        if "é™ä½å­¦ä¹ ç‡" in assessment_text or "è°ƒæ•´å­¦ä¹ ç‡" in assessment_text:
            attempted_solutions.append("è°ƒæ•´å­¦ä¹ ç‡")
        if "batch_size" in assessment_text or "æ‰¹æ¬¡å¤§å°" in assessment_text:
            attempted_solutions.append("è°ƒæ•´æ‰¹æ¬¡å¤§å°")
        if "ä¼˜åŒ–å™¨" in assessment_text:
            attempted_solutions.append("å°è¯•ä¸åŒä¼˜åŒ–å™¨")

        # æå–æ’é™¤çš„åŸå› 
        excluded_causes = []
        if "ä¸æ˜¯å­¦ä¹ ç‡" in assessment_text or "å­¦ä¹ ç‡å·²è°ƒæ•´" in assessment_text:
            excluded_causes.append("å­¦ä¹ ç‡é—®é¢˜å·²æ’é™¤")
        if "ä¸æ˜¯æ˜¾å­˜" in assessment_text or "æ˜¾å­˜è¶³å¤Ÿ" in assessment_text:
            excluded_causes.append("æ˜¾å­˜é—®é¢˜å·²æ’é™¤")

        # å‰©ä½™é€‰é¡¹
        remaining_options = []
        if "æ•°æ®" in assessment_text and "æ•°æ®" not in "".join(attempted_solutions):
            remaining_options.append("æ£€æŸ¥æ•°æ®è´¨é‡")
        if "æ¨¡å‹" in assessment_text and "æ¨¡å‹" not in "".join(attempted_solutions):
            remaining_options.append("è°ƒæ•´æ¨¡å‹æ¶æ„")
        if not remaining_options:
            remaining_options = ["å°è¯•å…¶ä»–è¶…å‚æ•°ç»„åˆ", "æ£€æŸ¥ä»£ç å®ç°", "å’¨è¯¢ä¸“å®¶"]

        # ç¡®å®šå»ºè®®
        if problem_resolved:
            recommendation = "continue"
            recommendation_reason = "é—®é¢˜å·²è§£å†³ï¼Œå¯ç»§ç»­ä½¿ç”¨è¯¥æ–¹æ¡ˆ"
            needs_human_support = False
        elif turn_count >= 8:
            recommendation = "escalate"
            recommendation_reason = f"å·²å°è¯• {turn_count} è½®å¯¹è¯ä»æœªè§£å†³ï¼Œå»ºè®®äººå·¥æ”¯æŒ"
            needs_human_support = True
        elif turn_count >= 6:
            recommendation = "pivot"
            recommendation_reason = "å¸¸è§„æ–¹æ³•æ•ˆæœä¸ä½³ï¼Œå»ºè®®å°è¯•å…¶ä»–æ’æŸ¥è§’åº¦"
            needs_human_support = False
        else:
            recommendation = "continue"
            recommendation_reason = "ç»§ç»­å½“å‰æ’æŸ¥è·¯å¾„"
            needs_human_support = False

        # ä¸‹ä¸€æ­¥å»ºè®®
        if recommendation == "escalate":
            next_steps = [
                "æ•´ç†å·²å°è¯•çš„æ‰€æœ‰æ–¹æ³•",
                "å‡†å¤‡å®Œæ•´çš„é—®é¢˜æè¿°å’Œæ—¥å¿—",
                "è”ç³»æŠ€æœ¯æ”¯æŒå›¢é˜Ÿ"
            ]
        elif recommendation == "pivot":
            next_steps = remaining_options[:3]
        else:
            next_steps = ["ç»§ç»­æŒ‰ç…§å½“å‰æ–¹æ¡ˆæ’æŸ¥", "æ”¶é›†æ›´å¤šä¿¡æ¯", "éªŒè¯è§£å†³æ•ˆæœ"]

        return ProgressAssessment(
            turn_count=turn_count,
            problem_resolved=problem_resolved,
            confidence_score=confidence_score,
            attempted_solutions=attempted_solutions if attempted_solutions else ["å¤šç§æ–¹æ¡ˆ"],
            excluded_causes=excluded_causes if excluded_causes else ["éƒ¨åˆ†åŸå› å·²æ’é™¤"],
            remaining_options=remaining_options,
            recommendation=recommendation,
            recommendation_reason=recommendation_reason,
            next_steps=next_steps,
            needs_human_support=needs_human_support
        )

    def _create_fallback_assessment(self, turn_count: int) -> ProgressAssessment:
        """åˆ›å»ºé™çº§è¯„ä¼°ç»“æœï¼ˆå½“ LLM è°ƒç”¨å¤±è´¥æ—¶ï¼‰

        Args:
            turn_count: å¯¹è¯è½®æ¬¡

        Returns:
            ProgressAssessment: åŸºäºè½®æ¬¡çš„ç®€å•è¯„ä¼°
        """
        if turn_count >= 8:
            return ProgressAssessment(
                turn_count=turn_count,
                problem_resolved=False,
                confidence_score=0.2,
                attempted_solutions=["å¤šç§å°è¯•"],
                excluded_causes=["éƒ¨åˆ†åŸå› å·²æ’é™¤"],
                remaining_options=["å…¶ä»–æ’æŸ¥è·¯å¾„"],
                recommendation="escalate",
                recommendation_reason="å¯¹è¯è½®æ¬¡è¿‡å¤šï¼Œå»ºè®®äººå·¥æ”¯æŒ",
                next_steps=["è”ç³»æŠ€æœ¯æ”¯æŒ"],
                needs_human_support=True
            )
        elif turn_count >= 5:
            return ProgressAssessment(
                turn_count=turn_count,
                problem_resolved=False,
                confidence_score=0.4,
                attempted_solutions=["å¸¸è§„æ–¹æ¡ˆ"],
                excluded_causes=["åŸºæœ¬åŸå› å·²æ’æŸ¥"],
                remaining_options=["æ·±å…¥æ’æŸ¥", "å°è¯•å…¶ä»–è§’åº¦"],
                recommendation="pivot",
                recommendation_reason="å»ºè®®è½¬å‘å…¶ä»–æ’æŸ¥è§’åº¦",
                next_steps=["æ£€æŸ¥æ•°æ®è´¨é‡", "éªŒè¯ä»£ç é€»è¾‘"],
                needs_human_support=False
            )
        else:
            return ProgressAssessment(
                turn_count=turn_count,
                problem_resolved=False,
                confidence_score=0.6,
                attempted_solutions=["åˆæ­¥å°è¯•"],
                excluded_causes=[],
                remaining_options=["ç»§ç»­æ’æŸ¥"],
                recommendation="continue",
                recommendation_reason="ç»§ç»­å½“å‰æ’æŸ¥è·¯å¾„",
                next_steps=["æŒ‰ç…§å»ºè®®ç»§ç»­å°è¯•"],
                needs_human_support=False
            )

    def format_assessment_summary(self, assessment: ProgressAssessment) -> str:
        """æ ¼å¼åŒ–è¯„ä¼°æ‘˜è¦ä¸ºå¯è¯»æ–‡æœ¬

        Args:
            assessment: è¯„ä¼°ç»“æœ

        Returns:
            str: æ ¼å¼åŒ–çš„æ‘˜è¦æ–‡æœ¬

        Example:
            >>> summary = tool.format_assessment_summary(assessment)
            >>> print(summary)
        """
        lines = [
            f"\n{'='*70}",
            f"ğŸ“Š å¯¹è¯è¿›åº¦è¯„ä¼°æŠ¥å‘Šï¼ˆç¬¬ {assessment.turn_count} è½®ï¼‰",
            f"{'='*70}",
            "",
            f"**é—®é¢˜çŠ¶æ€**: {'âœ… å·²è§£å†³' if assessment.problem_resolved else 'â³ è¿›è¡Œä¸­'}",
            f"**è§£å†³ç½®ä¿¡åº¦**: {assessment.confidence_score:.0%}",
            "",
            "**å·²å°è¯•çš„æ–¹æ¡ˆ**:",
        ]

        for i, solution in enumerate(assessment.attempted_solutions, 1):
            lines.append(f"  {i}. {solution}")

        if assessment.excluded_causes:
            lines.append("")
            lines.append("**å·²æ’é™¤çš„å¯èƒ½æ€§**:")
            for i, cause in enumerate(assessment.excluded_causes, 1):
                lines.append(f"  {i}. {cause}")

        if assessment.remaining_options:
            lines.append("")
            lines.append("**å‰©ä½™å¯å°è¯•é€‰é¡¹**:")
            for i, option in enumerate(assessment.remaining_options, 1):
                lines.append(f"  {i}. {option}")

        lines.extend([
            "",
            f"**å»ºè®®è¡ŒåŠ¨**: {self._get_recommendation_label(assessment.recommendation)}",
            f"**ç†ç”±**: {assessment.recommendation_reason}",
            "",
            "**ä¸‹ä¸€æ­¥å»ºè®®**:"
        ])

        for i, step in enumerate(assessment.next_steps, 1):
            lines.append(f"  {i}. {step}")

        if assessment.needs_human_support:
            lines.extend([
                "",
                "âš ï¸  **å»ºè®®**: é—®é¢˜è¾ƒä¸ºå¤æ‚ï¼Œå»ºè®®å¯»æ±‚äººå·¥æŠ€æœ¯æ”¯æŒ"
            ])

        lines.append(f"{'='*70}\n")

        return "\n".join(lines)

    def _get_recommendation_label(self, recommendation: str) -> str:
        """è·å–å»ºè®®çš„ä¸­æ–‡æ ‡ç­¾

        Args:
            recommendation: å»ºè®®ç±»å‹

        Returns:
            str: ä¸­æ–‡æ ‡ç­¾
        """
        labels = {
            "continue": "ç»§ç»­å½“å‰è·¯å¾„",
            "pivot": "è½¬å‘å…¶ä»–è§’åº¦",
            "escalate": "å¯»æ±‚äººå·¥æ”¯æŒ"
        }
        return labels.get(recommendation, recommendation)
