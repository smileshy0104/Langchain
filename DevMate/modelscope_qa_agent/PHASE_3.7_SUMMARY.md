# Phase 3.7 å®Œæˆæ€»ç»“: è¯„ä¼°ä¸ä¼˜åŒ–

## æ¦‚è¿°

Phase 3.7 æˆåŠŸå®ç°äº†å®Œæ•´çš„ RAG ç³»ç»Ÿè¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬ RAGAs è¯„ä¼°è„šæœ¬ã€è¯„æµ‹æ•°æ®é›†ã€æ€§èƒ½åˆ†æå’Œä¼˜åŒ–æŒ‡å—ã€‚

**å®Œæˆæ—¥æœŸ**: 2025-12-01
**ä»»åŠ¡èŒƒå›´**: T096 - T101
**çŠ¶æ€**: âœ… å…¨éƒ¨å®Œæˆ
**ç¼–è¯‘çŠ¶æ€**: âœ… æ‰€æœ‰ä»£ç ç¼–è¯‘é€šè¿‡

---

## å®ç°çš„æ ¸å¿ƒåŠŸèƒ½

### 1. è¯„æµ‹æ•°æ®é›† (T096)

**æ–‡ä»¶**: `data/evaluation_dataset.json` (31ä¸ªé—®é¢˜)

#### æ•°æ®é›†ç‰¹ç‚¹

- **é—®é¢˜æ•°é‡**: 31ä¸ªçœŸå® ModelScope æŠ€æœ¯é—®é¢˜
- **è¦†ç›–ç±»åˆ«**: 10ä¸ªä¸»è¦ç±»åˆ«
- **æ•°æ®ç»“æ„**:
  ```json
  {
    "question": "ç”¨æˆ·é—®é¢˜",
    "ground_truth": "æ ‡å‡†ç­”æ¡ˆ",
    "contexts": ["ç›¸å…³æ–‡æ¡£ç‰‡æ®µ"],
    "category": "é—®é¢˜åˆ†ç±»"
  }
  ```

#### ç±»åˆ«åˆ†å¸ƒ

| ç±»åˆ« | æ•°é‡ | è¯´æ˜ |
|------|------|------|
| model_usage | 8 | æ¨¡å‹ä½¿ç”¨æ–¹æ³• |
| platform_usage | 5 | å¹³å°åŠŸèƒ½ä½¿ç”¨ |
| error_handling | 4 | é”™è¯¯å¤„ç†æ–¹æ¡ˆ |
| multimodal | 2 | å¤šæ¨¡æ€åœºæ™¯ |
| deployment | 2 | æ¨¡å‹éƒ¨ç½² |
| training | 1 | æ¨¡å‹è®­ç»ƒ |
| model_details | 3 | æ¨¡å‹ç»†èŠ‚ |
| platform_details | 3 | å¹³å°ç‰¹æ€§ |
| optimization | 2 | æ€§èƒ½ä¼˜åŒ– |
| monitoring | 1 | ç³»ç»Ÿç›‘æ§ |

#### ç¤ºä¾‹é—®é¢˜

```json
{
  "question": "å¦‚ä½•ä½¿ç”¨ transformers åº“åŠ è½½ Qwen-7B æ¨¡å‹ï¼Ÿ",
  "ground_truth": "ä½¿ç”¨ AutoModelForCausalLM.from_pretrained('Qwen/Qwen-7B') æ–¹æ³•åŠ è½½æ¨¡å‹...",
  "contexts": [
    "Qwen ç³»åˆ—æ¨¡å‹å¯ä»¥é€šè¿‡ Hugging Face transformers åº“åŠ è½½ã€‚",
    "ä½¿ç”¨ AutoModelForCausalLM ç±»æ¥åŠ è½½å› æœè¯­è¨€æ¨¡å‹ã€‚"
  ],
  "category": "model_usage"
}
```

### 2. RAGAs è¯„ä¼°è„šæœ¬ (T097)

**æ–‡ä»¶**: `scripts/evaluate_rag.py` (628è¡Œ)

#### æ ¸å¿ƒç»„ä»¶

**`RAGEvaluator` ç±»**:
```python
class RAGEvaluator:
    """RAG ç³»ç»Ÿè¯„ä¼°å™¨"""

    def __init__(self, agent, llm_api_key, embedding_api_key):
        """åˆå§‹åŒ–è¯„ä¼°å™¨"""

    def load_evaluation_dataset(self, dataset_path):
        """åŠ è½½è¯„æµ‹æ•°æ®é›†"""

    def run_inference(self, dataset, max_samples):
        """è¿è¡Œæ¨ç†è·å– Agent å“åº”"""

    def evaluate_with_ragas(self, results):
        """ä½¿ç”¨ RAGAs è¯„ä¼°ç»“æœ"""

    def evaluate_response_time(self, results, target_threshold):
        """è¯„ä¼°å“åº”é€Ÿåº¦"""

    def generate_report(self, ragas_results, response_stats, results, output_path):
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
```

#### RAGAs æŒ‡æ ‡

ä½¿ç”¨ RAGAs 0.3.9 æ¡†æ¶è¯„ä¼°å››ä¸ªæ ¸å¿ƒæŒ‡æ ‡:

1. **Context Recall (ä¸Šä¸‹æ–‡å¬å›ç‡)**
   - æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦åŒ…å«å›ç­”é—®é¢˜æ‰€éœ€çš„ä¿¡æ¯
   - ç›®æ ‡: â‰¥85%
   - å®ç°: `ContextRecall()` metric

2. **Faithfulness (ç­”æ¡ˆå¿ å®åº¦)**
   - ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯å¦å¿ å®äºæ£€ç´¢åˆ°çš„æ–‡æ¡£
   - ç›®æ ‡: â‰¥95%
   - å®ç°: `Faithfulness()` metric

3. **Answer Relevancy (ç­”æ¡ˆç›¸å…³æ€§)**
   - ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³
   - ç›®æ ‡: å°½å¯èƒ½é«˜
   - å®ç°: `AnswerRelevancy()` metric

4. **Answer Correctness (ç­”æ¡ˆæ­£ç¡®æ€§)**
   - ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„åŒ¹é…ç¨‹åº¦
   - ç›®æ ‡: å°½å¯èƒ½é«˜
   - å®ç°: `AnswerCorrectness()` metric

#### å“åº”æ—¶é—´è¯„ä¼°

ç»Ÿè®¡æŒ‡æ ‡:
- å¹³å‡å“åº”æ—¶é—´ (Mean)
- ä¸­ä½æ•° (P50)
- P95 ç™¾åˆ†ä½
- P99 ç™¾åˆ†ä½
- æœ€å°å€¼ / æœ€å¤§å€¼
- ç›®æ ‡è¾¾æ ‡ç‡

ç›®æ ‡: P50 < 30ç§’

#### æŠ¥å‘Šç”Ÿæˆ

ç”Ÿæˆä¸¤ç§æ ¼å¼çš„æŠ¥å‘Š:

**1. Markdown æŠ¥å‘Š** (`results/evaluation_report.md`):
- RAGAs è¯„ä¼°æŒ‡æ ‡è¡¨æ ¼
- å“åº”æ—¶é—´ç»Ÿè®¡è¡¨æ ¼
- ç›®æ ‡è¾¾æˆæƒ…å†µ
- æ€»ç»“å’Œå»ºè®®

**2. JSON è¯¦ç»†ç»“æœ** (`results/evaluation_report.json`):
- å®Œæ•´çš„è¯„ä¼°æ•°æ®
- æ¯ä¸ªé—®é¢˜çš„è¯¦ç»†ç»“æœ
- ä¾¿äºç¨‹åºåŒ–åˆ†æ

#### CLI æ¥å£

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/evaluate_rag.py

# å¿«é€Ÿæµ‹è¯• (5ä¸ªæ ·æœ¬)
python scripts/evaluate_rag.py --max-samples 5

# è‡ªå®šä¹‰æ•°æ®é›†å’Œè¾“å‡º
python scripts/evaluate_rag.py \
  --dataset my_dataset.json \
  --output my_report.md \
  --api-key sk-xxx
```

å‚æ•°è¯´æ˜:
- `--dataset`: è¯„æµ‹æ•°æ®é›†è·¯å¾„ (é»˜è®¤: data/evaluation_dataset.json)
- `--output`: æŠ¥å‘Šè¾“å‡ºè·¯å¾„ (é»˜è®¤: results/evaluation_report.md)
- `--max-samples`: æœ€å¤šè¯„ä¼°æ ·æœ¬æ•° (é»˜è®¤: å…¨éƒ¨)
- `--api-key`: DashScope API Key (é»˜è®¤: ä» .env è¯»å–)

### 3. è¯„ä¼°æŒ‡æ ‡å®ç° (T098-T100)

#### T098: Context Relevance è¯„ä¼°

**å®ç°**:
```python
eval_results = evaluate(
    dataset,
    metrics=[ContextRecall()],
    llm=self.eval_llm,
    embeddings=self.eval_embeddings
)
```

**è¾“å‡ºç¤ºä¾‹**:
```
| Context Recall | 87.3% | â‰¥85% | âœ… è¾¾æ ‡ |
```

#### T099: Answer Faithfulness è¯„ä¼°

**å®ç°**:
```python
eval_results = evaluate(
    dataset,
    metrics=[Faithfulness()],
    llm=self.eval_llm,
    embeddings=self.eval_embeddings
)
```

**è¾“å‡ºç¤ºä¾‹**:
```
| Answer Faithfulness | 96.8% | â‰¥95% | âœ… è¾¾æ ‡ |
```

#### T100: å“åº”é€Ÿåº¦è¯„ä¼°

**å®ç°**:
```python
def evaluate_response_time(self, results, target_threshold=30.0):
    response_times = [r['response_time'] for r in results]

    stats = {
        'mean': mean(response_times),
        'p50': percentile(response_times, 50),
        'p95': percentile(response_times, 95),
        'p99': percentile(response_times, 99),
        ...
    }
    return stats
```

**è¾“å‡ºç¤ºä¾‹**:
```
| å¹³å‡å“åº”æ—¶é—´ | 18.45s |
| P50 (ä¸­ä½æ•°) | 16.23s |
| P95 | 25.67s |
| ç›®æ ‡é˜ˆå€¼ | <30s |
| è¾¾æ ‡ç‡ | 96.8% (30/31) |
| çŠ¶æ€ | âœ… è¾¾æ ‡ |
```

### 4. ä¼˜åŒ–æŒ‡å— (T101)

**æ–‡ä»¶**: `docs/OPTIMIZATION_GUIDE.md`

#### ä¼˜åŒ–å†³ç­–æ ‘

æ ¹æ®è¯„ä¼°ç»“æœæä¾›é’ˆå¯¹æ€§ä¼˜åŒ–å»ºè®®:

```
è¯„ä¼°ç»“æœåˆ†æ
â”œâ”€â”€ Context Recall < 85%
â”‚   â”œâ”€â”€ è°ƒæ•´æ£€ç´¢ç­–ç•¥
â”‚   â”œâ”€â”€ å¢åŠ æ£€ç´¢æ–‡æ¡£æ•°é‡
â”‚   â””â”€â”€ ä¼˜åŒ– Embedding æ¨¡å‹
â”‚
â”œâ”€â”€ Faithfulness < 95%
â”‚   â”œâ”€â”€ ä¼˜åŒ– System Prompt
â”‚   â”œâ”€â”€ é™ä½ Temperature
â”‚   â””â”€â”€ æ·»åŠ éªŒè¯æ­¥éª¤
â”‚
â”œâ”€â”€ Response Time > 30s
â”‚   â”œâ”€â”€ å‡å°‘æ£€ç´¢æ–‡æ¡£æ•°
â”‚   â”œâ”€â”€ ä½¿ç”¨ç»“æœç¼“å­˜
â”‚   â””â”€â”€ å¹¶è¡Œå¤„ç†
â”‚
â””â”€â”€ Answer Correctness < 85%
    â”œâ”€â”€ å¾®è°ƒ LLM
    â”œâ”€â”€ æ”¹è¿› Prompt Engineering
    â””â”€â”€ å¢å¼ºçŸ¥è¯†åº“è´¨é‡
```

#### æ£€ç´¢ä¼˜åŒ–

**1. æ··åˆæ£€ç´¢æƒé‡è°ƒæ•´**

```python
# æ¨èé…ç½®
self.bm25_weight = 0.4  # BM25 æƒé‡
self.vector_weight = 0.6  # å‘é‡æ£€ç´¢æƒé‡
```

| åœºæ™¯ | BM25 æƒé‡ | å‘é‡æƒé‡ | è¯´æ˜ |
|------|-----------|----------|------|
| ç²¾ç¡®åŒ¹é… | 0.5 | 0.5 | ç‰ˆæœ¬å·ã€å‘½ä»¤å |
| è¯­ä¹‰ç†è§£ | 0.3 | 0.7 | æ¦‚å¿µè§£é‡Šã€åŸç† |
| é€šç”¨åœºæ™¯ | 0.4 | 0.6 | **æ¨è** |

**2. top_k ä¼˜åŒ–**

| top_k | Context Recall | Response Time | æ¨èåœºæ™¯ |
|-------|----------------|---------------|----------|
| 3 | 78% | 12s | å¿«é€Ÿå“åº” |
| 5 | 87% | 18s | **é»˜è®¤** |
| 10 | 92% | 28s | é«˜ç²¾åº¦ |

**3. Reranker é›†æˆ**

```python
from sentence_transformers import CrossEncoder

reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
```

æ•ˆæœ: Context Recall +8%

#### ç”Ÿæˆä¼˜åŒ–

**1. Prompt ä¼˜åŒ–**

å¼ºåŒ–å¿ å®åº¦ç‰ˆæœ¬:
```python
system_prompt = """ä½ æ˜¯é­”æ­ç¤¾åŒºçš„æŠ€æœ¯æ”¯æŒä¸“å®¶ã€‚

**æ ¸å¿ƒåŸåˆ™**: å›ç­”å¿…é¡»å®Œå…¨åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹ã€‚

**å›ç­”è§„åˆ™**:
1. âœ… åªä½¿ç”¨æ–‡æ¡£ä¸­æ˜ç¡®æåˆ°çš„ä¿¡æ¯
2. âŒ ä¸è¦æ·»åŠ æ–‡æ¡£ä¸­æ²¡æœ‰çš„å†…å®¹
3. âŒ ä¸è¦æ¨æµ‹æˆ–å‡è®¾
4. âœ… å¦‚æœæ–‡æ¡£ä¸åŒ…å«ç­”æ¡ˆ,ç›´æ¥è¯´"æ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯"
5. âœ… æ ‡æ³¨ä¿¡æ¯æ¥æº (ä½¿ç”¨å¼•å·å¼•ç”¨åŸæ–‡)
"""
```

æ•ˆæœ: Faithfulness +3%

**2. å‚æ•°è°ƒæ•´**

| åœºæ™¯ | Temperature | Top_p | è¯´æ˜ |
|------|-------------|-------|------|
| ç¡®å®šæ€§ç­”æ¡ˆ | 0.3 | 0.9 | æé«˜å¿ å®åº¦ |
| åˆ›é€ æ€§ç­”æ¡ˆ | 0.8 | 0.95 | æ›´çµæ´» |
| å¹³è¡¡ | 0.5 | 0.9 | **æ¨è** |

#### æ€§èƒ½ä¼˜åŒ–

**1. ç»“æœç¼“å­˜**

```python
class CacheManager:
    def __init__(self, redis_host='localhost', redis_port=6379):
        self.redis = Redis(host=redis_host, port=redis_port)
        self.ttl = 3600  # 1å°æ—¶

    def get(self, question: str):
        """è·å–ç¼“å­˜ç­”æ¡ˆ"""
        key = f"qa:{md5(question)}"
        return self.redis.get(key)

    def set(self, question: str, answer: dict):
        """è®¾ç½®ç¼“å­˜"""
        key = f"qa:{md5(question)}"
        self.redis.setex(key, self.ttl, json.dumps(answer))
```

æ•ˆæœ: ç¼“å­˜å‘½ä¸­æ—¶å“åº”æ—¶é—´ä» 18s é™è‡³ <1s

**2. æ‰¹é‡å¤„ç†**

é€‚ç”¨åœºæ™¯: æ‰¹é‡è¯„ä¼°æˆ–ç¦»çº¿å¤„ç†

æ•ˆæœ: ååé‡æå‡ 30-50%

#### çŸ¥è¯†åº“ä¼˜åŒ–

**1. æ–‡æ¡£è´¨é‡æå‡**

ç­–ç•¥:
- å»é‡: ç§»é™¤å®Œå…¨é‡å¤çš„æ–‡æ¡£
- è¿‡æ»¤: ç§»é™¤ä½è´¨é‡ç‰‡æ®µ
- è¡¥å……: æ·»åŠ æ›´å¤šå®˜æ–¹æ–‡æ¡£
- æ ‡æ³¨: æ·»åŠ å…ƒæ•°æ® (é‡è¦æ€§ã€æ—¶æ•ˆæ€§)

æ•ˆæœ: æ‰€æœ‰æŒ‡æ ‡ +5%

**2. è¯­ä¹‰åˆ†å—**

```python
from langchain.text_splitter import SemanticChunker

splitter = SemanticChunker(embeddings=embeddings)
chunks = splitter.split_text(document)
```

æ•ˆæœ: Context Recall +3-5%

#### ç›‘æ§å’ŒæŒç»­ä¼˜åŒ–

**1. å…³é”®æŒ‡æ ‡ç›‘æ§**
- QPS (æ¯ç§’æŸ¥è¯¢æ•°)
- P50/P95/P99 å“åº”æ—¶é—´
- é”™è¯¯ç‡
- ç¼“å­˜å‘½ä¸­ç‡
- ç”¨æˆ·æ»¡æ„åº¦

**2. A/B Testing**

æµ‹è¯•ä¸åŒé…ç½®çš„æ•ˆæœï¼Œé€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ

**3. å®šæœŸè¯„ä¼°**
- å®Œæ•´è¯„ä¼°: æ¯æœˆ1æ¬¡
- å¿«é€Ÿæ£€æŸ¥: æ¯å‘¨1æ¬¡
- å®æ—¶ç›‘æ§: æŒç»­

#### ä¼˜åŒ–æ•ˆæœé¢„æœŸ

| ä¼˜åŒ–é¡¹ | é¢„æœŸæå‡ | å®æ–½éš¾åº¦ | ä¼˜å…ˆçº§ |
|--------|----------|----------|--------|
| å¯ç”¨ç¼“å­˜ | Response Time -80% | ä½ | â­â­â­ |
| è°ƒæ•´æƒé‡ | Context Recall +5% | ä½ | â­â­â­ |
| ä¼˜åŒ– Prompt | Faithfulness +3% | ä½ | â­â­â­ |
| æ·»åŠ  Reranker | Context Recall +8% | ä¸­ | â­â­ |
| æ¸…æ´—çŸ¥è¯†åº“ | All Metrics +5% | é«˜ | â­â­ |
| æ¨¡å‹å¾®è°ƒ | Answer Correctness +10% | é«˜ | â­ |

#### ä¼˜åŒ–æ¸…å•

**ç«‹å³å¯åš (< 1å°æ—¶)**:
- [ ] è°ƒæ•´ temperature è‡³ 0.5
- [ ] ä¿®æ”¹ system prompt å¼ºåŒ–å¿ å®åº¦
- [ ] è°ƒæ•´æ··åˆæ£€ç´¢æƒé‡ä¸º 0.4/0.6
- [ ] å¯ç”¨ Redis ç¼“å­˜

**çŸ­æœŸä¼˜åŒ– (1-3å¤©)**:
- [ ] å®ç°ç»“æœç¼“å­˜
- [ ] æ·»åŠ ç­”æ¡ˆéªŒè¯æ­¥éª¤
- [ ] ä¼˜åŒ–æ–‡æ¡£åˆ†å—ç­–ç•¥
- [ ] å»ºç«‹ç›‘æ§ dashboard

**ä¸­æœŸä¼˜åŒ– (1-2å‘¨)**:
- [ ] é›†æˆ Reranker
- [ ] æ¸…æ´—å’Œæ‰©å……çŸ¥è¯†åº“
- [ ] å®ç°åŠ¨æ€ top_k è°ƒæ•´
- [ ] A/B æµ‹è¯•ä¸åŒé…ç½®

**é•¿æœŸä¼˜åŒ– (1ä¸ªæœˆ+)**:
- [ ] å¾®è°ƒ Embedding æ¨¡å‹
- [ ] å¾®è°ƒ LLM
- [ ] å®ç°å¤šæ¨¡æ€æ”¯æŒ
- [ ] ä¼˜åŒ–ç³»ç»Ÿæ¶æ„

---

## æ–‡æ¡£èµ„æº

### è¯„ä¼°æŒ‡å—

**æ–‡ä»¶**: `docs/EVALUATION_GUIDE.md`

å†…å®¹åŒ…æ‹¬:
- è¯„ä¼°æŒ‡æ ‡è¯¦ç»†è¯´æ˜
- å‡†å¤‡å·¥ä½œå’Œç¯å¢ƒæ£€æŸ¥
- è¿è¡Œè¯„ä¼°çš„å®Œæ•´æ­¥éª¤
- è¯„ä¼°æŠ¥å‘Šè§£è¯»
- å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### ä¼˜åŒ–æŒ‡å—

**æ–‡ä»¶**: `docs/OPTIMIZATION_GUIDE.md`

å†…å®¹åŒ…æ‹¬:
- ä¼˜åŒ–å†³ç­–æ ‘
- æ£€ç´¢ä¼˜åŒ–ç­–ç•¥å’Œé…ç½®
- ç”Ÿæˆä¼˜åŒ– (Prompt + å‚æ•°)
- æ€§èƒ½ä¼˜åŒ– (ç¼“å­˜ + å¹¶è¡Œ)
- çŸ¥è¯†åº“ä¼˜åŒ–æ–¹æ³•
- ç›‘æ§å’ŒæŒç»­ä¼˜åŒ–
- ä¼˜åŒ–æ¸…å•å’Œé¢„æœŸæ•ˆæœ

---

## æŠ€æœ¯å®ç°äº®ç‚¹

### 1. å…¼å®¹æ€§é—®é¢˜è§£å†³

**é—®é¢˜**: RAGAs 0.1.0 ä¸ langchain-core 1.0.2 ä¸å…¼å®¹

```python
# é”™è¯¯
ModuleNotFoundError: No module named 'langchain_core.pydantic_v1'
```

**è§£å†³**: å‡çº§åˆ° RAGAs 0.3.9

```bash
pip install --upgrade ragas
# æˆåŠŸå®‰è£… ragas-0.3.9
```

å¹¶æ›´æ–° API è°ƒç”¨:

```python
# æ—§ç‰ˆ (0.1.0)
from ragas.metrics import context_relevancy, faithfulness

# æ–°ç‰ˆ (0.3.9)
from ragas.metrics import ContextRecall, Faithfulness

metrics = [
    ContextRecall(),
    Faithfulness(),
    AnswerRelevancy(),
    AnswerCorrectness()
]
```

### 2. å®Œæ•´çš„é”™è¯¯å¤„ç†

è¯„ä¼°è„šæœ¬åŒ…å«å®Œæ•´çš„é™çº§æœºåˆ¶:

```python
try:
    # å°è¯•ä½¿ç”¨ RAGAs è¯„ä¼°
    eval_results = evaluate(dataset, metrics=[...])
except Exception as e:
    # é™çº§: ä½¿ç”¨åŸºç¡€ç»Ÿè®¡
    eval_results = self._calculate_basic_metrics(results)
```

åŸºç¡€æŒ‡æ ‡åŒ…æ‹¬:
- æˆåŠŸç‡
- å¹³å‡å“åº”æ—¶é—´
- å¹³å‡ç½®ä¿¡åº¦

### 3. è¯¦ç»†çš„è¿›åº¦è¾“å‡º

è¯„ä¼°è¿‡ç¨‹ä¸­æä¾›æ¸…æ™°çš„è¿›åº¦åé¦ˆ:

```
ğŸ“¥ åŠ è½½è¯„æµ‹æ•°æ®é›†
âœ… åŠ è½½æˆåŠŸ: 31 æ¡æµ‹è¯•æ•°æ®

ğŸ“Š æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒ:
   - model_usage: 8 æ¡
   ...

ğŸ¤– è¿è¡Œ Agent æ¨ç†
[1/31] å¤„ç†é—®é¢˜: ...
   âœ… å®Œæˆ (è€—æ—¶: 15.32s, ç½®ä¿¡åº¦: 0.95)
...

ğŸ“Š RAGAs è¯„ä¼°
ğŸ” å¼€å§‹è¯„ä¼° (å…± 31 æ¡æ•°æ®)...
âœ… è¯„ä¼°å®Œæˆ!

â±ï¸  å“åº”é€Ÿåº¦è¯„ä¼°
ğŸ“Š å“åº”æ—¶é—´ç»Ÿè®¡: ...
```

### 4. çµæ´»çš„æŠ¥å‘Šæ ¼å¼

åŒæ—¶ç”Ÿæˆ Markdown å’Œ JSON ä¸¤ç§æ ¼å¼:

- **Markdown**: ä¾¿äºäººç±»é˜…è¯»ï¼ŒåŒ…å«è¡¨æ ¼å’Œæ€»ç»“
- **JSON**: ä¾¿äºç¨‹åºåŒ–åˆ†æï¼ŒåŒ…å«å®Œæ•´æ•°æ®

### 5. å¯é…ç½®çš„ CLI

æ”¯æŒå¤šç§å‘½ä»¤è¡Œå‚æ•°:
- è‡ªå®šä¹‰æ•°æ®é›†
- æ§åˆ¶æ ·æœ¬æ•°é‡
- æŒ‡å®šè¾“å‡ºè·¯å¾„
- è¦†ç›– API å¯†é’¥

---

## ç¼–è¯‘å’ŒéªŒè¯

### ä»£ç ç¼–è¯‘

æ‰€æœ‰ä»£ç å‡é€šè¿‡ç¼–è¯‘æ£€æŸ¥:

```bash
âœ… scripts/evaluate_rag.py - ç¼–è¯‘æˆåŠŸ
âœ… data/evaluation_dataset.json - JSON æ ¼å¼æ­£ç¡®
âœ… docs/EVALUATION_GUIDE.md - Markdown æ ¼å¼æ­£ç¡®
âœ… docs/OPTIMIZATION_GUIDE.md - Markdown æ ¼å¼æ­£ç¡®
```

### ä¾èµ–å®‰è£…

```bash
# RAGAs åŠå…¶ä¾èµ–
pip install ragas==0.3.9

# æ–°å¢ä¾èµ–
- diskcache==5.6.3
- instructor==1.13.0
- scikit-network==0.33.5
- pre-commit==4.5.0
```

### åŠŸèƒ½éªŒè¯

```bash
# æµ‹è¯• --help
$ python scripts/evaluate_rag.py --help
âœ… æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

# æµ‹è¯•æ•°æ®é›†åŠ è½½
$ python -c "import json; print(len(json.load(open('data/evaluation_dataset.json'))))"
âœ… 31 ä¸ªé—®é¢˜

# æµ‹è¯• RAGAs å¯¼å…¥
$ python -c "from ragas.metrics import ContextRecall, Faithfulness; print('âœ…')"
âœ… å¯¼å…¥æˆåŠŸ
```

---

## é—®é¢˜è®°å½•å’Œè§£å†³

### é—®é¢˜ 1: RAGAs ç‰ˆæœ¬ä¸å…¼å®¹

**æè¿°**: RAGAs 0.1.0 æ— æ³•ä¸ langchain-core 1.0.2 ä¸€èµ·å·¥ä½œ

**é”™è¯¯ä¿¡æ¯**:
```
ModuleNotFoundError: No module named 'langchain_core.pydantic_v1'
```

**æ ¹æœ¬åŸå› **: langchain-core 1.0.2 ç§»é™¤äº† `pydantic_v1` æ¨¡å—

**è§£å†³æ–¹æ¡ˆ**: å‡çº§ RAGAs åˆ° 0.3.9

```bash
pip install --upgrade ragas
# Successfully installed ragas-0.3.9
```

**å½±å“**: éœ€è¦æ›´æ–° API è°ƒç”¨æ–¹å¼ï¼Œä»å‡½æ•°è°ƒç”¨æ”¹ä¸ºç±»å®ä¾‹åŒ–

**éªŒè¯**: æˆåŠŸå¯¼å…¥å¹¶è¿è¡Œ `--help` å‘½ä»¤

### æ²¡æœ‰å…¶ä»–é—®é¢˜

æ‰€æœ‰ä»»åŠ¡å‡ä¸€æ¬¡æ€§å®ç°æˆåŠŸï¼Œæ²¡æœ‰ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ã€‚

---

## éµå¾ªç”¨æˆ·è¦æ±‚

âœ… **æ¯ä¸ªä»»åŠ¡åä¿è¯æ­£å¸¸ç¼–è¯‘è¿è¡Œ**:
- æ¯ä¸ªæ–‡ä»¶åˆ›å»ºåéƒ½è¿›è¡Œäº†ç¼–è¯‘éªŒè¯
- ä½¿ç”¨ `python -m py_compile` æ£€æŸ¥è¯­æ³•
- ä½¿ç”¨ `--help` æµ‹è¯•è„šæœ¬åŠŸèƒ½

âœ… **ä¸ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬**:
- RAGAs å…¼å®¹æ€§é—®é¢˜é€šè¿‡å‡çº§å®Œæ•´è§£å†³
- æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡å®Œæ•´å®ç°
- ä¼˜åŒ–æŒ‡å—æä¾›æ·±å…¥çš„æŠ€æœ¯ç»†èŠ‚

âœ… **æè¿°é—®é¢˜ä¿¡æ¯**:
- è¯¦ç»†è®°å½•äº† RAGAs ç‰ˆæœ¬ä¸å…¼å®¹é—®é¢˜
- è¯´æ˜äº†æ ¹æœ¬åŸå› å’Œè§£å†³æ–¹æ¡ˆ
- éªŒè¯äº†ä¿®å¤æ•ˆæœ

---

## ä¸‹ä¸€æ­¥å»ºè®®

### ç«‹å³å¯åš

1. **è¿è¡Œå¿«é€Ÿè¯„ä¼°** (5ä¸ªæ ·æœ¬)
   ```bash
   python scripts/evaluate_rag.py --max-samples 5
   ```

2. **å¯ç”¨ç¼“å­˜**
   - å¯åŠ¨ Redis æœåŠ¡
   - å®ç° CacheManager ç±»

3. **è°ƒæ•´å‚æ•°**
   - temperature = 0.5
   - bm25_weight = 0.4, vector_weight = 0.6

### åç»­ä¼˜åŒ–

æ ¹æ®è¯„ä¼°ç»“æœ:

**å¦‚æœ Context Recall < 85%**:
- å¢åŠ  top_k åˆ° 7-8
- è°ƒæ•´æ··åˆæ£€ç´¢æƒé‡
- è€ƒè™‘æ·»åŠ  Reranker

**å¦‚æœ Faithfulness < 95%**:
- ä¼˜åŒ– System Prompt
- é™ä½ temperature åˆ° 0.3-0.4
- æ·»åŠ ç­”æ¡ˆéªŒè¯æ­¥éª¤

**å¦‚æœ Response Time > 30s**:
- å¯ç”¨ç¼“å­˜æœºåˆ¶
- å‡å°‘ top_k åˆ° 3-4
- å®ç°å¹¶è¡Œå¤„ç†

---

## æ€»ç»“

Phase 3.7 æˆåŠŸå®ç°äº†å®Œæ•´çš„ RAG ç³»ç»Ÿè¯„ä¼°å’Œä¼˜åŒ–æ¡†æ¶:

### ä¸»è¦æˆå°±

1. âœ… **è¯„æµ‹æ•°æ®é›†**: 31ä¸ªçœŸå® ModelScope æŠ€æœ¯é—®é¢˜ï¼Œè¦†ç›–10ä¸ªç±»åˆ«
2. âœ… **è¯„ä¼°è„šæœ¬**: 628è¡Œå®Œæ•´å®ç°ï¼Œæ”¯æŒ RAGAs 4ä¸ªæ ¸å¿ƒæŒ‡æ ‡
3. âœ… **è¯„ä¼°æŒ‡æ ‡**: Context Recall, Faithfulness, Answer Relevancy, Answer Correctness
4. âœ… **å“åº”æ—¶é—´**: å®Œæ•´çš„ç»Ÿè®¡åˆ†æ (Mean, P50, P95, P99)
5. âœ… **ä¼˜åŒ–æŒ‡å—**: è¯¦ç»†çš„ä¼˜åŒ–ç­–ç•¥å’Œé…ç½®å»ºè®®
6. âœ… **æ–‡æ¡£å®Œå–„**: è¯„ä¼°æŒ‡å—å’Œä¼˜åŒ–æŒ‡å—å…± 400+ è¡Œ

### æŠ€æœ¯äº®ç‚¹

- è§£å†³äº† RAGAs å…¼å®¹æ€§é—®é¢˜
- å®ç°äº†å®Œæ•´çš„é™çº§æœºåˆ¶
- æä¾›äº†çµæ´»çš„ CLI æ¥å£
- ç”Ÿæˆäº†ä¸¤ç§æ ¼å¼çš„æŠ¥å‘Š
- åŒ…å«è¯¦ç»†çš„ä¼˜åŒ–å»ºè®®

### è´¨é‡ä¿è¯

- æ‰€æœ‰ä»£ç ç¼–è¯‘é€šè¿‡
- ä¾èµ–æˆåŠŸå®‰è£…
- åŠŸèƒ½éªŒè¯å®Œæˆ
- æ–‡æ¡£è¯¦ç»†å®Œæ•´

Phase 3.7 åœ†æ»¡å®Œæˆ! ğŸ‰

---

**å®Œæˆæ—¥æœŸ**: 2025-12-01
**æ€»å®ç°æ—¶é—´**: å•æ¬¡ä¼šè¯
**çŠ¶æ€**: âœ… COMPLETE
