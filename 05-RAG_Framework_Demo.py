#!/usr/bin/env python3
"""
LangChain v1.0 - RAG æ™ºèƒ½æ¡†æ¶æ¼”ç¤ºç‰ˆ
=====================================

ç®€åŒ–ç‰ˆæ¼”ç¤ºï¼Œä¸“æ³¨äºæ ¸å¿ƒ RAG åŠŸèƒ½
"""

import os
import time
from dataclasses import dataclass
from typing import List, Dict, Any

import dotenv
from langchain_community.chat_models import ChatZhipuAI
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, SystemMessage
from langchain.agents import create_agent
from langchain.agents.middleware import AgentMiddleware, ModelRequest
from langchain.agents.middleware.types import ModelResponse
from langchain_core.tools import tool

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv(dotenv_path="../.env")


# ========== å·¥å…· ==========

@tool
def rag_retriever(query: str) -> str:
    """RAG æ£€ç´¢å·¥å…·"""
    return f"[RAG] æ­£åœ¨æ£€ç´¢å…³äº '{query}' çš„ä¿¡æ¯"


@tool
def web_search_tool(query: str) -> str:
    """ç½‘ç»œæœç´¢å·¥å…·"""
    return f"[æœç´¢] æ­£åœ¨æœç´¢ '{query}'"


@tool
def knowledge_qa(question: str, context: str) -> str:
    """çŸ¥è¯†é—®ç­”å·¥å…·

    Args:
        question: é—®é¢˜
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    return f"[QA] åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ï¼š\n{context}\n\né—®é¢˜ï¼š{question}"


# ========== ä¸­é—´ä»¶ ==========

class RAGLoggingMiddleware(AgentMiddleware):
    """RAG æ—¥å¿—ä¸­é—´ä»¶"""

    def wrap_model_call(
        self,
        request: ModelRequest,
        handler,
    ) -> ModelResponse:
        print(f"\nğŸ” [ä¸­é—´ä»¶] å¤„ç†è¯·æ±‚")
        print(f"   æ¶ˆæ¯æ•°: {len(request.messages)}")

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        # æ‰§è¡Œè¯·æ±‚
        response = handler(request)

        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        print(f"   è€—æ—¶: {end_time - start_time:.3f}s")

        return response


# ========== ç¤ºä¾‹æ–‡æ¡£ ==========

def create_sample_documents() -> List[Document]:
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£"""
    texts = [
        """äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚

AI çš„ä¸»è¦åº”ç”¨é¢†åŸŸï¼š
1. è‡ªç„¶è¯­è¨€å¤„ç† - ä½¿è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€
2. è®¡ç®—æœºè§†è§‰ - ä½¿è®¡ç®—æœºèƒ½å¤Ÿè§£é‡Šå’Œç†è§£è§†è§‰ä¿¡æ¯
3. æœºå™¨å­¦ä¹  - è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ 
4. æœºå™¨äººæŠ€æœ¯ - å°†æ™ºèƒ½é›†æˆåˆ°ç‰©ç†æœºå™¨äººä¸­

AI çš„å‘å±•ç»å†äº†å¤šä¸ªé˜¶æ®µï¼ŒåŒ…æ‹¬ç¬¦å· AIã€è¿æ¥ä¸»ä¹‰ã€æ·±åº¦å­¦ä¹ ç­‰ã€‚""",

        """æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨ç»Ÿè®¡æŠ€æœ¯è®©è®¡ç®—æœºä»æ•°æ®ä¸­"å­¦ä¹ "ã€‚

æœºå™¨å­¦ä¹ çš„ä¸‰ç§ä¸»è¦ç±»å‹ï¼š
1. ç›‘ç£å­¦ä¹  - ä½¿ç”¨æ ‡è®°æ•°æ®è®­ç»ƒæ¨¡å‹
2. æ— ç›‘ç£å­¦ä¹  - å‘ç°æ•°æ®ä¸­çš„éšè—æ¨¡å¼
3. å¼ºåŒ–å­¦ä¹  - é€šè¿‡è¯•é”™å­¦ä¹ æœ€ä¼˜ç­–ç•¥

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰ä»»åŠ¡ä¸­å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚""",

        """è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½å’Œè¯­è¨€å­¦çš„äº¤å‰é¢†åŸŸï¼Œè‡´åŠ›äºè®©è®¡ç®—æœºç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚

NLP çš„ä¸»è¦ä»»åŠ¡ï¼š
- æ–‡æœ¬åˆ†ç±»ï¼šè‡ªåŠ¨å°†æ–‡æœ¬åˆ†é…åˆ°é¢„å®šä¹‰çš„ç±»åˆ«
- æƒ…æ„Ÿåˆ†æï¼šè¯†åˆ«æ–‡æœ¬ä¸­çš„æƒ…æ„Ÿå€¾å‘
- æœºå™¨ç¿»è¯‘ï¼šå°†æ–‡æœ¬ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€
- é—®ç­”ç³»ç»Ÿï¼šç†è§£é—®é¢˜å¹¶æä¾›å‡†ç¡®çš„ç­”æ¡ˆ
- æ–‡æœ¬æ‘˜è¦ï¼šç”Ÿæˆæ–‡æ¡£çš„ç®€æ´æ‘˜è¦

ç°ä»£ NLP å¹¿æ³›ä½¿ç”¨ Transformer æ¶æ„å’Œé¢„è®­ç»ƒæ¨¡å‹ã€‚""",
    ]

    return [
        Document(page_content=text, metadata={"source": f"doc_{i}"})
        for i, text in enumerate(texts)
    ]


# ========== RAG æ¡†æ¶ ==========

class SimpleRAGFramework:
    """ç®€åŒ–ç‰ˆ RAG æ¡†æ¶"""

    def __init__(self):
        # å·¥å…·
        self.tools = [rag_retriever, web_search_tool, knowledge_qa]

        # æ¨¡å‹
        self.llm = ChatZhipuAI(
            model="glm-4.6",
            temperature=0.3,
            api_key=os.getenv("ZHIPUAI_API_KEY"),
        )

        # ä¸­é—´ä»¶
        self.middleware = RAGLoggingMiddleware()

        # åˆ›å»º Agent
        self.agent = create_agent(
            model=self.llm,
            tools=self.tools,
            middleware=[self.middleware],
        )

        # æ–‡æ¡£å­˜å‚¨
        self.docs = []
        self.vector_store = None

        print("âœ… RAG æ¡†æ¶åˆå§‹åŒ–å®Œæˆ")

    def load_documents(self, docs: List[Document]):
        """åŠ è½½æ–‡æ¡£"""
        # åˆ†å‰²æ–‡æ¡£
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
        )
        self.docs = splitter.split_documents(docs)

        # åˆ›å»ºå‘é‡å­˜å‚¨
        embeddings = OpenAIEmbeddings(
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            openai_api_base=os.getenv("OPENAI_BASE_URL"),
        )
        self.vector_store = FAISS.from_documents(self.docs, embeddings)

        print(f"âœ… æ–‡æ¡£åŠ è½½å®Œæˆ: {len(self.docs)} ä¸ªæ–‡æ¡£å—")

    def retrieve(self, query: str, k: int = 3) -> List[Document]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        if not self.vector_store:
            raise ValueError("è¯·å…ˆåŠ è½½æ–‡æ¡£")

        retriever = self.vector_store.as_retriever(
            search_kwargs={"k": k}
        )
        return retriever.invoke(query)

    def query(self, question: str) -> Dict[str, Any]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = self.retrieve(question)
        context = "\n\n".join([doc.page_content for doc in docs])

        # æ„å»ºæŸ¥è¯¢
        enhanced_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ï¼Œå¹¶æ³¨æ˜ä¿¡æ¯æ¥æºã€‚"""

        # æ‰§è¡ŒæŸ¥è¯¢
        result = self.agent.invoke({
            "messages": [
                SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åŸºäºæ–‡æ¡£å›ç­”é—®é¢˜ã€‚"),
                HumanMessage(content=enhanced_prompt),
            ]
        })

        return {
            "question": question,
            "answer": result.get("output", str(result)),
            "context_docs": len(docs),
            "sources": [doc.metadata for doc in docs],
        }


# ========== æ¼”ç¤ºå‡½æ•° ==========

def demo_basic_rag():
    """æ¼”ç¤ºåŸºæœ¬ RAG åŠŸèƒ½"""
    print("=" * 70)
    print("ğŸ“š RAG æ™ºèƒ½æ¡†æ¶æ¼”ç¤º")
    print("=" * 70)

    # åˆå§‹åŒ–æ¡†æ¶
    framework = SimpleRAGFramework()

    # åŠ è½½ç¤ºä¾‹æ–‡æ¡£
    docs = create_sample_documents()
    framework.load_documents(docs)

    # æµ‹è¯•æŸ¥è¯¢
    questions = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ",
        "è‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸»è¦ä»»åŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ",
    ]

    print(f"\nğŸ” æ‰§è¡Œ {len(questions)} ä¸ªæŸ¥è¯¢...\n")

    for i, q in enumerate(questions, 1):
        print(f"ã€æŸ¥è¯¢ {i}ã€‘{q}")
        result = framework.query(q)
        print(f"\nğŸ“ ç­”æ¡ˆï¼š\n{result['answer']}")
        print(f"\nğŸ“Š ä½¿ç”¨äº† {result['context_docs']} ä¸ªç›¸å…³æ–‡æ¡£")
        print("-" * 70)


def explain_framework():
    """è§£é‡Šæ¡†æ¶æ¶æ„"""
    print("\n" + "=" * 70)
    print("ğŸ—ï¸ RAG æ™ºèƒ½æ¡†æ¶æ¶æ„")
    print("=" * 70)

    print("""
ğŸ”§ æ ¸å¿ƒç»„ä»¶ï¼š

1. DocumentProcessorï¼ˆæ–‡æ¡£å¤„ç†å™¨ï¼‰
   - åŠ è½½å’Œåˆ†å‰²æ–‡æ¡£
   - ç”Ÿæˆå‘é‡è¡¨ç¤º

2. VectorStoreï¼ˆå‘é‡å­˜å‚¨ï¼‰
   - ä½¿ç”¨ FAISS è¿›è¡Œé«˜æ•ˆæ£€ç´¢
   - æ”¯æŒç›¸ä¼¼åº¦æœç´¢

3. Toolsï¼ˆå·¥å…·é›†ï¼‰
   - RAG æ£€ç´¢å·¥å…·
   - ç½‘ç»œæœç´¢å·¥å…·
   - çŸ¥è¯†é—®ç­”å·¥å…·

4. Middlewareï¼ˆä¸­é—´ä»¶ï¼‰
   - æ—¥å¿—è®°å½•
   - æ€§èƒ½ç›‘æ§
   - è¯·æ±‚æ‹¦æˆª

5. Agentï¼ˆæ™ºèƒ½ä»£ç†ï¼‰
   - è‡ªåŠ¨é€‰æ‹©å·¥å…·
   - æ•´åˆå¤šä¸ªä¿¡æ¯æº
   - ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

ğŸš€ å·¥ä½œæµç¨‹ï¼š
1. ç”¨æˆ·æé—®
2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
3. æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
4. Agent è‡ªåŠ¨é€‰æ‹©å·¥å…·
5. ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

ğŸ’¡ åˆ›æ–°ç‰¹æ€§ï¼š
âœ… æ¨¡å—åŒ–è®¾è®¡
âœ… å¯æ‰©å±•å·¥å…·é›†
âœ… ä¸­é—´ä»¶æ”¯æŒ
âœ… LangChain v1.0 å…¼å®¹
âœ… ä¸­æ–‡ä¼˜åŒ–
    """)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LangChain v1.0 - RAG æ™ºèƒ½æ¡†æ¶æ¼”ç¤º")
    print("=" * 80)

    try:
        # æ¶æ„è¯´æ˜
        explain_framework()

        # åŸºæœ¬æ¼”ç¤º
        demo_basic_rag()

        print("\n" + "=" * 70)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 70)

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
