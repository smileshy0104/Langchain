#!/usr/bin/env python3
"""
GLM-4.6 å·¥å…·è°ƒç”¨ Agent ç¤ºä¾‹ï¼ˆLangChain v1.0 è¯­æ³•ï¼‰ã€‚

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ GLM-4.6 ä¸ LangChain v1.0 çš„ create_agent
æ„å»ºä¸€ä¸ªå¯ä»¥è°ƒç”¨å·¥å…·çš„å¯¹è¯å¼ Agentã€‚

ä¸»è¦å˜åŒ–ï¼ˆv1.0ï¼‰ï¼š
- ä½¿ç”¨æ–°çš„ create_agent APIï¼ˆåŸºäº langgraphï¼‰
- AgentExecutor å·²è¢«ç§»é™¤
- è¿”å› CompiledStateGraph å¯¹è±¡
- ä½¿ç”¨å†…ç½®çš„å·¥å…·è°ƒç”¨æœºåˆ¶
- æ”¯æŒ GLM-4.6 æ™ºè°±AIæ¨¡å‹
"""

from __future__ import annotations

import os
from typing import Any, Sequence

import dotenv
from langchain_community.chat_models import ChatZhipuAI
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage
from langchain_core.tools import BaseTool, tool
from langchain.agents import create_agent

# ä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½ .env
dotenv.load_dotenv(dotenv_path="../.env")


def _require_env_var(name: str) -> str:
    """ç¡®ä¿å¿…éœ€çš„ç¯å¢ƒå˜é‡å­˜åœ¨ã€‚"""
    value = os.getenv(name)
    if not value or value.startswith("your-"):
        raise EnvironmentError(
            f"æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„ {name}ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ .env ä¸­é…ç½®åé‡è¯•ã€‚"
        )
    return value


def _normalize_tools(
    tools: Sequence[BaseTool],
) -> list[BaseTool]:
    """ç¡®ä¿å·¥å…·æ˜¯ BaseTool å®ä¾‹åˆ—è¡¨ã€‚"""
    normalized: list[BaseTool] = []
    for item in tools:
        if isinstance(item, BaseTool):
            normalized.append(item)
        else:
            raise TypeError(f"å·¥å…·å¿…é¡»æ˜¯ BaseTool å®ä¾‹ï¼Œå¾—åˆ°: {type(item)}")
    return normalized


@tool
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”é¢„æŠ¥ï¼ˆç¤ºä¾‹å‡½æ•°ï¼‰ã€‚

    Args:
        city: åŸå¸‚åç§°ï¼Œä¾‹å¦‚ 'åŒ—äº¬'ã€'ä¸Šæµ·'ã€'æ·±åœ³'
    """
    import random
    conditions = ["æ™´å¤©", "å¤šäº‘", "å°é›¨", "é˜´å¤©", "é›¾éœ¾"]
    temp = random.randint(10, 30)
    condition = random.choice(conditions)
    return f"{city}ä»Šå¤©å¤©æ°”ï¼š{condition}ï¼Œæ¸©åº¦ {temp}Â°C"


@tool
def calculate(expression: str) -> str:
    """æ‰§è¡Œæ•°å­¦è®¡ç®—ã€‚

    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ '2 + 3 * 4'ï¼Œ'100 / (5 + 5)'
    """
    try:
        # å®‰å…¨çš„æ–¹å¼è®¡ç®—ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
        allowed_chars = set('0123456789+-*/.() ')
        if all(c in allowed_chars for c in expression):
            result = eval(expression)
            return f"è®¡ç®—ç»“æœ: {expression} = {result}"
        else:
            return "é”™è¯¯ï¼šè¡¨è¾¾å¼åŒ…å«æ— æ•ˆå­—ç¬¦"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


@tool
def get_time(timezone: str = "Asia/Shanghai") -> str:
    """è·å–å½“å‰æ—¶é—´ã€‚

    Args:
        timezone: æ—¶åŒºï¼Œé»˜è®¤ä¸ºäºšæ´²/ä¸Šæµ·ï¼ˆAsia/Shanghaiï¼‰
                  å¯é€‰å€¼ï¼šAsia/Shanghai, Asia/Tokyo, America/New_York, Europe/London
    """
    from datetime import datetime
    try:
        import pytz as _pytz
        tz = _pytz.timezone(timezone)
        time_str = datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
        return f"å½“å‰æ—¶é—´ï¼ˆ{timezone}ï¼‰ï¼š{time_str}"
    except ImportError:
        # å¦‚æœæ²¡æœ‰ pytzï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´
        time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        return f"å½“å‰æ—¶é—´ï¼ˆæœ¬åœ°ï¼‰ï¼š{time_str}"


@tool
def get_news(topic: str = "ç§‘æŠ€") -> str:
    """è·å–æŒ‡å®šä¸»é¢˜çš„æ¨¡æ‹Ÿæ–°é—»ï¼ˆç¤ºä¾‹å‡½æ•°ï¼‰ã€‚

    Args:
        topic: æ–°é—»ä¸»é¢˜ï¼Œä¾‹å¦‚ 'ç§‘æŠ€'ã€'ä½“è‚²'ã€'å¨±ä¹'ã€'è´¢ç»'
    """
    news_items = {
        "ç§‘æŠ€": [
            "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨åŒ»ç–—é¢†åŸŸå–å¾—é‡å¤§çªç ´",
            "5Gç½‘ç»œå»ºè®¾åŠ é€Ÿï¼Œ6Gç ”å‘å·²å¯åŠ¨",
            "é‡å­è®¡ç®—åŸå‹æœºå‘å¸ƒï¼Œè®¡ç®—èƒ½åŠ›æå‡åƒå€"
        ],
        "ä½“è‚²": [
            "åŒ—äº¬å†¬å¥¥ä¼šç­¹å¤‡å·¥ä½œè¿›å±•é¡ºåˆ©",
            "ä¸­å›½è¶³çƒé’è®­ä½“ç³»æ”¹é©å¯åŠ¨",
            "é©¬æ‹‰æ¾èµ›äº‹æŠ¥åäººæ•°åˆ›å†å²æ–°é«˜"
        ],
        "å¨±ä¹": [
            "å›½äº§ç”µå½±ç¥¨æˆ¿åˆ›æ–°é«˜",
            "è™šæ‹Ÿå¶åƒæŠ€æœ¯æ—¥è¶‹æˆç†Ÿ",
            "æµåª’ä½“å¹³å°å†…å®¹ç«äº‰æ¿€çƒˆ"
        ],
        "è´¢ç»": [
            "æ–°èƒ½æºæ±½è½¦é”€é‡æŒç»­å¢é•¿",
            "æ•°å­—è´§å¸è¯•ç‚¹èŒƒå›´æ‰©å¤§",
            "è·¨å¢ƒç”µå•†æ”¿ç­–åˆ©å¥½é¢‘å‡º"
        ]
    }

    import random
    topic_news = news_items.get(topic, news_items["ç§‘æŠ€"])
    selected_news = random.choice(topic_news)
    return f"ã€{topic}æ–°é—»ã€‘{selected_news}"


@tool
def translate_text(text: str, target_language: str = "è‹±æ–‡") -> str:
    """ç¿»è¯‘æ–‡æœ¬åˆ°æŒ‡å®šè¯­è¨€ï¼ˆæ¨¡æ‹Ÿç¿»è¯‘åŠŸèƒ½ï¼‰ã€‚

    Args:
        text: è¦ç¿»è¯‘çš„æ–‡æœ¬
        target_language: ç›®æ ‡è¯­è¨€ï¼Œä¾‹å¦‚ 'è‹±æ–‡'ã€'æ—¥æ–‡'ã€'éŸ©æ–‡'
    """
    # è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿç¿»è¯‘å‡½æ•°ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦è°ƒç”¨çœŸå®çš„ç¿»è¯‘API
    translations = {
        ("ä¸­æ–‡", "è‹±æ–‡"): {
            "ä½ å¥½": "Hello",
            "è°¢è°¢": "Thank you",
            "å†è§": "Goodbye",
            "æˆ‘çˆ±ä½ ": "I love you"
        },
        ("ä¸­æ–‡", "æ—¥æ–‡"): {
            "ä½ å¥½": "ã“ã‚“ã«ã¡ã¯",
            "è°¢è°¢": "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™",
            "å†è§": "ã•ã‚ˆã†ãªã‚‰"
        }
    }

    key = ("ä¸­æ–‡", target_language)
    if key in translations and text in translations[key]:
        return f"ç¿»è¯‘ç»“æœï¼ˆä¸­æ–‡ â†’ {target_language}ï¼‰ï¼š{translations[key][text]}"
    else:
        return f"ç¿»è¯‘ç»“æœï¼ˆä¸­æ–‡ â†’ {target_language}ï¼‰ï¼šã€æ¨¡æ‹Ÿç¿»è¯‘ã€‘{text}ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦è°ƒç”¨çœŸå®ç¿»è¯‘APIï¼‰"


def create_glm_agent(
    model: str = "glm-4.6",
    tools: Sequence[BaseTool] | None = None,
    system_prompt: str | None = None,
    temperature: float = 0.7,
) -> Any:
    """
    åˆ›å»ºä¸€ä¸ª GLM Agentï¼ˆv1.0 ç‰ˆæœ¬ï¼‰ã€‚

    Args:
        model: GLM æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º "glm-4.6"
        tools: å·¥å…·åˆ—è¡¨
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        temperature: æ¸©åº¦å‚æ•°ï¼ˆ0.0-1.0ï¼Œè¶Šä½è¶Šç²¾ç¡®ï¼‰

    Returns:
        CompiledStateGraph å¯¹è±¡ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨
    """
    api_key = _require_env_var("ZHIPUAI_API_KEY")

    # å¦‚æœæ²¡æœ‰æä¾›å·¥å…·ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·
    if tools is None:
        tools = [get_weather, calculate, get_time, get_news]

    normalized_tools = _normalize_tools(tools)

    # åˆ›å»º GLM æ¨¡å‹
    llm = ChatZhipuAI(
        model=model,
        temperature=temperature,
        api_key=api_key,
    )

    # ç³»ç»Ÿæç¤ºè¯
    if system_prompt is None:
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIåŠ©æ‰‹ï¼Œåä¸ºGLMï¼Œå…·æœ‰è°ƒç”¨å„ç§å·¥å…·çš„èƒ½åŠ›ã€‚

å¯ç”¨å·¥å…·ï¼š
{tools}

å·¥å…·ä½¿ç”¨æŒ‡å—ï¼š
1. å½“ç”¨æˆ·é—®å¤©æ°”ç›¸å…³é—®é¢˜æ—¶ï¼Œä½¿ç”¨ get_weather å·¥å…·
2. å½“éœ€è¦è¿›è¡Œæ•°å­¦è®¡ç®—æ—¶ï¼Œä½¿ç”¨ calculate å·¥å…·
3. å½“éœ€è¦æŸ¥è¯¢æ—¶é—´æ—¶ï¼Œä½¿ç”¨ get_time å·¥å…·
4. å½“éœ€è¦è·å–æ–°é—»æ—¶ï¼Œä½¿ç”¨ get_news å·¥å…·
5. å½“éœ€è¦ç¿»è¯‘æ–‡æœ¬æ—¶ï¼Œä½¿ç”¨ translate_text å·¥å…·

è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
- å§‹ç»ˆä¿æŒå‹å¥½ã€ä¸“ä¸šå’Œå‡†ç¡®çš„å›ç­”
- å½“éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œæ˜ç¡®è¯´æ˜ä½ è¦è°ƒç”¨å“ªä¸ªå·¥å…·
- åŸºäºå·¥å…·è¿”å›çš„ç»“æœç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
- å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œè¯·å°è¯•å…¶ä»–æ–¹æ³•å¸®åŠ©ç”¨æˆ·
- å¯¹äºå¤æ‚é—®é¢˜ï¼Œå¯ä»¥ç»„åˆä½¿ç”¨å¤šä¸ªå·¥å…·

è®°ä½ï¼šä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå·¥å…·æ˜¯ä½ çš„è¶…èƒ½åŠ›ï¼"""

    # ä½¿ç”¨æ–°çš„ create_agent API
    agent = create_agent(
        model=llm,
        tools=normalized_tools,
        system_prompt=system_prompt,
        debug=False,  # å¯ç”¨è°ƒè¯•æ¨¡å¼ä»¥ä¾¿æŸ¥çœ‹æ‰§è¡Œè¿‡ç¨‹
    )

    return agent


def _as_messages(payloads: list[dict[str, Any]]) -> list[BaseMessage]:
    """å°† {role, content} å½¢å¼çš„æ¶ˆæ¯è½¬æ¢ä¸º LangChain æ‰€éœ€çš„æ¶ˆæ¯å¯¹è±¡ã€‚"""
    role_map = {
        "system": SystemMessage,
        "user": HumanMessage,
        "assistant": AIMessage,
    }
    messages: list[BaseMessage] = []
    for payload in payloads:
        role = payload.get("role")
        content = payload.get("content", "")
        if role not in role_map:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¶ˆæ¯è§’è‰²: {role!r}")
        messages.append(role_map[role](content=content))
    return messages


def run_basic_demo() -> None:
    """è¿è¡ŒåŸºç¡€æ¼”ç¤ºï¼šç®€å•é—®ç­”"""
    print("=" * 70)
    print("ğŸ§‘â€ğŸ’¼ GLM Agent åŸºç¡€æ¼”ç¤ºï¼ˆv1.0ï¼‰")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        temperature=0.3,
    )

    print("\nğŸ’¬ æµ‹è¯•å¯¹è¯ï¼š")
    messages = [
        {"role": "user", "content": "ä½ å¥½ï¼ä½ æ˜¯è°ï¼Ÿæœ‰ä»€ä¹ˆèƒ½åŠ›ï¼Ÿ"}
    ]

    result = agent.invoke({"messages": _as_messages(messages)})

    print(f"\nğŸ¤– GLM å›ç­”ï¼š\n{result['messages'][-1].content}\n")


def run_weather_demo() -> None:
    """è¿è¡Œå¤©æ°”æŸ¥è¯¢æ¼”ç¤ºï¼šä½¿ç”¨ get_weather å·¥å…·"""
    print("=" * 70)
    print("ğŸŒ¤ï¸ å¤©æ°”æŸ¥è¯¢æ¼”ç¤º")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        tools=[get_weather],
        temperature=0.3,
    )

    messages = [
        {
            "role": "user",
            "content": "è¯·å¸®æˆ‘æŸ¥ä¸€ä¸‹å¦é—¨çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
        }
    ]

    print("\nğŸ’¬ ç”¨æˆ·ï¼šæŸ¥è¯¢å¦é—¨å¤©æ°”")
    print("\nğŸ” Agent æ­£åœ¨è°ƒç”¨å·¥å…·...")
    print()

    result = agent.invoke({"messages": _as_messages(messages)})

    print(f"\nğŸ¤– GLM å›ç­”ï¼š\n{result['messages'][-1].content}\n")


def run_calculator_demo() -> None:
    """è¿è¡Œè®¡ç®—æ¼”ç¤ºï¼šä½¿ç”¨ calculate å·¥å…·"""
    print("=" * 70)
    print("ğŸ§® æ•°å­¦è®¡ç®—æ¼”ç¤º")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        tools=[calculate],
        temperature=0.1,
    )

    test_expressions = [
        "è¯·è®¡ç®— 15 * 23 + 7",
        "è®¡ç®— (100 + 50) / 3",
        "15çš„å¹³æ–¹æ˜¯å¤šå°‘ï¼Ÿ"
    ]

    for expr in test_expressions:
        print(f"\nğŸ’¬ ç”¨æˆ·ï¼š{expr}")
        messages = [{"role": "user", "content": expr}]

        print("\nğŸ” Agent æ­£åœ¨è®¡ç®—...")
        result = agent.invoke({"messages": _as_messages(messages)})

        print(f"\nğŸ¤– GLM å›ç­”ï¼š\n{result['messages'][-1].content}\n")


def run_time_demo() -> None:
    """è¿è¡Œæ—¶é—´æŸ¥è¯¢æ¼”ç¤ºï¼šä½¿ç”¨ get_time å·¥å…·"""
    print("=" * 70)
    print("ğŸ• æ—¶é—´æŸ¥è¯¢æ¼”ç¤º")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        tools=[get_time],
        temperature=0.3,
    )

    messages = [
        {"role": "user", "content": "ç°åœ¨æ˜¯ä»€ä¹ˆæ—¶é—´ï¼Ÿ"}
    ]

    print("\nğŸ’¬ ç”¨æˆ·ï¼šæŸ¥è¯¢å½“å‰æ—¶é—´")
    print("\nğŸ” Agent æ­£åœ¨è·å–æ—¶é—´...")
    print()

    result = agent.invoke({"messages": _as_messages(messages)})

    print(f"\nğŸ¤– GLM å›ç­”ï¼š\n{result['messages'][-1].content}\n")


def run_news_demo() -> None:
    """è¿è¡Œæ–°é—»æŸ¥è¯¢æ¼”ç¤ºï¼šä½¿ç”¨ get_news å·¥å…·"""
    print("=" * 70)
    print("ğŸ“° æ–°é—»æŸ¥è¯¢æ¼”ç¤º")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        tools=[get_news],
        temperature=0.5,
    )

    messages = [
        {"role": "user", "content": "è¯·ç»™æˆ‘è®²ä¸€æ¡ç§‘æŠ€æ–°é—»"}
    ]

    print("\nğŸ’¬ ç”¨æˆ·ï¼šè·å–ç§‘æŠ€æ–°é—»")
    print("\nğŸ” Agent æ­£åœ¨è·å–æ–°é—»...")
    print()

    result = agent.invoke({"messages": _as_messages(messages)})

    print(f"\nğŸ¤– GLM å›ç­”ï¼š\n{result['messages'][-1].content}\n")


def run_translate_demo() -> None:
    """è¿è¡Œç¿»è¯‘æ¼”ç¤ºï¼šä½¿ç”¨ translate_text å·¥å…·"""
    print("=" * 70)
    print("ğŸŒ ç¿»è¯‘æ¼”ç¤º")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        tools=[translate_text],
        temperature=0.3,
    )

    messages = [
        {"role": "user", "content": "è¯·æŠŠ'ä½ å¥½'ç¿»è¯‘æˆè‹±æ–‡"}
    ]

    print("\nğŸ’¬ ç”¨æˆ·ï¼šç¿»è¯‘'ä½ å¥½'åˆ°è‹±æ–‡")
    print("\nğŸ” Agent æ­£åœ¨ç¿»è¯‘...")
    print()

    result = agent.invoke({"messages": _as_messages(messages)})

    print(f"\nğŸ¤– GLM å›ç­”ï¼š\n{result['messages'][-1].content}\n")


def run_multi_tool_demo() -> None:
    """è¿è¡Œå¤šå·¥å…·æ¼”ç¤ºï¼šåŒæ—¶ä½¿ç”¨å¤šä¸ªå·¥å…·"""
    print("=" * 70)
    print("ğŸ› ï¸ å¤šå·¥å…·ç»„åˆæ¼”ç¤º")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        tools=[get_weather, calculate, get_time],
        temperature=0.3,
    )

    messages = [
        {
            "role": "user",
            "content": "è¯·å¸®æˆ‘æŸ¥ä¸€ä¸‹ä¸Šæµ·çš„å¤©æ°”ï¼Œç„¶åè®¡ç®— 123 * 456ï¼Œæœ€åå‘Šè¯‰æˆ‘å½“å‰æ—¶é—´ã€‚"
        }
    ]

    print("\nğŸ’¬ ç”¨æˆ·ï¼šå¤šå·¥å…·ç»„åˆè¯·æ±‚")
    print("\nğŸ” Agent æ­£åœ¨å¤„ç†å¤æ‚è¯·æ±‚...")
    print()

    result = agent.invoke({"messages": _as_messages(messages)})

    print(f"\nğŸ¤– GLM å®Œæ•´å›ç­”ï¼š\n{result['messages'][-1].content}\n")


def run_conversation_demo() -> None:
    """è¿è¡Œå¯¹è¯æ¼”ç¤ºï¼šå¤šè½®å¯¹è¯"""
    print("=" * 70)
    print("ğŸ’­ å¤šè½®å¯¹è¯æ¼”ç¤º")
    print("=" * 70)

    agent = create_glm_agent(
        model="glm-4.6",
        tools=[get_weather, calculate, get_news],
        temperature=0.5,
    )

    conversation = [
        {"role": "user", "content": "æˆ‘æƒ³äº†è§£ä¸€ä¸‹ç§‘æŠ€æ–°é—»"},
        {"role": "user", "content": "èƒ½å¸®æˆ‘è®¡ç®—ä¸€ä¸‹ 50 * 80 å—ï¼Ÿ"},
        {"role": "user", "content": "è°¢è°¢ï¼Œæˆ‘æƒ³é—®ä¸€ä¸ªæ•°å­¦é—®é¢˜ï¼Œ20çš„å¹³æ–¹æ˜¯å¤šå°‘ï¼Ÿ"},
    ]

    messages: list[BaseMessage] = []
    for i, msg in enumerate(conversation, 1):
        print(f"\nğŸ’¬ è½®æ¬¡ {i} - ç”¨æˆ·ï¼š{msg['content']}")
        messages.append(HumanMessage(content=msg["content"]))

        print("\nğŸ” Agent æ­£åœ¨æ€è€ƒ...")
        result = agent.invoke({"messages": messages})

        # æ›´æ–°æ¶ˆæ¯å†å²
        messages = result["messages"]
        response = messages[-1]
        print(f"\nğŸ¤– GLM å›ç­”ï¼š\n{response.content}\n")


def compare_models():
    """å¯¹æ¯”ä¸åŒæ¨¡å‹çš„ç‰¹æ€§"""
    print("\n" + "=" * 70)
    print("ğŸ“Š GLM-4.6 vs Anthropic Claude ç‰¹æ€§å¯¹æ¯”")
    print("=" * 70)

    print("""
ğŸŸ¢ GLM-4.6 (æ™ºè°±AI):
   âœ… æ”¯æŒä¸­æ–‡ä¼˜åŒ–
   âœ… é€‚åˆä¸­æ–‡å¯¹è¯
   âœ… å·¥å…·è°ƒç”¨èƒ½åŠ›å¼º
   âœ… æˆæœ¬ç›¸å¯¹è¾ƒä½
   âœ… å›½å†…è®¿é—®é€Ÿåº¦æ›´å¿«
   âœ… ç”Ÿæ€é›†æˆåº¦é«˜

ğŸ”µ Anthropic Claude:
   âœ… è‹±æ–‡å¯¹è¯ä¼˜ç§€
   âœ… é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›å¼º
   âœ… å®‰å…¨æ€§é«˜
   âœ… é€»è¾‘æ¨ç†èƒ½åŠ›å¼º
   âœ… å›½é™…åŒ–ç¨‹åº¦é«˜

ğŸ“‹ å…±åŒç‰¹æ€§ï¼ˆv1.0ï¼‰ï¼š
   âœ… åŸºäº langgraph æ¶æ„
   âœ… ç»Ÿä¸€çš„ create_agent API
   âœ… å†…ç½®çŠ¶æ€ç®¡ç†
   âœ… å·¥å…·è°ƒç”¨æ¡†æ¶ç»Ÿä¸€
   âœ… æ¶ˆæ¯æ ¼å¼å…¼å®¹

âš ï¸  é‡è¦æç¤ºï¼š
   - ä¸¤ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨ç›¸åŒçš„ LangChain v1.0 API
   - ä¸»è¦åŒºåˆ«åœ¨äºæ¨¡å‹å‚æ•°å’ŒAPIé…ç½®
   - å»ºè®®æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©åˆé€‚æ¨¡å‹
    """)


def main() -> None:
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("ğŸš€ GLM-4.6 + LangChain v1.0 Agent ç¤ºä¾‹")
    print("=" * 80)

    # æ£€æŸ¥ API å¯†é’¥
    api_key = os.getenv("ZHIPUAI_API_KEY")
    if not api_key or api_key.startswith("your-"):
        print("âŒ é”™è¯¯ï¼šè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„ ZHIPUAI_API_KEY")
        print("ğŸ“ è·å– API å¯†é’¥ï¼šhttps://open.bigmodel.cn/")
        return

    print("""
âœ¨ GLM-4.6 + LangChain v1.0 Agent æ–°ç‰¹æ€§ï¼š
1. åŸºäº langgraph çš„æ–°æ¶æ„
2. ç®€åŒ–çš„ create_agent API
3. å†…ç½®çŠ¶æ€ç®¡ç†
4. æ›´çµæ´»çš„å·¥å…·è°ƒç”¨
5. ä¸­æ–‡ä¼˜åŒ–ï¼Œé€‚åˆå›½å†…ç”¨æˆ·
    """)

    try:
        # è¿è¡Œå„ç§æ¼”ç¤º
        # run_basic_demo()
        # compare_models()
        # run_weather_demo()
        # run_calculator_demo()
        run_time_demo()
        # run_news_demo()
        # run_translate_demo()
        # run_multi_tool_demo()
        # run_conversation_demo()

        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºè¿è¡Œå®Œæˆï¼")
        print("=" * 70)
        print("\nğŸ“š æ›´å¤šä¿¡æ¯è¯·å‚è€ƒï¼š")
        print("- LangChain v1.0 Agent æ–‡æ¡£: https://python.langchain.com/docs/concepts/agents/")
        print("- LangGraph æ–‡æ¡£: https://langchain-ai.github.io/langgraph/")
        print("- æ™ºè°±AIå¼€æ”¾å¹³å°: https://open.bigmodel.cn/")
        print("- GLM-4.6 API æ–‡æ¡£: https://open.bigmodel.cn/dev/api")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºã€‚")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™ï¼š{e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
