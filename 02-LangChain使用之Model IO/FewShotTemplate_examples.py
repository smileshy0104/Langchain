#!/usr/bin/env python3
"""
GLM-4.6 + LangChain å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤º FewShotPromptTemplate å’Œ FewShotChatMessagePromptTemplate çš„ä½¿ç”¨æ–¹æ³•
"""

import os
import dotenv
from typing import List, Dict, Any
from langchain_community.chat_models import ChatZhipuAI
from langchain_core.prompts import (
    FewShotPromptTemplate,
    FewShotChatMessagePromptTemplate,
    PromptTemplate,
    ChatPromptTemplate
)
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# æ£€æŸ¥APIå¯†é’¥
api_key = os.getenv("ZHIPUAI_API_KEY")
if not api_key or api_key == "your-zhipu-api-key-here":
    print("âŒ é”™è¯¯ï¼šè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„ZHIPUAI_API_KEY")
    exit(1)

# åˆå§‹åŒ–GLMæ¨¡å‹
def get_glm_model(temperature: float = 0.7):
    """è·å–GLMæ¨¡å‹å®ä¾‹"""
    return ChatZhipuAI(
        model="glm-4.6",
        temperature=temperature,
        api_key=api_key
    )

def basic_few_shot_prompt():
    """åŸºç¡€ FewShotPromptTemplate ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸ“ åŸºç¡€ FewShotPromptTemplate ç¤ºä¾‹")
    print("=" * 60)

    model = get_glm_model()

    # 1. åˆ›å»ºç¤ºä¾‹
    examples = [
        {
            "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "answer": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚"
        },
        {
            "question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            "answer": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶æ”¹è¿›æ€§èƒ½ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚"
        },
        {
            "question": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
            "answer": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ï¼Œå¤„ç†å¤æ‚çš„æ¨¡å¼ã€‚"
        }
    ]

    # 2. åˆ›å»ºç¤ºä¾‹æç¤ºæ¨¡æ¿
    example_prompt = PromptTemplate(
        input_variables=["question", "answer"],
        template="é—®é¢˜ï¼š{question}\nå›ç­”ï¼š{answer}"
    )

    # 3. åˆ›å»ºå°‘æ ·æœ¬æç¤ºæ¨¡æ¿
    few_shot_prompt = FewShotPromptTemplate(
        examples=examples,
        example_prompt=example_prompt,
        prefix="è¯·æ ¹æ®ä»¥ä¸‹ç¤ºä¾‹å›ç­”é—®é¢˜ï¼Œä¿æŒå›ç­”çš„ç®€æ´æ€§å’Œå‡†ç¡®æ€§ï¼š",
        suffix="é—®é¢˜ï¼š{input}\nå›ç­”ï¼š",
        input_variables=["input"],
        example_separator="\n\n"
    )

    # 4. æ ¼å¼åŒ–æç¤ºè¯
    new_question = "ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ"
    formatted_prompt = few_shot_prompt.format(input=new_question)

    print("ğŸ“‹ ç”Ÿæˆçš„å°‘æ ·æœ¬æç¤ºè¯ï¼š")
    print(formatted_prompt)
    print("-" * 40)

    # 5. è°ƒç”¨æ¨¡å‹
    response = model.invoke(formatted_prompt)
    print(f"ğŸ¤– GLM-4.6 å›ç­”ï¼š")
    print(f"{response.content}\n")

def translation_few_shot():
    """ç¿»è¯‘ä»»åŠ¡å°‘æ ·æœ¬ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸŒ ç¿»è¯‘ä»»åŠ¡ FewShotPromptTemplate ç¤ºä¾‹")
    print("=" * 60)

    model = get_glm_model()

    # ç¿»è¯‘ç¤ºä¾‹
    translation_examples = [
        {
            "chinese": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚",
            "english": "The weather is nice today."
        },
        {
            "chinese": "æˆ‘å–œæ¬¢å­¦ä¹ ç¼–ç¨‹ã€‚",
            "english": "I like learning programming."
        },
        {
            "chinese": "è¿™æœ¬ä¹¦å¾ˆæœ‰è¶£ã€‚",
            "english": "This book is very interesting."
        }
    ]

    # ç¿»è¯‘æç¤ºæ¨¡æ¿
    translation_prompt = PromptTemplate(
        input_variables=["chinese", "english"],
        template="ä¸­æ–‡ï¼š{chinese}\nè‹±æ–‡ï¼š{english}"
    )

    # åˆ›å»ºå°‘æ ·æœ¬æ¨¡æ¿
    few_shot_translation = FewShotPromptTemplate(
        examples=translation_examples,
        example_prompt=translation_prompt,
        prefix="è¯·æ ¹æ®ä»¥ä¸‹ç¤ºä¾‹å°†ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼š",
        suffix="ä¸­æ–‡ï¼š{input}\nè‹±æ–‡ï¼š",
        input_variables=["input"]
    )

    # æµ‹è¯•ç¿»è¯‘
    test_sentence = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚"
    formatted_prompt = few_shot_translation.format(input=test_sentence)

    print("ğŸ“‹ ç¿»è¯‘ä»»åŠ¡æç¤ºè¯ï¼š")
    print(formatted_prompt)
    print("-" * 40)

    response = model.invoke(formatted_prompt)
    print(f"ğŸ¤– GLM-4.6 ç¿»è¯‘ç»“æœï¼š")
    print(f"{response.content}\n")

def code_generation_few_shot():
    """ä»£ç ç”Ÿæˆå°‘æ ·æœ¬ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸ’» ä»£ç ç”Ÿæˆ FewShotPromptTemplate ç¤ºä¾‹")
    print("=" * 60)

    model = get_glm_model(temperature=0.3)  # ä»£ç ç”Ÿæˆä½¿ç”¨è¾ƒä½æ¸©åº¦

    # ä»£ç ç¤ºä¾‹
    code_examples = [
        {
            "description": "è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„å’Œ",
            "code": "def add(a, b):\n    return a + b"
        },
        {
            "description": "è®¡ç®—æ•°å­—çš„å¹³æ–¹",
            "code": "def square(x):\n    return x ** 2"
        },
        {
            "description": "åˆ¤æ–­æ•°å­—æ˜¯å¦ä¸ºå¶æ•°",
            "code": "def is_even(n):\n    return n % 2 == 0"
        }
    ]

    # ä»£ç æç¤ºæ¨¡æ¿
    code_prompt = PromptTemplate(
        input_variables=["description", "code"],
        template="åŠŸèƒ½æè¿°ï¼š{description}\nä»£ç å®ç°ï¼š\n{code}"
    )

    # åˆ›å»ºå°‘æ ·æœ¬æ¨¡æ¿
    few_shot_code = FewShotPromptTemplate(
        examples=code_examples,
        example_prompt=code_prompt,
        prefix="è¯·æ ¹æ®ä»¥ä¸‹ç¤ºä¾‹ç¼–å†™Pythonå‡½æ•°ï¼š",
        suffix="åŠŸèƒ½æè¿°ï¼š{input}\nä»£ç å®ç°ï¼š",
        input_variables=["input"]
    )

    # æµ‹è¯•ä»£ç ç”Ÿæˆ
    function_description = "è®¡ç®—åˆ—è¡¨çš„å¹³å‡å€¼"
    formatted_prompt = few_shot_code.format(input=function_description)

    print("ğŸ“‹ ä»£ç ç”Ÿæˆæç¤ºè¯ï¼š")
    print(formatted_prompt)
    print("-" * 40)

    response = model.invoke(formatted_prompt)
    print(f"ğŸ¤– GLM-4.6 ç”Ÿæˆçš„ä»£ç ï¼š")
    print(f"{response.content}\n")

def basic_few_shot_chat():
    """åŸºç¡€ FewShotChatMessagePromptTemplate ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸ’¬ åŸºç¡€ FewShotChatMessagePromptTemplate ç¤ºä¾‹")
    print("=" * 60)

    model = get_glm_model()

    # 1. åˆ›å»ºå¯¹è¯ç¤ºä¾‹
    chat_examples = [
        {
            "input": "è§£é‡Šä»€ä¹ˆæ˜¯é€’å½’",
            "output": "é€’å½’æ˜¯ä¸€ç§ç¼–ç¨‹æŠ€æœ¯ï¼Œå‡½æ•°ç›´æ¥æˆ–é—´æ¥è°ƒç”¨è‡ªèº«æ¥è§£å†³é—®é¢˜ã€‚å°±åƒä¿„ç½—æ–¯å¥—å¨ƒï¼Œæ¯ä¸ªå¨ƒå¨ƒé‡Œé¢éƒ½æœ‰ä¸€ä¸ªæ›´å°çš„å¨ƒå¨ƒã€‚"
        },
        {
            "input": "è§£é‡Šä»€ä¹ˆæ˜¯é¢å‘å¯¹è±¡ç¼–ç¨‹",
            "output": "é¢å‘å¯¹è±¡ç¼–ç¨‹æ˜¯ä¸€ç§ç¼–ç¨‹èŒƒå¼ï¼Œå®ƒå°†æ•°æ®å’Œæ“ä½œæ•°æ®çš„æ–¹æ³•ç»„ç»‡åœ¨å¯¹è±¡ä¸­ã€‚å°±åƒç°å®ä¸–ç•Œä¸­çš„æ±½è½¦ï¼Œå®ƒæœ‰å±æ€§ï¼ˆé¢œè‰²ã€å“ç‰Œï¼‰å’Œè¡Œä¸ºï¼ˆåŠ é€Ÿã€åˆ¹è½¦ï¼‰ã€‚"
        },
        {
            "input": "è§£é‡Šä»€ä¹ˆæ˜¯API",
            "output": "APIæ˜¯åº”ç”¨ç¨‹åºæ¥å£ï¼Œå®ƒå®šä¹‰äº†ä¸åŒè½¯ä»¶ç»„ä»¶ä¹‹é—´å¦‚ä½•äº¤äº’ã€‚å°±åƒé¤å…çš„æœåŠ¡å‘˜ï¼Œä»–è´Ÿè´£å°†ä½ çš„è®¢å•ä¼ è¾¾ç»™å¨æˆ¿ï¼Œå¹¶å°†é£Ÿç‰©å¸¦ç»™ä½ ã€‚"
        }
    ]

    # 2. åˆ›å»ºç¤ºä¾‹æç¤ºæ¨¡æ¿
    chat_example_prompt = ChatPromptTemplate.from_messages([
        ("human", "{input}"),
        ("ai", "{output}")
    ])

    # 3. åˆ›å»ºå°‘æ ·æœ¬èŠå¤©æç¤ºæ¨¡æ¿
    few_shot_chat_prompt = FewShotChatMessagePromptTemplate(
        examples=chat_examples,
        example_prompt=chat_example_prompt
    )

    # 4. åˆ›å»ºæœ€ç»ˆæç¤ºæ¨¡æ¿
    final_prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹è€å¸ˆï¼Œæ“…é•¿ç”¨ç”ŸåŠ¨çš„æ¯”å–»æ¥è§£é‡Šå¤æ‚çš„ç¼–ç¨‹æ¦‚å¿µã€‚è¯·ä¿æŒå›ç­”ç®€æ´æ˜äº†ã€‚"),
        few_shot_chat_prompt,
        ("human", "{input}")
    ])

    # 5. æ ¼å¼åŒ–æ¶ˆæ¯
    messages = final_prompt.format_messages(input="è§£é‡Šä»€ä¹ˆæ˜¯æ•°æ®åº“ç´¢å¼•")

    print("ğŸ“‹ ç”Ÿæˆçš„èŠå¤©æ¶ˆæ¯ï¼š")
    for i, msg in enumerate(messages, 1):
        print(f"  {i}. [{msg.__class__.__name__}]: {msg.content}")
        if hasattr(msg, 'additional_kwargs') and msg.additional_kwargs:
            print(f"     é¢å¤–ä¿¡æ¯: {msg.additional_kwargs}")

    print("-" * 40)

    # 6. è°ƒç”¨æ¨¡å‹
    response = model.invoke(messages)
    print(f"ğŸ¤– GLM-4.6 å›ç­”ï¼š")
    print(f"{response.content}\n")

def sentiment_analysis_chat():
    """æƒ…æ„Ÿåˆ†æèŠå¤©æ¨¡æ¿ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸ˜Š æƒ…æ„Ÿåˆ†æ FewShotChatMessagePromptTemplate ç¤ºä¾‹")
    print("=" * 60)

    model = get_glm_model(temperature=0.2)  # æƒ…æ„Ÿåˆ†æä½¿ç”¨è¾ƒä½æ¸©åº¦

    # æƒ…æ„Ÿåˆ†æç¤ºä¾‹
    sentiment_examples = [
        {
            "text": "ä»Šå¤©çœŸæ˜¯å¤ªæ£’äº†ï¼æˆ‘å®Œæˆäº†æ‰€æœ‰çš„ä»»åŠ¡ã€‚",
            "sentiment": "æ­£é¢"
        },
        {
            "text": "è¿™ä¸ªäº§å“è´¨é‡å¾ˆå·®ï¼Œå®Œå…¨ä¸å€¼å¾—è´­ä¹°ã€‚",
            "sentiment": "è´Ÿé¢"
        },
        {
            "text": "è¿™éƒ¨ç”µå½±è¿˜å¯ä»¥ï¼Œæ²¡æœ‰ç‰¹åˆ«çš„æƒŠå–œã€‚",
            "sentiment": "ä¸­æ€§"
        }
    ]

    # æƒ…æ„Ÿåˆ†ææç¤ºæ¨¡æ¿
    sentiment_example_prompt = ChatPromptTemplate.from_messages([
        ("human", "è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿï¼š{text}"),
        ("ai", "æƒ…æ„Ÿåˆ†æç»“æœï¼š{sentiment}")
    ])

    # åˆ›å»ºå°‘æ ·æœ¬æ¨¡æ¿
    few_shot_sentiment = FewShotChatMessagePromptTemplate(
        examples=sentiment_examples,
        example_prompt=sentiment_example_prompt
    )

    # æœ€ç»ˆæç¤ºæ¨¡æ¿
    final_sentiment_prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªæƒ…æ„Ÿåˆ†æä¸“å®¶ï¼Œè¯·å‡†ç¡®åˆ¤æ–­æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼šæ­£é¢ã€è´Ÿé¢æˆ–ä¸­æ€§ã€‚"),
        few_shot_sentiment,
        ("human", "è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿï¼š{input}")
    ])

    # åˆ›å»ºå¤„ç†é“¾
    chain = final_sentiment_prompt | model | StrOutputParser()

    # æµ‹è¯•æƒ…æ„Ÿåˆ†æ
    test_texts = [
        "è™½ç„¶é‡åˆ°äº†ä¸€äº›å›°éš¾ï¼Œä½†æœ€ç»ˆè¿˜æ˜¯è§£å†³äº†é—®é¢˜ã€‚",
        "æœåŠ¡æ€åº¦æ¶åŠ£ï¼Œå®Œå…¨ä¸ä¼šå†æ¥è¿™é‡Œäº†ã€‚",
        "è¿™æ¬¡çš„äº§å“ä½“éªŒä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„æ„Ÿè§‰ã€‚"
    ]

    for text in test_texts:
        print(f"ğŸ“ åˆ†ææ–‡æœ¬ï¼š{text}")
        result = chain.invoke({"input": text})
        print(f"ğŸ¯ åˆ†æç»“æœï¼š{result}\n")

def dynamic_few_shot():
    """åŠ¨æ€é€‰æ‹©ç¤ºä¾‹çš„å°‘æ ·æœ¬æ¨¡æ¿"""
    print("=" * 60)
    print("ğŸ”„ åŠ¨æ€é€‰æ‹©ç¤ºä¾‹çš„ FewShotPromptTemplate")
    print("=" * 60)

    model = get_glm_model()

    # æ•°å­¦é¢˜ç¤ºä¾‹åº“
    math_examples = [
        {
            "difficulty": "easy",
            "question": "2 + 2 = ?",
            "answer": "4"
        },
        {
            "difficulty": "easy",
            "question": "5 Ã— 3 = ?",
            "answer": "15"
        },
        {
            "difficulty": "medium",
            "question": "12 Ã· 4 = ?",
            "answer": "3"
        },
        {
            "difficulty": "medium",
            "question": "7Â² = ?",
            "answer": "49"
        },
        {
            "difficulty": "hard",
            "question": "âˆš144 = ?",
            "answer": "12"
        }
    ]

    def select_examples_by_difficulty(examples: List[Dict], difficulty: str, max_examples: int = 2) -> List[Dict]:
        """æ ¹æ®éš¾åº¦é€‰æ‹©ç¤ºä¾‹"""
        filtered = [ex for ex in examples if ex["difficulty"] == difficulty]
        return filtered[:max_examples]

    # åŸºç¡€æç¤ºæ¨¡æ¿
    math_prompt = PromptTemplate(
        input_variables=["question", "answer"],
        template="é¢˜ç›®ï¼š{question}\nç­”æ¡ˆï¼š{answer}"
    )

    def create_dynamic_few_shot(difficulty: str):
        """åˆ›å»ºåŠ¨æ€å°‘æ ·æœ¬æ¨¡æ¿"""
        selected_examples = select_examples_by_difficulty(math_examples, difficulty)

        return FewShotPromptTemplate(
            examples=selected_examples,
            example_prompt=math_prompt,
            prefix="è¯·æ ¹æ®ä»¥ä¸‹ç¤ºä¾‹è®¡ç®—æ•°å­¦é¢˜ï¼š",
            suffix="é¢˜ç›®ï¼š{input}\nç­”æ¡ˆï¼š",
            input_variables=["input"]
        )

    # æµ‹è¯•ä¸åŒéš¾åº¦
    difficulties = ["easy", "medium", "hard"]
    test_questions = {
        "easy": "3 + 6 = ?",
        "medium": "8 Ã— 7 = ?",
        "hard": "2Â³ = ?"
    }

    for difficulty in difficulties:
        print(f"ğŸ¯ éš¾åº¦çº§åˆ«ï¼š{difficulty.upper()}")
        dynamic_prompt = create_dynamic_few_shot(difficulty)

        formatted_prompt = dynamic_prompt.format(input=test_questions[difficulty])
        print(f"ğŸ“‹ ç”Ÿæˆçš„æç¤ºè¯ï¼š\n{formatted_prompt}")

        response = model.invoke(formatted_prompt)
        print(f"ğŸ¤– GLM-4.6 å›ç­”ï¼š{response.content}")
        print("-" * 40)

def few_shot_chain_example():
    """å°‘æ ·æœ¬æ¨¡æ¿é“¾å¼è°ƒç”¨ç¤ºä¾‹"""
    print("=" * 60)
    print("â›“ï¸ å°‘æ ·æœ¬æ¨¡æ¿é“¾å¼è°ƒç”¨ç¤ºä¾‹")
    print("=" * 60)

    model = get_glm_model()

    # 1. åˆ›å»ºåˆ†ç±»ç¤ºä¾‹
    classification_examples = [
        {
            "text": "è‹¹æœã€é¦™è•‰ã€æ©™å­",
            "category": "æ°´æœ"
        },
        {
            "text": "æ±½è½¦ã€ç«è½¦ã€é£æœº",
            "category": "äº¤é€šå·¥å…·"
        },
        {
            "text": "ç‹—ã€çŒ«ã€å…”å­",
            "category": "åŠ¨ç‰©"
        }
    ]

    # 2. åˆ†ç±»æç¤ºæ¨¡æ¿
    classification_prompt = PromptTemplate(
        input_variables=["text", "category"],
        template="æ–‡æœ¬ï¼š{text}\nåˆ†ç±»ï¼š{category}"
    )

    # 3. åˆ›å»ºå°‘æ ·æœ¬æ¨¡æ¿
    few_shot_classification = FewShotPromptTemplate(
        examples=classification_examples,
        example_prompt=classification_prompt,
        prefix="è¯·å°†ä»¥ä¸‹æ–‡æœ¬åˆ†ç±»åˆ°åˆé€‚çš„ç±»åˆ«ï¼š",
        suffix="æ–‡æœ¬ï¼š{input}\nåˆ†ç±»ï¼š",
        input_variables=["input"]
    )

    # 4. åˆ›å»ºå¤„ç†é“¾
    chain = few_shot_classification | model | StrOutputParser()

    # 5. æ‰¹é‡æµ‹è¯•
    test_items = [
        "è¥¿çº¢æŸ¿ã€é»„ç“œã€ç™½èœ",
        "è‡ªè¡Œè½¦ã€åœ°é“ã€å…¬äº¤è½¦",
        "ç‹®å­ã€è€è™ã€å¤§è±¡"
    ]

    print("ğŸ”„ æ‰¹é‡åˆ†ç±»æµ‹è¯•ï¼š")
    for item in test_items:
        result = chain.invoke({"input": item})
        print(f"ğŸ“ {item} â†’ {result}")

    print()

def best_practices():
    """å°‘æ ·æœ¬æ¨¡æ¿æœ€ä½³å®è·µ"""
    print("=" * 60)
    print("ğŸ’¡ å°‘æ ·æœ¬æ¨¡æ¿æœ€ä½³å®è·µ")
    print("=" * 60)

    print("""
âœ… æ¨èåšæ³•:
1. é€‰æ‹©é«˜è´¨é‡ã€ä»£è¡¨æ€§çš„ç¤ºä¾‹
2. ç¤ºä¾‹æ•°é‡é€šå¸¸åœ¨3-10ä¸ªä¹‹é—´
3. ä¿æŒç¤ºä¾‹æ ¼å¼çš„ä¸€è‡´æ€§
4. æ ¹æ®ä»»åŠ¡éš¾åº¦è°ƒæ•´ç¤ºä¾‹å¤æ‚åº¦
5. ä½¿ç”¨åŠ¨æ€é€‰æ‹©æ¥ä¼˜åŒ–ç¤ºä¾‹ç›¸å…³æ€§

âŒ é¿å…åšæ³•:
1. ä½¿ç”¨è¿‡å¤šæˆ–è¿‡å°‘çš„ç¤ºä¾‹
2. é€‰æ‹©ä½è´¨é‡æˆ–æœ‰åè§çš„ç¤ºä¾‹
3. ç¤ºä¾‹ä¹‹é—´æ ¼å¼ä¸ä¸€è‡´
4. å¿½ç•¥ç¤ºä¾‹çš„ä»£è¡¨æ€§

ğŸ¯ ç¤ºä¾‹é€‰æ‹©ç­–ç•¥:
- ç®€å•ä»»åŠ¡ï¼š3-5ä¸ªç¤ºä¾‹
- å¤æ‚ä»»åŠ¡ï¼š5-10ä¸ªç¤ºä¾‹
- æ ¹æ®è¾“å…¥ç‰¹å¾åŠ¨æ€é€‰æ‹©
- è¦†ç›–ä¸åŒçš„è¾“å…¥æ¨¡å¼

ğŸ“Š æ€§èƒ½ä¼˜åŒ–:
- ç¼“å­˜å¸¸ç”¨çš„å°‘æ ·æœ¬æ¨¡æ¿
- é¢„è®¡ç®—ç¤ºä¾‹çš„é€‰æ‹©
- ä½¿ç”¨é“¾å¼è°ƒç”¨æé«˜æ•ˆç‡
    """)

def comparison_summary():
    """ä¸¤ç§æ¨¡æ¿çš„å¯¹æ¯”æ€»ç»“"""
    print("=" * 60)
    print("ğŸ“Š FewShotPromptTemplate vs FewShotChatMessagePromptTemplate")
    print("=" * 60)

    comparison_data = [
        ["ç‰¹æ€§", "FewShotPromptTemplate", "FewShotChatMessagePromptTemplate"],
        ["æ ¼å¼", "çº¯æ–‡æœ¬æ ¼å¼", "æ¶ˆæ¯æ ¼å¼"],
        ["é€‚ç”¨åœºæ™¯", "ç®€å•æ–‡æœ¬ç”Ÿæˆä»»åŠ¡", "å¯¹è¯å’ŒèŠå¤©ä»»åŠ¡"],
        ["çµæ´»æ€§", "è¾ƒä½", "è¾ƒé«˜"],
        ["æ¶ˆæ¯ç±»å‹", "ä¸åŒºåˆ†", "åŒºåˆ†ç”¨æˆ·/åŠ©æ‰‹æ¶ˆæ¯"],
        ["å¤æ‚åº¦", "ç®€å•", "ä¸­ç­‰"],
        ["æ§åˆ¶åŠ›", "å®Œå…¨æ§åˆ¶æ ¼å¼", "éµå¾ªèŠå¤©æ ¼å¼"],
        ["æœ€ä½³ç”¨é€”", "æ–‡æœ¬è¡¥å…¨ã€ç¿»è¯‘", "å¯¹è¯ç³»ç»Ÿã€é—®ç­”"]
    ]

    print("ğŸ“‹ åŠŸèƒ½å¯¹æ¯”ï¼š")
    for row in comparison_data:
        print(f"  {row[0]:<15} | {row[1]:<25} | {row[2]:<25}")

    print("\nğŸ’¡ é€‰æ‹©å»ºè®®ï¼š")
    print("  ğŸ“ ä½¿ç”¨ FewShotPromptTemplate å½“ä½ éœ€è¦ï¼š")
    print("     - ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ")
    print("     - ç¿»è¯‘ä»»åŠ¡")
    print("     - ä»£ç ç”Ÿæˆ")
    print("     - æ ¼å¼åŒ–è¾“å‡º")

    print("\n  ğŸ’¬ ä½¿ç”¨ FewShotChatMessagePromptTemplate å½“ä½ éœ€è¦ï¼š")
    print("     - å¯¹è¯ç³»ç»Ÿ")
    print("     - é—®ç­”ä»»åŠ¡")
    print("     - æƒ…æ„Ÿåˆ†æ")
    print("     - å¤æ‚çš„æ¨ç†ä»»åŠ¡")

def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ GLM-4.6 + å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 80)

    try:
        # è¿è¡Œå„ç§ç¤ºä¾‹
        basic_few_shot_prompt()
        translation_few_shot()
        code_generation_few_shot()
        basic_few_shot_chat()
        sentiment_analysis_chat()
        dynamic_few_shot()
        few_shot_chain_example()
        best_practices()
        comparison_summary()

        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("\nğŸ“š æ›´å¤šä¿¡æ¯è¯·å‚è€ƒï¼š")
        print("- LangChainå®˜æ–¹æ–‡æ¡£: https://python.langchain.com/")
        print("- å°‘æ ·æœ¬å­¦ä¹ æŒ‡å—: https://www.promptingguide.ai/techniques/fewshot")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™ï¼š{e}")

if __name__ == "__main__":
    main()