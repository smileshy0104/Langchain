import os
import dotenv
from langchain_community.chat_models import ChatZhipuAI
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# æ£€æŸ¥APIå¯†é’¥
api_key = os.getenv("ZHIPUAI_API_KEY")
if not api_key or api_key == "your-zhipu-api-key-here":
    print("âŒ é”™è¯¯ï¼šè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„ZHIPUAI_API_KEY")
    exit(1)

# åˆå§‹åŒ–GLMæ¨¡å‹
llm = ChatZhipuAI(
    model="glm-4.6",
    temperature=0.7,
    api_key=api_key
)

def prompt_template_demo():
    """PromptTemplate åŸºç¡€æ¼”ç¤º"""
    print("ğŸš€ GLM-4.6 + PromptTemplate åŸºç¡€æ¼”ç¤º")
    print("=" * 50)

    # 1. åŸºç¡€æ¨¡æ¿ä½¿ç”¨
    print("\n1ï¸âƒ£ åŸºç¡€æ¨¡æ¿ç¤ºä¾‹")
    prompt_template = PromptTemplate.from_template(
        template="è¯·è¯„ä»·{product}çš„ä¼˜ç¼ºç‚¹ï¼ŒåŒ…æ‹¬{aspect1}å’Œ{aspect2}ã€‚"
    )

    # ä½¿ç”¨formatæ–¹æ³•
    prompt = prompt_template.format(product="ç¬”è®°æœ¬ç”µè„‘", aspect1="æ€§èƒ½", aspect2="ç”µæ± ç»­èˆª")
    print(f"ğŸ“‹ ç”Ÿæˆçš„æç¤ºè¯: {prompt}")
    print(f"ğŸ“Š æç¤ºè¯ç±»å‹: {type(prompt)}")

    # 2. ä½¿ç”¨invokeæ–¹æ³• (æ¨è)
    print("\n2ï¸âƒ£ ä½¿ç”¨invokeæ–¹æ³•")
    prompt_dict = prompt_template.invoke({
        "product": "æ™ºèƒ½æ‰‹æœº",
        "aspect1": "æ‹ç…§è´¨é‡",
        "aspect2": "ç³»ç»Ÿæµç•…åº¦"
    })
    print(f"ğŸ“‹ ç”Ÿæˆçš„æç¤ºè¯: {prompt_dict}")
    print(f"ğŸ“Š æç¤ºè¯ç±»å‹: {type(prompt_dict)}")

    # 3. åˆ›å»ºå¤„ç†é“¾
    print("\n3ï¸âƒ£ åˆ›å»ºå¤„ç†é“¾")
    chain = prompt_template | llm | StrOutputParser()

    result = chain.invoke({
        "product": "å¹³æ¿ç”µè„‘",
        "aspect1": "å±å¹•æ˜¾ç¤º",
        "aspect2": "ä¾¿æºæ€§"
    })
    print(f"ğŸ¤– GLM-4.6 å›ç­”:")
    print(f"{result}\n")

def chat_prompt_template_demo():
    """ChatPromptTemplate æ¼”ç¤º"""
    print("ğŸ’¬ ChatPromptTemplate æ¼”ç¤º")
    print("=" * 50)

    # åˆ›å»ºèŠå¤©æ¨¡æ¿
    chat_prompt = ChatPromptTemplate.from_template(
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“è¯„æµ‹ä¸“å®¶ã€‚è¯·{action}ï¼š{topic}ï¼Œé‡ç‚¹å…³æ³¨{aspects}ã€‚"
    )

    # æ ¼å¼åŒ–èŠå¤©æç¤ºè¯
    messages = chat_prompt.format_messages(
        action="è¯„ä»·",
        topic="æ— çº¿è€³æœº",
        aspects="éŸ³è´¨ã€ç»­èˆªã€èˆ’é€‚åº¦"
    )

    print("ğŸ“‹ ç”Ÿæˆçš„èŠå¤©æ¶ˆæ¯:")
    for i, msg in enumerate(messages, 1):
        print(f"  {i}. [{msg.__class__.__name__}]: {msg.content}")

    # è°ƒç”¨æ¨¡å‹
    response = llm.invoke(messages)
    print(f"\nğŸ¤– GLM-4.6 å›ç­”:")
    print(f"{response.content}\n")

def advanced_template_usage():
    """é«˜çº§æ¨¡æ¿ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ”§ é«˜çº§æ¨¡æ¿ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)

    # 1. å¤æ‚å¤šå˜é‡æ¨¡æ¿
    print("1ï¸âƒ£ å¤æ‚å¤šå˜é‡æ¨¡æ¿")
    complex_template = PromptTemplate(
        template="""
äº§å“åç§°: {product}
è¯„æµ‹ç»´åº¦: {aspects}
ç›®æ ‡ç”¨æˆ·: {target_audience}
è¯„æµ‹é£æ ¼: {style}

è¯·ä¸º{target_audience}å†™ä¸€ä»½å…³äº{product}çš„{style}è¯„æµ‹æŠ¥å‘Šï¼Œé‡ç‚¹å…³æ³¨ï¼š{aspects}ã€‚
        """.strip(),
        input_variables=["product", "aspects", "target_audience", "style"]
    )

    # åˆ›å»ºå¤„ç†é“¾
    chain = complex_template | llm | StrOutputParser()

    result = chain.invoke({
        "product": "æœºæ¢°é”®ç›˜",
        "aspects": "æ‰‹æ„Ÿã€å£°éŸ³ã€è€ç”¨æ€§",
        "target_audience": "æ¸¸æˆç©å®¶",
        "style": "ä¸“ä¸šè¯¦ç»†"
    })

    print(f"ğŸ¤– GLM-4.6 ç”Ÿæˆçš„è¯„æµ‹æŠ¥å‘Š:")
    print(f"{result[:300]}...\n")

    # 2. æ¨¡æ¿ç»„åˆ
    print("2ï¸âƒ£ æ¨¡æ¿ç»„åˆç¤ºä¾‹")

    # ç³»ç»Ÿæç¤ºæ¨¡æ¿
    system_template = PromptTemplate.from_template(
        "ä½ æ˜¯ä¸€ä¸ª{role}ï¼Œä¸“é—¨{specialty}ã€‚"
    )

    # ç”¨æˆ·æç¤ºæ¨¡æ¿
    user_template = PromptTemplate.from_template(
        "è¯·{action}ï¼š{topic}"
    )

    # ç»„åˆæˆèŠå¤©æ¨¡æ¿
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("human", user_template)
    ])

    # åˆ›å»ºé“¾
    chain = chat_prompt | llm | StrOutputParser()

    result = chain.invoke({
        "role": "ç§‘æŠ€è¯„æµ‹åšä¸»",
        "specialty": "æ•°ç äº§å“è¯„æµ‹",
        "action": "è¯„æµ‹æ™ºèƒ½æ‰‹è¡¨",
        "topic": "Apple Watch Series 9"
    })

    print(f"ğŸ¤– GLM-4.6 çš„å›ç­”:")
    print(f"{result[:300]}...\n")

def best_practices():
    """æœ€ä½³å®è·µç¤ºä¾‹"""
    print("ğŸ’¡ PromptTemplate æœ€ä½³å®è·µ")
    print("=" * 50)

    print("""
âœ… æ¨èåšæ³•:
1. ä½¿ç”¨æè¿°æ€§çš„å˜é‡å
2. æä¾›æ¸…æ™°çš„æ¨¡æ¿ç»“æ„
3. ä½¿ç”¨invokeæ–¹æ³•è€Œéformatæ–¹æ³•
4. åˆ›å»ºå¤„ç†é“¾ä»¥æé«˜ä»£ç å¯è¯»æ€§
5. ä¸ºå¤æ‚æ¨¡æ¿æ·»åŠ æ³¨é‡Š

âŒ é¿å…åšæ³•:
1. ä½¿ç”¨æ¨¡ç³Šçš„å˜é‡å
2. åˆ›å»ºè¿‡äºå¤æ‚çš„å•ä¸€æ¨¡æ¿
3. ç¡¬ç¼–ç å˜é‡å€¼
4. å¿½ç•¥é”™è¯¯å¤„ç†

ğŸ”§ ä»£ç ç¤ºä¾‹:
    """)

    # å¥½çš„ç¤ºä¾‹
    print("å¥½çš„ç¤ºä¾‹:")
    good_template = PromptTemplate.from_template(
        "è¯·ä¸º{target_audience}è§£é‡Š{concept}ï¼Œä½¿ç”¨{language_style}çš„è¯­è¨€ã€‚"
    )

    chain = good_template | llm | StrOutputParser()
    result = chain.invoke({
        "target_audience": "åˆå­¦è€…",
        "concept": "ä»€ä¹ˆæ˜¯API",
        "language_style": "ç®€å•æ˜“æ‡‚"
    })
    print(f"ç»“æœ: {result[:100]}...")

if __name__ == "__main__":
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    try:
        prompt_template_demo()
        chat_prompt_template_demo()
        advanced_template_usage()
        best_practices()

        print("ğŸ‰ PromptTemplate æ¼”ç¤ºå®Œæˆï¼")

    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")