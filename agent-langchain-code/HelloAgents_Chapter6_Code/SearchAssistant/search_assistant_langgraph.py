#!/usr/bin/env python3
"""
LangGraph æ™ºèƒ½æœç´¢åŠ©æ‰‹ - åŸºäºçŠ¶æ€å›¾çš„å¤šæ­¥æ¨ç†ç³»ç»Ÿ

æ ¸å¿ƒç‰¹æ€§:
- ä½¿ç”¨ LangGraph æ„å»ºçŠ¶æ€æœºå·¥ä½œæµ
- å¤šèŠ‚ç‚¹åä½œï¼šç†è§£æŸ¥è¯¢ -> æœç´¢ä¿¡æ¯ -> ç”Ÿæˆç­”æ¡ˆ
- æ”¯æŒçœŸå®ç½‘ç»œæœç´¢ï¼ˆå¯é€‰ï¼‰æˆ–æ¨¡æ‹Ÿæœç´¢
- åŸºäºæ™ºè°±AI GLM-4.6 æ¨¡å‹
- æ”¯æŒå¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡è®°å¿†

å·¥ä½œæµç¨‹:
1. understand_query: ç†è§£ç”¨æˆ·æ„å›¾ï¼Œä¼˜åŒ–æœç´¢å…³é”®è¯
2. search_information: æ‰§è¡Œæœç´¢ï¼ˆç½‘ç»œæˆ–æ¨¡æ‹Ÿï¼‰
3. generate_answer: åŸºäºæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ

é€‚ç”¨åœºæ™¯:
âœ… éœ€è¦å®æ—¶ä¿¡æ¯çš„é—®ç­”ç³»ç»Ÿ
âœ… å¤æ‚çš„å¤šæ­¥æ¨ç†ä»»åŠ¡
âœ… éœ€è¦çŠ¶æ€ç®¡ç†çš„å¯¹è¯ç³»ç»Ÿ
"""

from __future__ import annotations

import os
import sys
from typing import TypedDict, Annotated, List, Literal
from dotenv import load_dotenv

# æ·»åŠ  Chapter4 ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥å·¥å…·æ¨¡å—
chapter4_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "..", "HelloAgents_Chapter4_Code")
sys.path.insert(0, os.path.abspath(chapter4_path))
from utils import get_llm

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ========== çŠ¶æ€å®šä¹‰ ==========

class SearchState(TypedDict):
    """æœç´¢åŠ©æ‰‹çŠ¶æ€"""
    messages: Annotated[List[BaseMessage], add_messages]  # å¯¹è¯å†å²
    user_query: str                    # ç”¨æˆ·åŸå§‹æŸ¥è¯¢
    search_query: str                  # ä¼˜åŒ–åçš„æœç´¢æŸ¥è¯¢
    search_results: str                # æœç´¢ç»“æœ
    final_answer: str                  # æœ€ç»ˆç­”æ¡ˆ
    step: str                          # å½“å‰æ­¥éª¤


# ========== å·¥å…·å‡½æ•° ==========

def simulate_search(query: str) -> str:
    """
    æ¨¡æ‹Ÿæœç´¢åŠŸèƒ½ï¼ˆæ¼”ç¤ºç”¨ï¼‰

    Args:
        query: æœç´¢æŸ¥è¯¢

    Returns:
        æ¨¡æ‹Ÿçš„æœç´¢ç»“æœ
    """
    # æ ¹æ®å…³é”®è¯è¿”å›æ¨¡æ‹Ÿç»“æœ
    search_database = {
        "å¤©æ°”": "æ ¹æ®æ°”è±¡å±€æ•°æ®ï¼Œä»Šå¤©åŒ—äº¬æ™´ï¼Œæ°”æ¸©15-25â„ƒï¼Œç©ºæ°”è´¨é‡è‰¯å¥½ã€‚",
        "langchain": "LangChainæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚å®ƒæä¾›äº†æ ‡å‡†åŒ–çš„æ¥å£ã€æ¨¡å—åŒ–ç»„ä»¶å’Œå®Œæ•´çš„åº”ç”¨é“¾ã€‚",
        "äººå·¥æ™ºèƒ½": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½è¡Œä¸ºçš„ç³»ç»Ÿã€‚",
        "python": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åï¼Œå¹¿æ³›åº”ç”¨äºæ•°æ®ç§‘å­¦ã€Webå¼€å‘å’Œè‡ªåŠ¨åŒ–ã€‚",
        "æ™ºè°±ai": "æ™ºè°±AIæ˜¯ä¸€å®¶ä¸“æ³¨äºè®¤çŸ¥æ™ºèƒ½å’Œå†³ç­–æ™ºèƒ½çš„äººå·¥æ™ºèƒ½å…¬å¸ï¼Œæ¨å‡ºäº†GLMç³»åˆ—å¤§è¯­è¨€æ¨¡å‹ã€‚",
    }

    # æŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯
    for keyword, result in search_database.items():
        if keyword.lower() in query.lower():
            return f"æœç´¢ç»“æœï¼š\n{result}"

    # é»˜è®¤è¿”å›
    return f"æœç´¢å…³é”®è¯ '{query}' çš„ç›¸å…³ä¿¡æ¯ï¼š\næ ¹æ®æœ€æ–°èµ„æ–™ï¼Œè¯¥ä¸»é¢˜æ¶‰åŠå¤šä¸ªæ–¹é¢ã€‚å»ºè®®æ‚¨æŸ¥é˜…ä¸“ä¸šèµ„æ–™ä»¥è·å–æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚"


# ========== LangGraph èŠ‚ç‚¹å‡½æ•° ==========

def understand_query_node(state: SearchState, llm) -> dict:
    """
    èŠ‚ç‚¹1: ç†è§£ç”¨æˆ·æŸ¥è¯¢å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯

    Args:
        state: å½“å‰çŠ¶æ€
        llm: è¯­è¨€æ¨¡å‹

    Returns:
        çŠ¶æ€æ›´æ–°
    """
    # è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
    user_message = ""
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            user_message = msg.content
            break

    # æ„å»ºç†è§£æç¤ºè¯
    understand_prompt = f"""åˆ†æç”¨æˆ·çš„æŸ¥è¯¢ï¼š"{user_message}"

è¯·å®Œæˆä¸¤ä¸ªä»»åŠ¡ï¼š
1. ç®€æ´æ€»ç»“ç”¨æˆ·æƒ³è¦äº†è§£ä»€ä¹ˆï¼ˆ1-2å¥è¯ï¼‰
2. ç”Ÿæˆæœ€é€‚åˆæœç´¢çš„å…³é”®è¯ï¼ˆä¸­è‹±æ–‡å‡å¯ï¼Œè¦ç²¾å‡†ä¸”ç®€çŸ­ï¼‰

æ ¼å¼ï¼š
ç†è§£ï¼š[ç”¨æˆ·éœ€æ±‚æ€»ç»“]
æœç´¢è¯ï¼š[æœ€ä½³æœç´¢å…³é”®è¯]"""

    response = llm.invoke([SystemMessage(content=understand_prompt)])

    # æå–æœç´¢å…³é”®è¯
    response_text = response.content
    search_query = user_message  # é»˜è®¤ä½¿ç”¨åŸå§‹æŸ¥è¯¢

    if "æœç´¢è¯ï¼š" in response_text:
        search_query = response_text.split("æœç´¢è¯ï¼š")[1].strip()
    elif "æœç´¢å…³é”®è¯ï¼š" in response_text:
        search_query = response_text.split("æœç´¢å…³é”®è¯ï¼š")[1].strip()

    print(f"ğŸ¤” ç†è§£æŸ¥è¯¢: {response.content}")
    print(f"ğŸ” æœç´¢å…³é”®è¯: {search_query}\n")

    return {
        "user_query": user_message,
        "search_query": search_query,
        "step": "understood",
        "messages": [AIMessage(content=f"æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ï¼š{response.content}")]
    }


def search_information_node(state: SearchState) -> dict:
    """
    èŠ‚ç‚¹2: æ‰§è¡Œæœç´¢

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        çŠ¶æ€æ›´æ–°
    """
    search_query = state["search_query"]

    print(f"ğŸ” æ­£åœ¨æœç´¢: {search_query}")

    # ä½¿ç”¨æ¨¡æ‹Ÿæœç´¢ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥æ›¿æ¢ä¸ºçœŸå®çš„æœç´¢APIï¼‰
    search_results = simulate_search(search_query)

    print(f"ğŸ“„ æœç´¢ç»“æœ:\n{search_results}\n")

    return {
        "search_results": search_results,
        "step": "searched"
    }


def generate_answer_node(state: SearchState, llm) -> dict:
    """
    èŠ‚ç‚¹3: åŸºäºæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ

    Args:
        state: å½“å‰çŠ¶æ€
        llm: è¯­è¨€æ¨¡å‹

    Returns:
        çŠ¶æ€æ›´æ–°
    """
    # æ„å»ºç­”æ¡ˆç”Ÿæˆæç¤ºè¯
    answer_prompt = f"""ç”¨æˆ·æŸ¥è¯¢ï¼š{state['user_query']}

æœç´¢ç»“æœï¼š
{state['search_results']}

è¯·åŸºäºæœç´¢ç»“æœï¼Œç”¨ç®€æ´ã€å‡†ç¡®çš„è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
- ç›´æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦é‡å¤æœç´¢ç»“æœ
- å¦‚æœæœç´¢ç»“æœä¸å……åˆ†ï¼Œè¯·è¯šå®è¯´æ˜
- ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„è¯­æ°”"""

    response = llm.invoke([SystemMessage(content=answer_prompt)])
    final_answer = response.content

    print(f"ğŸ’¡ ç”Ÿæˆç­”æ¡ˆ:\n{final_answer}\n")

    return {
        "final_answer": final_answer,
        "step": "answered",
        "messages": [AIMessage(content=final_answer)]
    }


# ========== LangGraph æ„å»º ==========

class SearchAssistant:
    """LangGraph æ™ºèƒ½æœç´¢åŠ©æ‰‹"""

    def __init__(
        self,
        model: str = "glm-4.6",
        temperature: float = 0.7,
        use_memory: bool = True,
        debug: bool = False
    ):
        """
        åˆå§‹åŒ–æœç´¢åŠ©æ‰‹

        Args:
            model: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
            use_memory: æ˜¯å¦ä½¿ç”¨è®°å¿†ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ï¼‰
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        """
        self.llm = get_llm(provider="zhipuai", model=model, temperature=temperature)
        self.debug = debug

        # æ„å»ºçŠ¶æ€å›¾
        self.graph = self._build_graph()

        # ç¼–è¯‘å›¾ï¼ˆå¸¦è®°å¿†æ”¯æŒï¼‰
        if use_memory:
            memory = MemorySaver()
            self.app = self.graph.compile(checkpointer=memory)
        else:
            self.app = self.graph.compile()

    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph çŠ¶æ€å›¾"""

        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(SearchState)

        # æ·»åŠ èŠ‚ç‚¹ï¼ˆä½¿ç”¨ lambda åŒ…è£…ä»¥ä¼ é€’ llmï¼‰
        workflow.add_node(
            "understand_query",
            lambda state: understand_query_node(state, self.llm)
        )
        workflow.add_node(
            "search_information",
            search_information_node
        )
        workflow.add_node(
            "generate_answer",
            lambda state: generate_answer_node(state, self.llm)
        )

        # æ·»åŠ è¾¹ï¼ˆå®šä¹‰å·¥ä½œæµï¼‰
        workflow.add_edge(START, "understand_query")
        workflow.add_edge("understand_query", "search_information")
        workflow.add_edge("search_information", "generate_answer")
        workflow.add_edge("generate_answer", END)

        return workflow

    def search(self, query: str, thread_id: str = "default") -> str:
        """
        æ‰§è¡Œæœç´¢æŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            thread_id: çº¿ç¨‹IDï¼ˆç”¨äºè®°å¿†ç®¡ç†ï¼‰

        Returns:
            æœ€ç»ˆç­”æ¡ˆ
        """
        if self.debug:
            print(f"\n{'='*80}")
            print(f"ğŸš€ æ™ºèƒ½æœç´¢åŠ©æ‰‹å¯åŠ¨")
            print(f"{'='*80}")
            print(f"ğŸ“ æŸ¥è¯¢: {query}\n")

        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "user_query": "",
            "search_query": "",
            "search_results": "",
            "final_answer": "",
            "step": "init"
        }

        # æ‰§è¡Œå›¾
        config = {"configurable": {"thread_id": thread_id}}
        final_state = self.app.invoke(initial_state, config)

        if self.debug:
            print(f"\n{'='*80}")
            print(f"âœ… æœç´¢å®Œæˆ")
            print(f"{'='*80}\n")

        return final_state["final_answer"]

    def chat(self, message: str, thread_id: str = "default") -> str:
        """
        å¤šè½®å¯¹è¯æ¥å£ï¼ˆåˆ©ç”¨è®°å¿†åŠŸèƒ½ï¼‰

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            thread_id: å¯¹è¯çº¿ç¨‹ID

        Returns:
            åŠ©æ‰‹å›å¤
        """
        return self.search(message, thread_id)


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

def example_basic_search():
    """ç¤ºä¾‹1: åŸºç¡€æœç´¢"""
    print("="*80)
    print("ğŸ“Œ ç¤ºä¾‹1: åŸºç¡€æœç´¢æŸ¥è¯¢")
    print("="*80)

    assistant = SearchAssistant(debug=True)

    queries = [
        "ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ",
        "Python ç¼–ç¨‹è¯­è¨€æœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ"
    ]

    for query in queries:
        print(f"\n{'='*80}")
        print(f"ç”¨æˆ·æŸ¥è¯¢: {query}")
        print(f"{'='*80}")

        answer = assistant.search(query)

        print(f"\næœ€ç»ˆç­”æ¡ˆ: {answer}\n")


def example_conversation():
    """ç¤ºä¾‹2: å¤šè½®å¯¹è¯"""
    print("\n" + "="*80)
    print("ğŸ“Œ ç¤ºä¾‹2: å¤šè½®å¯¹è¯ï¼ˆå¸¦è®°å¿†ï¼‰")
    print("="*80)

    assistant = SearchAssistant(use_memory=True, debug=False)

    conversation = [
        "ä»€ä¹ˆæ˜¯æ™ºè°±AIï¼Ÿ",
        "å®ƒæœ‰å“ªäº›ä¸»è¦äº§å“ï¼Ÿ",  # æµ‹è¯•ä¸Šä¸‹æ–‡ç†è§£
        "è¿™äº›äº§å“å¯ä»¥åº”ç”¨åœ¨å“ªäº›åœºæ™¯ï¼Ÿ"
    ]

    thread_id = "conversation_1"

    for i, user_input in enumerate(conversation, 1):
        print(f"\n--- ç¬¬ {i} è½®å¯¹è¯ ---")
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_input}")

        response = assistant.chat(user_input, thread_id=thread_id)

        print(f"ğŸ¤– åŠ©æ‰‹: {response}")


def example_complex_query():
    """ç¤ºä¾‹3: å¤æ‚æŸ¥è¯¢"""
    print("\n" + "="*80)
    print("ğŸ“Œ ç¤ºä¾‹3: å¤æ‚æ¨ç†æŸ¥è¯¢")
    print("="*80)

    assistant = SearchAssistant(temperature=0.3, debug=True)

    query = """æˆ‘æƒ³å­¦ä¹ äººå·¥æ™ºèƒ½ï¼Œç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹å¼€å‘ã€‚
è¯·å‘Šè¯‰æˆ‘ï¼š
1. éœ€è¦å…·å¤‡å“ªäº›åŸºç¡€çŸ¥è¯†ï¼Ÿ
2. æ¨èå­¦ä¹ å“ªäº›æ¡†æ¶å’Œå·¥å…·ï¼Ÿ
3. å­¦ä¹ è·¯å¾„åº”è¯¥æ˜¯æ€æ ·çš„ï¼Ÿ"""

    answer = assistant.search(query)

    print(f"\nå®Œæ•´ç­”æ¡ˆ:\n{answer}")


def example_information_extraction():
    """ç¤ºä¾‹4: ä¿¡æ¯æå–"""
    print("\n" + "="*80)
    print("ğŸ“Œ ç¤ºä¾‹4: ä¿¡æ¯æå–å’Œæ€»ç»“")
    print("="*80)

    assistant = SearchAssistant(temperature=0.5, debug=True)

    queries = [
        "LangChain çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿè¯·åˆ—ä¸¾å‰ä¸‰ä¸ªã€‚",
        "Python å’Œ JavaScript çš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ"
    ]

    for query in queries:
        print(f"\næŸ¥è¯¢: {query}")
        answer = assistant.search(query)
        print(f"ç­”æ¡ˆ: {answer}\n")
        print("-" * 80)


def example_realtime_info():
    """ç¤ºä¾‹5: å®æ—¶ä¿¡æ¯æŸ¥è¯¢"""
    print("\n" + "="*80)
    print("ğŸ“Œ ç¤ºä¾‹5: å®æ—¶ä¿¡æ¯æŸ¥è¯¢ï¼ˆæ¨¡æ‹Ÿï¼‰")
    print("="*80)

    assistant = SearchAssistant(debug=True)

    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿæœç´¢
    # å®é™…åº”ç”¨ä¸­å¯ä»¥é›†æˆçœŸå®çš„æœç´¢APIï¼ˆå¦‚Tavilyã€SerpAPIç­‰ï¼‰
    queries = [
        "ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ",
        "æœ€æ–°çš„AIæŠ€æœ¯è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
    ]

    for query in queries:
        print(f"\næŸ¥è¯¢: {query}")
        answer = assistant.search(query)


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œç¤ºä¾‹"""
    print("ğŸš€ LangGraph æ™ºèƒ½æœç´¢åŠ©æ‰‹")
    print("="*80)

    # æ£€æŸ¥ API å¯†é’¥
    api_key = os.getenv("ZHIPUAI_API_KEY")
    if not api_key or api_key.startswith("your-"):
        print("âŒ é”™è¯¯ï¼šè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„ ZHIPUAI_API_KEY")
        print("ğŸ“ è·å– API å¯†é’¥ï¼šhttps://open.bigmodel.cn/")
        return

    try:
        # è¿è¡Œç¤ºä¾‹ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ï¼‰
        example_basic_search()
        # example_conversation()
        # example_complex_query()
        # example_information_extraction()
        # example_realtime_info()

        print("\n" + "="*80)
        print("âœ… æ™ºèƒ½æœç´¢åŠ©æ‰‹ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("="*80)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºã€‚")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™ï¼š{e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
