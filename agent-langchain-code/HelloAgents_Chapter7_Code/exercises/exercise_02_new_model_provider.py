"""
ä¹ é¢˜ 2: å¤šæ¨¡å‹æ”¯æŒ
å®è·µæ·»åŠ æ–°çš„æ¨¡å‹ä¾›åº”å•†

æœ¬æ–‡ä»¶å±•ç¤ºå¦‚ä½•ä¸ºæ¡†æ¶æ·»åŠ æ–°çš„ LLM æä¾›å•†æ”¯æŒ:
1. Anthropic Claude (ä½¿ç”¨ langchain-anthropic)
2. Moonshot AI (ä½¿ç”¨æ™ºè°± API æ ¼å¼)
3. æœ¬åœ° Ollama æ¨¡å‹
"""

import os
from typing import Optional, Dict, Any
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_community.chat_models import ChatZhipuAI

# è®¾ç½® API Key
os.environ["ZHIPUAI_API_KEY"] = os.getenv("ZHIPUAI_API_KEY", "your-api-key-here")


class MultiModelLLM:
    """
    å¤šæ¨¡å‹ LLM ç®¡ç†å™¨
    æ”¯æŒå¤šä¸ªæ¨¡å‹æä¾›å•†çš„ç»Ÿä¸€æ¥å£
    """

    def __init__(
        self,
        provider: str = "zhipuai",
        model: Optional[str] = None,
        **kwargs
    ):
        """
        åˆå§‹åŒ–å¤šæ¨¡å‹ LLM

        Args:
            provider: æä¾›å•†åç§° (zhipuai/anthropic/moonshot/ollama)
            model: æ¨¡å‹åç§°
            **kwargs: å…¶ä»–å‚æ•°
        """
        self.provider = provider.lower()
        self.model = model
        self.kwargs = kwargs
        self.llm = self._create_llm()

    def _create_llm(self) -> BaseChatModel:
        """æ ¹æ®æä¾›å•†åˆ›å»ºå¯¹åº”çš„ LLM å®ä¾‹"""

        if self.provider == "zhipuai":
            return self._create_zhipuai_llm()
        elif self.provider == "anthropic":
            return self._create_anthropic_llm()
        elif self.provider == "moonshot":
            return self._create_moonshot_llm()
        elif self.provider == "ollama":
            return self._create_ollama_llm()
        else:
            raise ValueError(
                f"ä¸æ”¯æŒçš„æä¾›å•†: {self.provider}. "
                f"æ”¯æŒçš„æä¾›å•†: zhipuai, anthropic, moonshot, ollama"
            )

    def _create_zhipuai_llm(self) -> ChatZhipuAI:
        """åˆ›å»ºæ™ºè°± AI LLM"""
        api_key = os.getenv("ZHIPUAI_API_KEY")
        if not api_key:
            raise ValueError("æœªè®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡")

        model = self.model or "glm-4-plus"
        temperature = self.kwargs.get("temperature", 0.7)

        print(f"âœ… åˆ›å»ºæ™ºè°±AI LLM: {model}")
        return ChatZhipuAI(
            model=model,
            temperature=temperature,
            zhipuai_api_key=api_key,
            **{k: v for k, v in self.kwargs.items() if k != "temperature"}
        )

    def _create_anthropic_llm(self) -> BaseChatModel:
        """åˆ›å»º Anthropic Claude LLM"""
        try:
            from langchain_anthropic import ChatAnthropic
        except ImportError:
            raise ImportError(
                "è¯·å®‰è£… langchain-anthropic: pip install langchain-anthropic"
            )

        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("æœªè®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")

        model = self.model or "claude-3-5-sonnet-20241022"
        temperature = self.kwargs.get("temperature", 0.7)

        print(f"âœ… åˆ›å»º Anthropic LLM: {model}")
        return ChatAnthropic(
            model=model,
            temperature=temperature,
            anthropic_api_key=api_key,
            **{k: v for k, v in self.kwargs.items() if k != "temperature"}
        )

    def _create_moonshot_llm(self) -> BaseChatModel:
        """
        åˆ›å»º Moonshot AI LLM
        Moonshot ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
        """
        try:
            from langchain_openai import ChatOpenAI
        except ImportError:
            raise ImportError(
                "è¯·å®‰è£… langchain-openai: pip install langchain-openai"
            )

        api_key = os.getenv("MOONSHOT_API_KEY")
        if not api_key:
            raise ValueError("æœªè®¾ç½® MOONSHOT_API_KEY ç¯å¢ƒå˜é‡")

        model = self.model or "moonshot-v1-8k"
        temperature = self.kwargs.get("temperature", 0.7)

        print(f"âœ… åˆ›å»º Moonshot LLM: {model}")
        return ChatOpenAI(
            model=model,
            temperature=temperature,
            openai_api_key=api_key,
            openai_api_base="https://api.moonshot.cn/v1",
            **{k: v for k, v in self.kwargs.items() if k != "temperature"}
        )

    def _create_ollama_llm(self) -> BaseChatModel:
        """åˆ›å»ºæœ¬åœ° Ollama LLM"""
        try:
            from langchain_community.chat_models import ChatOllama
        except ImportError:
            raise ImportError(
                "è¯·å®‰è£… langchain-community: pip install langchain-community"
            )

        model = self.model or "llama2"
        temperature = self.kwargs.get("temperature", 0.7)
        base_url = self.kwargs.get("base_url", "http://localhost:11434")

        print(f"âœ… åˆ›å»º Ollama LLM: {model}")
        return ChatOllama(
            model=model,
            temperature=temperature,
            base_url=base_url,
            **{k: v for k, v in self.kwargs.items()
               if k not in ["temperature", "base_url"]}
        )

    def invoke(self, messages):
        """è°ƒç”¨ LLM"""
        return self.llm.invoke(messages)

    def __repr__(self):
        return f"MultiModelLLM(provider={self.provider}, model={self.model})"


def test_zhipuai():
    """æµ‹è¯•æ™ºè°± AI"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1: æ™ºè°± AI (GLM-4)")
    print("=" * 60)

    try:
        llm = MultiModelLLM(provider="zhipuai", model="glm-4-flash")
        response = llm.invoke([{"role": "user", "content": "ä½ å¥½,è¯·ä»‹ç»ä½ è‡ªå·±"}])
        print(f"\nğŸ’¬ æ¨¡å‹: {llm.model}")
        print(f"ğŸ“ å“åº”: {response.content}\n")
        print("âœ… æ™ºè°± AI æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ æ™ºè°± AI æµ‹è¯•å¤±è´¥: {e}")


def test_anthropic():
    """æµ‹è¯• Anthropic Claude"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: Anthropic Claude")
    print("=" * 60)

    try:
        llm = MultiModelLLM(
            provider="anthropic",
            model="claude-3-5-sonnet-20241022"
        )
        response = llm.invoke([{"role": "user", "content": "Hello, introduce yourself"}])
        print(f"\nğŸ’¬ æ¨¡å‹: {llm.model}")
        print(f"ğŸ“ å“åº”: {response.content}\n")
        print("âœ… Anthropic æµ‹è¯•é€šè¿‡")
    except ValueError as e:
        print(f"âš ï¸  Anthropic æµ‹è¯•è·³è¿‡: {e}")
    except ImportError as e:
        print(f"âš ï¸  Anthropic æµ‹è¯•è·³è¿‡: {e}")
    except Exception as e:
        print(f"âŒ Anthropic æµ‹è¯•å¤±è´¥: {e}")


def test_moonshot():
    """æµ‹è¯• Moonshot AI"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: Moonshot AI")
    print("=" * 60)

    try:
        llm = MultiModelLLM(provider="moonshot", model="moonshot-v1-8k")
        response = llm.invoke([{"role": "user", "content": "ä½ å¥½,è¯·ä»‹ç»ä½ è‡ªå·±"}])
        print(f"\nğŸ’¬ æ¨¡å‹: {llm.model}")
        print(f"ğŸ“ å“åº”: {response.content}\n")
        print("âœ… Moonshot æµ‹è¯•é€šè¿‡")
    except ValueError as e:
        print(f"âš ï¸  Moonshot æµ‹è¯•è·³è¿‡: {e}")
    except ImportError as e:
        print(f"âš ï¸  Moonshot æµ‹è¯•è·³è¿‡: {e}")
    except Exception as e:
        print(f"âŒ Moonshot æµ‹è¯•å¤±è´¥: {e}")


def test_ollama():
    """æµ‹è¯• Ollama"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: Ollama (æœ¬åœ°æ¨¡å‹)")
    print("=" * 60)

    try:
        llm = MultiModelLLM(
            provider="ollama",
            model="llama2",
            base_url="http://localhost:11434"
        )
        response = llm.invoke([{"role": "user", "content": "Hello, who are you?"}])
        print(f"\nğŸ’¬ æ¨¡å‹: {llm.model}")
        print(f"ğŸ“ å“åº”: {response.content}\n")
        print("âœ… Ollama æµ‹è¯•é€šè¿‡")
    except ImportError as e:
        print(f"âš ï¸  Ollama æµ‹è¯•è·³è¿‡: {e}")
    except Exception as e:
        print(f"âš ï¸  Ollama æµ‹è¯•è·³è¿‡: {e}")
        print("æç¤º: è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œå¹¶å·²å®‰è£… llama2 æ¨¡å‹")


def demo_agent_with_multiple_models():
    """æ¼”ç¤º: ä½¿ç”¨ä¸åŒæ¨¡å‹åˆ›å»º Agent"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤º: åŒä¸€ä¸ª Agent,åˆ‡æ¢ä¸åŒæ¨¡å‹")
    print("=" * 60)

    import sys
    sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

    try:
        from agents.simple_agent_langchain import SimpleAgent

        # æµ‹è¯•é—®é¢˜
        question = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½?è¯·ç”¨ä¸€å¥è¯å›ç­”"

        # ä½¿ç”¨æ™ºè°± AI
        print("\nğŸ¤– Agent 1: ä½¿ç”¨æ™ºè°± GLM-4-Flash")
        llm1 = MultiModelLLM(provider="zhipuai", model="glm-4-flash")
        agent1 = SimpleAgent(name="æ™ºè°±åŠ©æ‰‹", llm=llm1.llm)
        response1 = agent1.run(question)
        print(f"å›ç­”: {response1}")

        # å¦‚æœé…ç½®äº†å…¶ä»–æ¨¡å‹,ä¹Ÿå¯ä»¥æµ‹è¯•
        if os.getenv("ANTHROPIC_API_KEY"):
            print("\nğŸ¤– Agent 2: ä½¿ç”¨ Claude")
            llm2 = MultiModelLLM(provider="anthropic")
            agent2 = SimpleAgent(name="ClaudeåŠ©æ‰‹", llm=llm2.llm)
            response2 = agent2.run(question)
            print(f"å›ç­”: {response2}")

        print("\nâœ… å¤šæ¨¡å‹ Agent æ¼”ç¤ºå®Œæˆ")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def show_configuration_guide():
    """æ˜¾ç¤ºé…ç½®æŒ‡å—"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ é…ç½®æŒ‡å—")
    print("=" * 60)

    print("""
è¦æµ‹è¯•ä¸åŒçš„æ¨¡å‹æä¾›å•†,è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ç›¸åº”çš„ API Key:

1. æ™ºè°± AI (å¿…éœ€)
   ZHIPUAI_API_KEY=your-key
   è·å–åœ°å€: https://open.bigmodel.cn/

2. Anthropic Claude (å¯é€‰)
   ANTHROPIC_API_KEY=your-key
   è·å–åœ°å€: https://console.anthropic.com/

3. Moonshot AI (å¯é€‰)
   MOONSHOT_API_KEY=your-key
   è·å–åœ°å€: https://platform.moonshot.cn/

4. Ollama (å¯é€‰ - æœ¬åœ°)
   æ— éœ€ API Key,éœ€è¦å®‰è£… Ollama
   å®‰è£…åœ°å€: https://ollama.ai/
   å¯åŠ¨å‘½ä»¤: ollama serve
   ä¸‹è½½æ¨¡å‹: ollama pull llama2

æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨:
- æ™ºè°±: glm-4-plus, glm-4-flash, glm-4, glm-3-turbo
- Claude: claude-3-5-sonnet-20241022, claude-3-opus-20240229
- Moonshot: moonshot-v1-8k, moonshot-v1-32k, moonshot-v1-128k
- Ollama: llama2, mistral, codellama, qwen ç­‰
    """)


if __name__ == "__main__":
    print("=" * 60)
    print("  ä¹ é¢˜ 2: å¤šæ¨¡å‹æ”¯æŒæµ‹è¯•")
    print("=" * 60)

    # æ˜¾ç¤ºé…ç½®æŒ‡å—
    show_configuration_guide()

    # æµ‹è¯•å„ä¸ªæä¾›å•†
    test_zhipuai()
    test_anthropic()
    test_moonshot()
    test_ollama()

    # æ¼”ç¤ºå¤šæ¨¡å‹ Agent
    demo_agent_with_multiple_models()

    print("\n" + "=" * 60)
    print("  æµ‹è¯•å®Œæˆ")
    print("=" * 60)
    print("""
ğŸ’¡ æ‰©å±•æ€è€ƒ:
1. å¦‚ä½•è‡ªåŠ¨é€‰æ‹©æœ€ä¾¿å®œçš„æ¨¡å‹?
2. å¦‚ä½•å®ç°æ¨¡å‹çš„çƒ­åˆ‡æ¢(ä¸é‡å¯ç¨‹åº)?
3. å¦‚ä½•å®ç°æ¨¡å‹çš„è´Ÿè½½å‡è¡¡?
4. å¦‚ä½•ä¸ºä¸åŒä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹?
    """)
