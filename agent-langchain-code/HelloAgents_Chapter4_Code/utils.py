#!/usr/bin/env python3
"""
é€šç”¨å·¥å…·æ¨¡å— - LLM åˆå§‹åŒ–å’Œè¾…åŠ©å‡½æ•°

æä¾›ç»Ÿä¸€çš„ LLM åˆå§‹åŒ–æ¥å£ï¼Œæ”¯æŒ:
- æ™ºè°±AI GLM-4ï¼ˆæ¨èï¼Œä¸­æ–‡ä¼˜åŒ–ï¼‰
- OpenAI GPT ç³»åˆ—
- å…¶ä»– OpenAI å…¼å®¹ API
"""

import os
from typing import Literal
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def get_llm(
    provider: Literal["zhipuai", "openai"] = "zhipuai",
    model: str | None = None,
    temperature: float = 0.7,
    streaming: bool = False
):
    """
    è·å– LLM å®ä¾‹

    Args:
        provider: LLM æä¾›å•†
            - "zhipuai": æ™ºè°±AI GLMï¼ˆæ¨èï¼Œä¸­æ–‡ä¼˜åŒ–ï¼‰
            - "openai": OpenAI æˆ–å…¼å®¹ API
        model: æ¨¡å‹åç§°
            - zhipuai: "glm-4" (é»˜è®¤), "glm-4-flash", "glm-4-plus"
            - openai: "gpt-4", "gpt-3.5-turbo" ç­‰
        temperature: æ¸©åº¦å‚æ•°ï¼ˆ0.0-1.0ï¼‰
            - 0.0: ç¡®å®šæ€§è¾“å‡ºï¼Œé€‚åˆäº‹å®æ€§ä»»åŠ¡
            - 0.7: å¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§ï¼ˆé»˜è®¤ï¼‰
            - 1.0: æœ€å¤§åˆ›é€ æ€§ï¼Œé€‚åˆåˆ›æ„å†™ä½œ
        streaming: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º

    Returns:
        LangChain LLM å®ä¾‹

    Raises:
        ValueError: å¦‚æœç¼ºå°‘å¿…è¦çš„ API å¯†é’¥

    Examples:
        >>> # ä½¿ç”¨æ™ºè°±AI GLM-4
        >>> llm = get_llm(provider="zhipuai")

        >>> # ä½¿ç”¨ OpenAI GPT-4
        >>> llm = get_llm(provider="openai", model="gpt-4")

        >>> # å¯ç”¨æµå¼è¾“å‡º
        >>> llm = get_llm(streaming=True)
    """

    if provider == "zhipuai":
        return _get_zhipuai_llm(model, temperature, streaming)
    elif provider == "openai":
        return _get_openai_llm(model, temperature, streaming)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ provider: {provider}")


def _get_zhipuai_llm(model: str | None, temperature: float, streaming: bool):
    """è·å–æ™ºè°±AI LLM å®ä¾‹"""
    from langchain_community.chat_models import ChatZhipuAI

    api_key = os.getenv("ZHIPUAI_API_KEY")
    if not api_key or api_key.startswith("your-"):
        raise ValueError(
            "æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„ ZHIPUAI_API_KEYã€‚\n"
            "è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ï¼Œæˆ–è®¿é—® https://open.bigmodel.cn/ è·å–å¯†é’¥ã€‚"
        )

    return ChatZhipuAI(
        model=model or "glm-4.6",
        api_key=api_key,
        temperature=temperature,
        streaming=streaming
    )


def _get_openai_llm(model: str | None, temperature: float, streaming: bool):
    """è·å– OpenAI LLM å®ä¾‹"""
    from langchain_openai import ChatOpenAI

    api_key = os.getenv("LLM_API_KEY")
    if not api_key or api_key.startswith("your-"):
        raise ValueError(
            "æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„ LLM_API_KEYã€‚\n"
            "è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OpenAI API å¯†é’¥ã€‚"
        )

    return ChatOpenAI(
        model=model or os.getenv("LLM_MODEL_ID", "gpt-4"),
        openai_api_key=api_key,
        openai_api_base=os.getenv("LLM_BASE_URL"),
        temperature=temperature,
        streaming=streaming
    )


def require_env_var(name: str) -> str:
    """
    ç¡®ä¿å¿…éœ€çš„ç¯å¢ƒå˜é‡å­˜åœ¨

    Args:
        name: ç¯å¢ƒå˜é‡åç§°

    Returns:
        ç¯å¢ƒå˜é‡å€¼

    Raises:
        EnvironmentError: å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨æˆ–æ— æ•ˆ
    """
    value = os.getenv(name)
    if not value or value.startswith("your-"):
        raise EnvironmentError(
            f"æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„ {name}ã€‚\n"
            f"è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®åé‡è¯•ã€‚"
        )
    return value


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯• LLM åˆå§‹åŒ–\n")

    # æµ‹è¯•æ™ºè°±AI
    try:
        print("1ï¸âƒ£ æµ‹è¯•æ™ºè°±AI GLM-4...")
        llm = get_llm(provider="zhipuai", model="glm-4.6", temperature=0.3)
        print(f"   âœ… æˆåŠŸ: {llm.__class__.__name__}")
        print(f"   æ¨¡å‹: {llm.model_name}")  # ChatZhipuAI ä½¿ç”¨ model_name å±æ€§
        print(f"   æ¸©åº¦: {llm.temperature}")
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")

    print()

    # æµ‹è¯• OpenAI
    try:
        print("2ï¸âƒ£ æµ‹è¯• OpenAI API...")
        llm = get_llm(provider="openai", model="gpt-4", temperature=0.5)
        print(f"   âœ… æˆåŠŸ: {llm.__class__.__name__}")
        print(f"   æ¨¡å‹: {llm.model_name}")
        print(f"   æ¸©åº¦: {llm.temperature}")
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")

    print("\nâœ¨ æµ‹è¯•å®Œæˆï¼")
