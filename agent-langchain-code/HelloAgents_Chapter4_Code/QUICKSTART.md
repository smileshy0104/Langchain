# 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

> å¿«é€Ÿä¸Šæ‰‹ Hello-Agents LangChain v1.0 å®ç°

## ğŸš€ ä¸‰æ­¥å¼€å§‹

### æ­¥éª¤ 1: å®‰è£…ä¾èµ–ï¼ˆ1åˆ†é’Ÿï¼‰

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /Users/yuyansong/AiProject/Langchain/hello-agents-langchain-v1

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### æ­¥éª¤ 2: é…ç½® API å¯†é’¥ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶
# å¡«å…¥ä½ çš„æ™ºè°±AI APIå¯†é’¥
```

**è·å– API å¯†é’¥**: https://open.bigmodel.cn/

`.env` æ–‡ä»¶å†…å®¹:
```bash
ZHIPUAI_API_KEY=ä½ çš„APIå¯†é’¥
```

### æ­¥éª¤ 3: è¿è¡Œç¤ºä¾‹ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
# è¿è¡Œ ReAct ç¤ºä¾‹
python 01_react_agent.py

# è¿è¡Œ Plan-and-Solve ç¤ºä¾‹
python 02_plan_and_solve.py

# è¿è¡Œ Reflection ç¤ºä¾‹
python 03_reflection_agent.py
```

---

## ğŸ“ ä½¿ç”¨ä½ è‡ªå·±çš„é—®é¢˜

### ReAct - åŠ¨æ€å·¥å…·è°ƒç”¨

```python
from utils import get_llm
from tools import get_weather, calculator
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage

# 1. åˆ›å»º LLM
llm = get_llm(provider="zhipuai", model="glm-4")

# 2. å®šä¹‰å·¥å…·
tools = [get_weather, calculator]

# 3. åˆ›å»º Agent
agent = create_agent(
    model=llm,
    tools=tools,
    system_prompt="ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥è°ƒç”¨å·¥å…·å¸®åŠ©ç”¨æˆ·ã€‚"
)

# 4. æé—®
result = agent.invoke({
    "messages": [HumanMessage(content="åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ")]
})

print(result["messages"][-1].content)
```

### Plan-and-Solve - ç»“æ„åŒ–è§„åˆ’

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from typing import List

class Plan(BaseModel):
    steps: List[str] = Field(description="æ­¥éª¤åˆ—è¡¨")

# è§„åˆ’é“¾
parser = JsonOutputParser(pydantic_object=Plan)
prompt = ChatPromptTemplate.from_messages([
    ("system", "{format_instructions}"),
    ("human", "é—®é¢˜: {question}")
])

chain = prompt.partial(
    format_instructions=parser.get_format_instructions()
) | llm | parser

# ç”Ÿæˆè®¡åˆ’
plan = chain.invoke({"question": "ä½ çš„é—®é¢˜"})
print(plan["steps"])
```

### Reflection - è¿­ä»£ä¼˜åŒ–

```python
# åˆå§‹ç”Ÿæˆ
initial_chain = initial_prompt | llm | StrOutputParser()
code = initial_chain.invoke({"task": "ç¼–å†™å‡½æ•°"})

# åæ€
reflect_chain = reflect_prompt | llm | StrOutputParser()
feedback = reflect_chain.invoke({"task": "ç¼–å†™å‡½æ•°", "code": code})

# ä¼˜åŒ–
refine_chain = refine_prompt | llm | StrOutputParser()
better_code = refine_chain.invoke({
    "task": "ç¼–å†™å‡½æ•°",
    "last_code": code,
    "feedback": feedback
})
```

---

## ğŸ”§ è‡ªå®šä¹‰å·¥å…·

åˆ›å»ºä½ è‡ªå·±çš„å·¥å…·:

```python
from langchain_core.tools import tool

@tool
def my_custom_tool(input: str) -> str:
    """å·¥å…·æè¿°ï¼ˆä¼šè¢« LLM çœ‹åˆ°ï¼‰

    Args:
        input: å‚æ•°æè¿°
    """
    # å®ç°ä½ çš„é€»è¾‘
    result = f"å¤„ç†ç»“æœ: {input}"
    return result

# ä½¿ç”¨
tools = [my_custom_tool]
agent = create_agent(model=llm, tools=tools, ...)
```

---

## ğŸ’¡ ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯» [README.md](README.md) äº†è§£è¯¦ç»†ä¿¡æ¯
- ğŸ“ æŸ¥çœ‹ [è½¬æ¢æŒ‡å—](../agent-docs/åŸå§‹ä»£ç åˆ°LangChain_v1.0_è½¬æ¢æŒ‡å—.md) å­¦ä¹ åŸç†
- ğŸ”¨ ä¿®æ”¹ä»£ç ç¤ºä¾‹ï¼Œè§£å†³ä½ è‡ªå·±çš„é—®é¢˜
- ğŸŒŸ æ¢ç´¢æ›´å¤š LangChain åŠŸèƒ½

---

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•åˆ‡æ¢åˆ° GPT-4ï¼Ÿ

ä¿®æ”¹ `.env`:
```bash
LLM_MODEL_ID=gpt-4
LLM_API_KEY=your_openai_key
LLM_BASE_URL=https://api.openai.com/v1
```

åœ¨ä»£ç ä¸­:
```python
llm = get_llm(provider="openai", model="gpt-4")
```

### Q: å¦‚ä½•å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Ÿ

```python
# ReAct
agent = ReActAgent(debug=True)

# Plan-and-Solve
agent = PlanAndSolveAgent(debug=True)

# Reflection
agent = ReflectionAgent(debug=True)

# æˆ–ä½¿ç”¨ create_agent
agent = create_agent(..., debug=True)
```

### Q: é‡åˆ°é”™è¯¯æ€ä¹ˆåŠï¼Ÿ

1. æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®
2. ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
3. æŸ¥çœ‹é”™è¯¯ä¿¡æ¯ï¼ˆé€šå¸¸å¾ˆæ˜ç¡®ï¼‰
4. å‚è€ƒ [README.md](README.md) å¸¸è§é—®é¢˜éƒ¨åˆ†

---

ğŸ‰ å¼€å§‹æ„å»ºä½ çš„æ™ºèƒ½ä½“å§ï¼
