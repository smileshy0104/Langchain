"""
LangChain Agents ä¸­é—´ä»¶ç¤ºä¾‹
æ¼”ç¤ºåŠ¨æ€æ¨¡å‹é€‰æ‹©ã€å·¥å…·é”™è¯¯å¤„ç†ã€åŠ¨æ€æç¤ºè¯ç­‰
ä½¿ç”¨ GLM æ¨¡å‹
"""

from langchain.agents import create_agent
from langchain_community.chat_models import ChatZhipuAI
from langchain.agents.middleware import (
    wrap_model_call,
    wrap_tool_call,
    dynamic_prompt,
    before_model,
    after_model
)
from langchain_core.tools import tool, ToolException
from langchain_core.messages import ToolMessage, AIMessage
from typing import Callable
import os
import time

# è®¾ç½® API Key
os.environ["ZHIPUAI_API_KEY"] = os.getenv("ZHIPUAI_API_KEY", "your-api-key-here")


# ==================== 1. å·¥å…·å®šä¹‰ ====================

@tool
def search(query: str) -> str:
    """æœç´¢ä¿¡æ¯"""
    return f"æœç´¢ç»“æœ: {query}"


@tool
def get_weather(location: str) -> str:
    """è·å–å¤©æ°”ä¿¡æ¯"""
    # æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„APIè°ƒç”¨
    if location == "ç«æ˜Ÿ":
        raise Exception("æ— æ³•è·å–ç«æ˜Ÿå¤©æ°”æ•°æ®")
    return f"{location} çš„å¤©æ°”æ˜¯æ™´æœ—çš„,æ¸©åº¦ 22Â°C"


@tool
def calculate(expression: str) -> float:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    try:
        return eval(expression)
    except Exception as e:
        raise ToolException(f"è®¡ç®—é”™è¯¯: {str(e)}")


@tool
def risky_operation(param: str) -> str:
    """å¯èƒ½å¤±è´¥çš„æ“ä½œ"""
    if "error" in param.lower():
        raise Exception("æ“ä½œå¤±è´¥: å‚æ•°åŒ…å«é”™è¯¯å…³é”®å­—")
    return f"æˆåŠŸå¤„ç†: {param}"


# ==================== 2. å·¥å…·é”™è¯¯å¤„ç†ä¸­é—´ä»¶ ====================

@wrap_tool_call
def handle_tool_errors(request, handler):
    """
    ç»Ÿä¸€å¤„ç†å·¥å…·æ‰§è¡Œé”™è¯¯
    
    è¯¥è£…é¥°å™¨ç”¨äºæ•è·å·¥å…·æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å¼‚å¸¸ï¼Œå¹¶è¿”å›å‹å¥½çš„é”™è¯¯æ¶ˆæ¯ç»™æ¨¡å‹ã€‚
    
    å‚æ•°:
        request: å·¥å…·è°ƒç”¨è¯·æ±‚å¯¹è±¡ï¼ŒåŒ…å«tool_callç­‰ä¿¡æ¯
        handler: å·¥å…·å¤„ç†å‡½æ•°
        
    è¿”å›:
        å·¥å…·æ‰§è¡Œç»“æœæˆ–ToolMessageé”™è¯¯æ¶ˆæ¯
    """
    try:
        return handler(request)
    except Exception as e:
        print(f"âš ï¸  å·¥å…· {request.tool_call['name']} æ‰§è¡Œå¤±è´¥: {str(e)}")
        # è¿”å›å‹å¥½çš„é”™è¯¯æ¶ˆæ¯ç»™æ¨¡å‹
        return ToolMessage(
            content=f"å·¥å…·æ‰§è¡Œå¤±è´¥: è¯·æ£€æŸ¥è¾“å…¥å‚æ•°ã€‚è¯¦æƒ…: {str(e)}",
            tool_call_id=request.tool_call["id"]
        )


def tool_error_handling_example():
    """å·¥å…·é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    print("=" * 50)
    print("å·¥å…·é”™è¯¯å¤„ç†ç¤ºä¾‹")
    print("=" * 50)

    model = ChatZhipuAI(model="glm-4.6", temperature=0.5)

    agent = create_agent(
        model=model,
        tools=[get_weather, calculate, risky_operation],
        middleware=[handle_tool_errors],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹,å¯ä»¥æŸ¥è¯¢å¤©æ°”ã€è®¡ç®—å’Œæ‰§è¡Œæ“ä½œ"
    )

    # æµ‹è¯•ä¼šå¯¼è‡´é”™è¯¯çš„æŸ¥è¯¢
    test_queries = [
        "ç«æ˜Ÿçš„å¤©æ°”å¦‚ä½•ï¼Ÿ",  # ä¼šå¯¼è‡´å¤©æ°”APIé”™è¯¯
        "è®¡ç®— 10 / 0",  # ä¼šå¯¼è‡´è®¡ç®—é”™è¯¯
        "æ‰§è¡Œ error æ“ä½œ"  # ä¼šå¯¼è‡´æ“ä½œå¤±è´¥
    ]

    for query in test_queries:
        print(f"\né—®é¢˜: {query}")
        try:
            result = agent.invoke({
                "messages": [{"role": "user", "content": query}]
            })
            print(f"å›ç­”: {result['messages'][-1].content}")
        except Exception as e:
            print(f"å¼‚å¸¸: {str(e)}")


# ==================== 3. åŠ¨æ€æ¨¡å‹é€‰æ‹©ä¸­é—´ä»¶ ====================

@wrap_model_call
def dynamic_model_selection(request, handler):
    """æ ¹æ®å¯¹è¯å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
    message_count = len(request.messages)

    print(f"\nğŸ“Š å½“å‰æ¶ˆæ¯æ•°: {message_count}")

    # æ ¹æ®æ¶ˆæ¯æ•°é‡é€‰æ‹©æ¨¡å‹
    if message_count > 5:
        print("âœ¨ ä½¿ç”¨é«˜çº§æ¨¡å‹ (glm-4.6)")
        model = ChatZhipuAI(model="glm-4.6", temperature=0.7)
    else:
        print("âš¡ ä½¿ç”¨å¿«é€Ÿæ¨¡å‹ (glm-4-flash)")
        model = ChatZhipuAI(model="glm-4-flash", temperature=0.5)

    # ä½¿ç”¨overrideæ–¹æ³•æ›¿æ¢æ¨¡å‹
    request = request.override(model=model)
    return handler(request)


def dynamic_model_example():
    """åŠ¨æ€æ¨¡å‹é€‰æ‹©ç¤ºä¾‹"""
    print("\n" + "=" * 50)
    print("åŠ¨æ€æ¨¡å‹é€‰æ‹©ç¤ºä¾‹")
    print("=" * 50)

    # åˆå§‹ä½¿ç”¨åŸºç¡€æ¨¡å‹
    basic_model = ChatZhipuAI(model="glm-4-flash", temperature=0.5)

    agent = create_agent(
        model=basic_model,
        tools=[search, get_weather],
        middleware=[dynamic_model_selection],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹"
    )

    # çŸ­å¯¹è¯
    print("\n--- çŸ­å¯¹è¯æµ‹è¯• ---")
    result = agent.invoke({
        "messages": [{"role": "user", "content": "ä½ å¥½"}]
    })
    print(f"å›ç­”: {result['messages'][-1].content}")


# ==================== 4. åŠ¨æ€æç¤ºè¯ä¸­é—´ä»¶ ====================

@dynamic_prompt
def context_aware_prompt(request):
    """åŸºäºä¸Šä¸‹æ–‡ç”ŸæˆåŠ¨æ€æç¤º"""
    message_count = len(request.messages)

    base = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"

    # é•¿å¯¹è¯æ—¶è¦æ±‚ç®€æ´
    if message_count > 10:
        base += "\nè¿™æ˜¯ä¸€ä¸ªé•¿å¯¹è¯ - è¯·ä¿æŒå›ç­”ç®€æ´ã€‚"

    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    has_tool_calls = any(
        hasattr(msg, 'tool_calls') and msg.tool_calls
        for msg in request.messages
    )
    if has_tool_calls:
        base += "\nä½ å·²ç»ä½¿ç”¨äº†å·¥å…·,è¯·åŸºäºå·¥å…·ç»“æœç»™å‡ºå‡†ç¡®å›ç­”ã€‚"

    return base


def dynamic_prompt_example():
    """åŠ¨æ€æç¤ºè¯ç¤ºä¾‹"""
    print("\n" + "=" * 50)
    print("åŠ¨æ€æç¤ºè¯ç¤ºä¾‹")
    print("=" * 50)

    model = ChatZhipuAI(model="glm-4.6", temperature=0.5)

    agent = create_agent(
        model=model,
        tools=[search, get_weather],
        middleware=[context_aware_prompt]
    )

    # æµ‹è¯•æŸ¥è¯¢
    result = agent.invoke({
        "messages": [{"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}]
    })

    print(f"\né—®é¢˜: åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ")
    print(f"å›ç­”: {result['messages'][-1].content}")


# ==================== 5. before_model é’©å­ ====================

@before_model
def log_before_model(state, runtime):
    """è®°å½•æ¨¡å‹è°ƒç”¨å‰çš„çŠ¶æ€"""
    print(f"\nğŸ” å‡†å¤‡è°ƒç”¨æ¨¡å‹,å½“å‰æœ‰ {len(state['messages'])} æ¡æ¶ˆæ¯")
    return None  # ä¸ä¿®æ”¹çŠ¶æ€


def before_model_example():
    """before_model é’©å­ç¤ºä¾‹"""
    print("\n" + "=" * 50)
    print("before_model é’©å­ç¤ºä¾‹")
    print("=" * 50)

    model = ChatZhipuAI(model="glm-4.6", temperature=0.5)

    agent = create_agent(
        model=model,
        tools=[search],
        middleware=[log_before_model],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹"
    )

    result = agent.invoke({
        "messages": [{"role": "user", "content": "æœç´¢ Python æ•™ç¨‹"}]
    })

    print(f"\nå›ç­”: {result['messages'][-1].content}")


# ==================== 6. after_model é’©å­ ====================

@after_model(can_jump_to=["end"])
def validate_output(state, runtime):
    """éªŒè¯æ¨¡å‹è¾“å‡ºå¹¶åº”ç”¨å†…å®¹è¿‡æ»¤"""
    last_message = state["messages"][-1]

    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¦æ­¢å†…å®¹
    forbidden_words = ["ç¦æ­¢", "æ•æ„Ÿ"]
    if any(word in last_message.content for word in forbidden_words):
        print("\nâš ï¸  æ£€æµ‹åˆ°ç¦æ­¢å†…å®¹,æå‰ç»“æŸ")
        return {
            "messages": [AIMessage(content="æŠ±æ­‰,æˆ‘æ— æ³•å›åº”è¯¥è¯·æ±‚ã€‚")],
            "jump_to": "end"  # æå‰ç»“æŸ Agent
        }

    return None


def after_model_example():
    """after_model é’©å­ç¤ºä¾‹"""
    print("\n" + "=" * 50)
    print("after_model é’©å­ç¤ºä¾‹")
    print("=" * 50)

    model = ChatZhipuAI(model="glm-4.6", temperature=0.5)

    agent = create_agent(
        model=model,
        tools=[search],
        middleware=[validate_output],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹"
    )

    # æ­£å¸¸æŸ¥è¯¢
    result = agent.invoke({
        "messages": [{"role": "user", "content": "æœç´¢å¤©æ°”ä¿¡æ¯"}]
    })
    print(f"\né—®é¢˜: æœç´¢å¤©æ°”ä¿¡æ¯")
    print(f"å›ç­”: {result['messages'][-1].content}")


# ==================== 7. å·¥å…·æ‰§è¡Œæ—¥å¿—ä¸­é—´ä»¶ ====================

@wrap_tool_call
def log_tool_execution(request, handler):
    """è®°å½•å·¥å…·æ‰§è¡Œ"""
    tool_name = request.tool_call["name"]
    print(f"\nğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}")
    print(f"   å‚æ•°: {request.tool_call.get('args', {})}")

    start_time = time.time()
    result = handler(request)
    elapsed = time.time() - start_time

    print(f"âœ… å·¥å…· {tool_name} å®Œæˆ,è€—æ—¶: {elapsed:.2f}s")
    return result


def tool_logging_example():
    """å·¥å…·æ‰§è¡Œæ—¥å¿—ç¤ºä¾‹"""
    print("\n" + "=" * 50)
    print("å·¥å…·æ‰§è¡Œæ—¥å¿—ç¤ºä¾‹")
    print("=" * 50)

    model = ChatZhipuAI(model="glm-4.6", temperature=0.5)

    agent = create_agent(
        model=model,
        tools=[search, get_weather, calculate],
        middleware=[log_tool_execution],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹,å¯ä»¥æœç´¢ã€æŸ¥å¤©æ°”ã€è®¡ç®—"
    )

    result = agent.invoke({
        "messages": [{"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿç„¶åè®¡ç®— 100 * 50"}]
    })

    print(f"\næœ€ç»ˆå›ç­”: {result['messages'][-1].content}")


# ==================== 8. ç»„åˆå¤šä¸ªä¸­é—´ä»¶ ====================

def combined_middleware_example():
    """ç»„åˆå¤šä¸ªä¸­é—´ä»¶ç¤ºä¾‹"""
    print("\n" + "=" * 50)
    print("ç»„åˆå¤šä¸ªä¸­é—´ä»¶ç¤ºä¾‹")
    print("=" * 50)

    model = ChatZhipuAI(model="glm-4.6", temperature=0.5)

    agent = create_agent(
        model=model,
        tools=[search, get_weather, calculate],
        middleware=[
            log_before_model,      # è®°å½•è°ƒç”¨å‰çŠ¶æ€
            context_aware_prompt,  # åŠ¨æ€æç¤ºè¯
            handle_tool_errors,    # å·¥å…·é”™è¯¯å¤„ç†
            log_tool_execution,    # å·¥å…·æ‰§è¡Œæ—¥å¿—
        ],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹"
    )

    result = agent.invoke({
        "messages": [{"role": "user", "content": "æŸ¥è¯¢ä¸Šæµ·å¤©æ°”,å¹¶è®¡ç®— 25 * 4"}]
    })

    print(f"\næœ€ç»ˆå›ç­”: {result['messages'][-1].content}")


if __name__ == "__main__":
    try:
        # tool_error_handling_example()
        # dynamic_model_example()
        # dynamic_prompt_example()
        # before_model_example()
        # after_model_example()
        # tool_logging_example()
        combined_middleware_example()
    except Exception as e:
        print(f"\né”™è¯¯: {str(e)}")
        print("è¯·ç¡®ä¿å·²è®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡")
