"""
ç¤ºä¾‹1ï¼šModel ä¸­ä½¿ç”¨ Streaming - åŸºç¡€ç”¨æ³•
æ¼”ç¤ºå¦‚ä½•åœ¨ LangChain Model ä¸­ä½¿ç”¨æµå¼ä¼ è¾“
"""

import os
import time
from langchain_community.chat_models import ChatZhipuAI
from langchain_core.messages import AIMessageChunk

os.environ["ZHIPUAI_API_KEY"] = os.getenv("ZHIPUAI_API_KEY", "your_api_key")


# ==================== ç¤ºä¾‹ 1.1: åŸºç¡€æµå¼è¾“å‡º ====================

def example_01_basic_streaming():
    """ç¤ºä¾‹ 1.1: åŸºç¡€ Token æµå¼è¾“å‡º"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1.1: åŸºç¡€ Token æµå¼è¾“å‡º")
    print("=" * 60)

    model = ChatZhipuAI(model="glm-4.5-air", temperature=0.7)

    print("\nğŸ‘¤ ç”¨æˆ·: ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½")
    print("\nğŸ¤– AI æµå¼å“åº”:")
    print("   ", end="", flush=True)

    # æµå¼è¾“å‡ºï¼Œé€ä¸ª token æ˜¾ç¤º
    for chunk in model.stream("ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½"):
        if hasattr(chunk, 'content') and chunk.content:
            print(chunk.content, end="", flush=True)
            time.sleep(0.02)  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ

    print("\n")


# ==================== ç¤ºä¾‹ 1.2: ç´¯ç§¯æ¶ˆæ¯å— ====================

def example_02_accumulate_chunks():
    """ç¤ºä¾‹ 1.2: ç´¯ç§¯æ¶ˆæ¯å—"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1.2: ç´¯ç§¯æ¶ˆæ¯å—")
    print("=" * 60)

    model = ChatZhipuAI(model="glm-4.5-air", temperature=0.7)

    print("\nğŸ‘¤ ç”¨æˆ·: åˆ—ä¸¾ä¸‰ç§ç¼–ç¨‹è¯­è¨€")
    print("\nğŸ“Š ç´¯ç§¯è¿‡ç¨‹:")

    full_message = None
    chunk_count = 0

    for chunk in model.stream("åˆ—ä¸¾ä¸‰ç§ç¼–ç¨‹è¯­è¨€"):
        chunk_count += 1

        # ç´¯ç§¯æ¶ˆæ¯å—
        if full_message is None:
            full_message = chunk
        else:
            full_message = full_message + chunk

        # æ¯5ä¸ªå—æ˜¾ç¤ºä¸€æ¬¡å½“å‰ç´¯ç§¯ç»“æœ
        if chunk_count % 5 == 0 and hasattr(full_message, 'content'):
            print(f"   å— #{chunk_count}: {full_message.content[:50]}...")

    print(f"\nâœ… å®Œæ•´æ¶ˆæ¯ (å…± {chunk_count} ä¸ªå—):")
    print(f"   ç±»å‹: {type(full_message)}")
    print(f"   å†…å®¹: {full_message.content}")


# ==================== ç¤ºä¾‹ 1.3: æµå¼è¾“å‡ºå¸¦å…ƒæ•°æ® ====================

def example_03_streaming_with_metadata():
    """ç¤ºä¾‹ 1.3: æµå¼è¾“å‡ºå¸¦å…ƒæ•°æ®"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1.3: æµå¼è¾“å‡ºå¸¦å…ƒæ•°æ®")
    print("=" * 60)

    model = ChatZhipuAI(model="glm-4.5-air", temperature=0.7)

    print("\nğŸ‘¤ ç”¨æˆ·: è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ")
    print("\nğŸ“‹ æµå¼å—è¯¦æƒ…:")

    total_content = ""
    chunk_sizes = []

    for i, chunk in enumerate(model.stream("è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "), 1):
        if hasattr(chunk, 'content') and chunk.content:
            content = chunk.content
            total_content += content
            chunk_sizes.append(len(content))

            # æ˜¾ç¤ºæ¯ä¸ªå—çš„è¯¦ç»†ä¿¡æ¯
            if i <= 5 or i % 10 == 0:  # åªæ˜¾ç¤ºå‰5ä¸ªå’Œä¹‹åæ¯10ä¸ª
                print(f"   å— #{i}:")
                print(f"      å†…å®¹: '{content}'")
                print(f"      é•¿åº¦: {len(content)} å­—ç¬¦")
                if hasattr(chunk, 'response_metadata'):
                    print(f"      å…ƒæ•°æ®: {chunk.response_metadata}")

    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"   æ€»å—æ•°: {len(chunk_sizes)}")
    print(f"   æ€»å­—ç¬¦: {len(total_content)}")
    print(f"   å¹³å‡å—å¤§å°: {sum(chunk_sizes) / len(chunk_sizes) if chunk_sizes else 0:.2f} å­—ç¬¦")


# ==================== ç¤ºä¾‹ 1.4: å®æ—¶æ‰“å­—æ•ˆæœ ====================

def example_04_typing_effect():
    """ç¤ºä¾‹ 1.4: æ¨¡æ‹Ÿå®æ—¶æ‰“å­—æ•ˆæœ"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1.4: å®æ—¶æ‰“å­—æ•ˆæœ")
    print("=" * 60)

    model = ChatZhipuAI(model="glm-4.5-air", temperature=0.7)

    print("\nğŸ‘¤ ç”¨æˆ·: å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—")
    print("\nğŸ–Šï¸  AI æ­£åœ¨åˆ›ä½œ...")
    print("\n" + "-" * 60)

    # æ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ
    for chunk in model.stream("å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—ï¼ˆå››å¥ï¼‰"):
        if hasattr(chunk, 'content') and chunk.content:
            for char in chunk.content:
                print(char, end="", flush=True)
                time.sleep(0.05)  # æ‰“å­—å»¶è¿Ÿ

    print("\n" + "-" * 60)


# ==================== ç¤ºä¾‹ 1.5: æµå¼è¾“å‡ºä¸éæµå¼å¯¹æ¯” ====================

def example_05_streaming_vs_non_streaming():
    """ç¤ºä¾‹ 1.5: æµå¼ vs éæµå¼æ€§èƒ½å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1.5: æµå¼ vs éæµå¼æ€§èƒ½å¯¹æ¯”")
    print("=" * 60)

    model = ChatZhipuAI(model="glm-4.5-air", temperature=0.7)
    prompt = "ç”¨100å­—ä»‹ç»æ·±åº¦å­¦ä¹ "

    # éæµå¼
    print("\nâ±ï¸  éæµå¼è°ƒç”¨:")
    print("   ç­‰å¾…å®Œæ•´å“åº”...")
    start_time = time.time()
    response = model.invoke(prompt)
    end_time = time.time()
    print(f"   âœ… å®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")
    print(f"   å“åº”: {response.content[:50]}...")

    print("\n" + "-" * 60)

    # æµå¼
    print("\nâš¡ æµå¼è°ƒç”¨:")
    print("   ", end="", flush=True)
    start_time = time.time()
    first_chunk_time = None

    for i, chunk in enumerate(model.stream(prompt)):
        if hasattr(chunk, 'content') and chunk.content:
            if first_chunk_time is None:
                first_chunk_time = time.time()
                print(f"\n   âš¡ é¦–ä¸ªå—åˆ°è¾¾: {first_chunk_time - start_time:.2f}ç§’")
                print("   ", end="", flush=True)

            print(chunk.content, end="", flush=True)

    end_time = time.time()
    print(f"\n   âœ… å®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")

    if first_chunk_time:
        print(f"\nğŸ’¡ æ„ŸçŸ¥æ€§èƒ½æå‡: {(end_time - start_time) - (first_chunk_time - start_time):.2f}ç§’")


# ==================== ç¤ºä¾‹ 1.6: å¤„ç†æµå¼ä¸­æ–­ ====================

def example_06_handle_streaming_interruption():
    """ç¤ºä¾‹ 1.6: å¤„ç†æµå¼ä¼ è¾“ä¸­æ–­"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1.6: å¤„ç†æµå¼ä¼ è¾“ä¸­æ–­")
    print("=" * 60)

    model = ChatZhipuAI(model="glm-4.5-air", temperature=0.7)

    print("\nğŸ‘¤ ç”¨æˆ·: è¯¦ç»†ä»‹ç»äº‘è®¡ç®—çš„å‘å±•å†å²")
    print("\nğŸ›‘ æ¨¡æ‹Ÿï¼šåœ¨æ¥æ”¶åˆ°50ä¸ªå­—ç¬¦åä¸­æ–­")
    print("\nğŸ¤– AI å“åº”:")
    print("   ", end="", flush=True)

    total_chars = 0
    max_chars = 50

    try:
        for chunk in model.stream("è¯¦ç»†ä»‹ç»äº‘è®¡ç®—çš„å‘å±•å†å²"):
            if hasattr(chunk, 'content') and chunk.content:
                content = chunk.content

                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
                if total_chars + len(content) > max_chars:
                    # åªæ‰“å°éƒ¨åˆ†å†…å®¹
                    remaining = max_chars - total_chars
                    print(content[:remaining], end="", flush=True)
                    print("\n\n   âš ï¸  å·²è¾¾åˆ°å­—ç¬¦é™åˆ¶ï¼Œä¸­æ–­æµå¼ä¼ è¾“")
                    break

                print(content, end="", flush=True)
                total_chars += len(content)

    except KeyboardInterrupt:
        print("\n\n   âš ï¸  ç”¨æˆ·ä¸­æ–­")

    print(f"\n   ğŸ“Š æ¥æ”¶å­—ç¬¦æ•°: {total_chars}")


# ==================== ä¸»å‡½æ•° ====================

def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("LangChain Streaming - Model åŸºç¡€ç”¨æ³•")
    print("=" * 60)

    examples = [
        # ("åŸºç¡€ Token æµå¼è¾“å‡º", example_01_basic_streaming),
        # ("ç´¯ç§¯æ¶ˆæ¯å—", example_02_accumulate_chunks),
        # ("æµå¼è¾“å‡ºå¸¦å…ƒæ•°æ®", example_03_streaming_with_metadata),
        # ("å®æ—¶æ‰“å­—æ•ˆæœ", example_04_typing_effect),
        # ("æµå¼ vs éæµå¼å¯¹æ¯”", example_05_streaming_vs_non_streaming),
        ("å¤„ç†æµå¼ä¸­æ–­", example_06_handle_streaming_interruption),
    ]

    for i, (name, func) in enumerate(examples, 1):
        print(f"\n{'='*60}")
        print(f"è¿è¡Œç¤ºä¾‹ {i}/{len(examples)}: {name}")
        print(f"{'='*60}")
        try:
            func()
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²ç»ˆæ­¢")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        print("è¯·ç¡®ä¿å·²è®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡")
