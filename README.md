# GLM-4.6 + LangChain é›†æˆç¤ºä¾‹

æœ¬é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ LangChain æ¡†æ¶é›†æˆæ™ºè°±AIçš„GLM-4.6å¤§è¯­è¨€æ¨¡å‹ï¼Œæä¾›äº†ä»åŸºç¡€è°ƒç”¨åˆ°é«˜çº§åº”ç”¨çš„å®Œæ•´ç¤ºä¾‹ã€‚

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ç¤ºä¾‹è¯´æ˜](#ç¤ºä¾‹è¯´æ˜)
- [APIå‚è€ƒ](#apiå‚è€ƒ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [ç›¸å…³èµ„æº](#ç›¸å…³èµ„æº)

## ğŸš€ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®åŸºäºå®˜æ–¹æ–‡æ¡£åˆ›å»ºï¼Œå±•ç¤ºäº†GLM-4.6æ¨¡å‹ä¸LangChainæ¡†æ¶çš„æ·±åº¦é›†æˆã€‚åŒ…å«ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

- **åŸºç¡€è°ƒç”¨**ï¼šç®€å•çš„æ–‡æœ¬ç”Ÿæˆ
- **æ¶ˆæ¯ç®¡ç†**ï¼šç³»ç»Ÿæç¤ºã€ç”¨æˆ·æ¶ˆæ¯ã€AIå›å¤çš„å¤„ç†
- **æç¤ºè¯æ¨¡æ¿**ï¼šåŠ¨æ€æ„å»ºå¤æ‚çš„æç¤ºè¯
- **é“¾å¼è°ƒç”¨**ï¼šç»„åˆå¤šä¸ªç»„ä»¶å®Œæˆå¤æ‚ä»»åŠ¡
- **å¤šè½®å¯¹è¯**ï¼šç»´æŠ¤å¯¹è¯å†å²çš„ä¸Šä¸‹æ–‡ç†è§£
- **æµå¼è¾“å‡º**ï¼šå®æ—¶ç”Ÿæˆå“åº”å†…å®¹
- **ä»£ç ç”Ÿæˆ**ï¼šæ™ºèƒ½ç¼–ç¨‹è¾…åŠ©

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- æ™ºè°±AI APIå¯†é’¥

### å®‰è£…ä¾èµ–

```bash
pip install langchain langchain-community python-dotenv
```

### ç¯å¢ƒå˜é‡é…ç½®

1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶
2. æ·»åŠ ä½ çš„æ™ºè°±AI APIå¯†é’¥ï¼š

```env
ZHIPUAI_API_KEY=your-zhipu-api-key-here
```

> ğŸ’¡ **è·å–APIå¯†é’¥**ï¼šè®¿é—® [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/) æ³¨å†Œå¹¶è·å–APIå¯†é’¥

## ğŸƒâ€â™‚ï¸ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository-url>
cd langchain-glm-examples
```

### 2. é…ç½®APIå¯†é’¥

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå°† `your-zhipu-api-key-here` æ›¿æ¢ä¸ºä½ çš„å®é™…APIå¯†é’¥ã€‚

### 3. è¿è¡Œç¤ºä¾‹

```bash
python glm_official_example.py
```

ç¨‹åºå°†ä¾æ¬¡è¿è¡Œæ‰€æœ‰ç¤ºä¾‹ï¼Œå±•ç¤ºGLM-4.6çš„ä¸åŒåŠŸèƒ½ç‰¹æ€§ã€‚

## ğŸ“š ç¤ºä¾‹è¯´æ˜

### 1. åŸºç¡€ç¤ºä¾‹ (`basic_example`)

æœ€ç®€å•çš„GLM-4è°ƒç”¨æ–¹å¼ï¼š

```python
from langchain_community.chat_models import ChatZhipuAI

chat = ChatZhipuAI(
    model="glm-4",
    temperature=0.5,
    api_key=api_key
)

response = chat.invoke("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹GLM-4æ¨¡å‹")
```

**ç‰¹ç‚¹**ï¼š
- ç›´æ¥æ–‡æœ¬è¾“å…¥è¾“å‡º
- é€‚åˆç®€å•çš„é—®ç­”åœºæ™¯
- å¯è°ƒèŠ‚temperatureæ§åˆ¶è¾“å‡ºéšæœºæ€§

### 2. æ¶ˆæ¯ç¤ºä¾‹ (`message_example`)

ä½¿ç”¨ç»“æ„åŒ–æ¶ˆæ¯è¿›è¡Œäº¤äº’ï¼š

```python
from langchain_core.messages import HumanMessage, SystemMessage

messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¼–ç¨‹åŠ©æ‰‹"),
    HumanMessage(content="è¯·è§£é‡Šä¸€ä¸‹Pythonä¸­çš„è£…é¥°å™¨")
]
response = chat.invoke(messages)
```

**ç‰¹ç‚¹**ï¼š
- æ”¯æŒç³»ç»Ÿæç¤ºè®¾å®šè§’è‰²
- ç»“æ„åŒ–æ¶ˆæ¯ä¼ é€’
- æ›´å¥½çš„ä¸Šä¸‹æ–‡æ§åˆ¶

### 3. æç¤ºè¯æ¨¡æ¿ç¤ºä¾‹ (`prompt_template_example`)

åŠ¨æ€æ„å»ºå¤æ‚æç¤ºè¯ï¼š

```python
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ª{role}ï¼Œæ“…é•¿{expertise}ã€‚"),
    ("human", "è¯·{task}ï¼š{topic}")
])

formatted_prompt = prompt.format_messages(
    role="ç§‘æŠ€åšä¸»",
    expertise="ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µ",
    task="è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
    topic="æœºå™¨å­¦ä¹ çš„åŸºæœ¬åŸç†"
)
```

**ç‰¹ç‚¹**ï¼š
- å‚æ•°åŒ–æç¤ºè¯æ¨¡æ¿
- åŠ¨æ€å†…å®¹å¡«å……
- é«˜åº¦å¯å¤ç”¨

### 4. é“¾å¼è°ƒç”¨ç¤ºä¾‹ (`chain_example`)

ä½¿ç”¨LCELï¼ˆLangChain Expression Languageï¼‰æ„å»ºå¤„ç†é“¾ï¼š

```python
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template(
    "è¯·ä¸ºä¸»é¢˜'{topic}'å†™ä¸€ä¸ª{style}çš„{length}ã€‚è¦æ±‚ï¼š{requirements}"
)

chain = prompt | chat | StrOutputParser()
result = chain.invoke({
    "topic": "äººå·¥æ™ºèƒ½ä¸äººç±»çš„å…³ç³»",
    "style": "å¯Œæœ‰æƒ³è±¡åŠ›",
    "length": "çŸ­è¯—",
    "requirements": "è¯­è¨€ä¼˜ç¾ï¼Œæ„å¢ƒæ·±è¿œ"
})
```

**ç‰¹ç‚¹**ï¼š
- å£°æ˜å¼ç¼–ç¨‹é£æ ¼
- ç»„ä»¶åŒ–è®¾è®¡
- æ˜“äºæ‰©å±•å’Œç»´æŠ¤

### 5. å¤šè½®å¯¹è¯ç¤ºä¾‹ (`conversation_example`)

ç»´æŠ¤å¯¹è¯å†å²çš„ä¸Šä¸‹æ–‡ç†è§£ï¼š

```python
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿè®°ä½å¯¹è¯å†…å®¹ã€‚"),
    HumanMessage(content="ä½ å¥½ï¼Œæˆ‘å«å°æ˜ï¼Œæˆ‘æ˜¯ä¸€åå¤§å­¦ç”Ÿã€‚"),
    AIMessage(content="ä½ å¥½å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ æ­£åœ¨å­¦ä¹ ä»€ä¹ˆä¸“ä¸šå‘¢ï¼Ÿ"),
    HumanMessage(content="æˆ‘åœ¨å­¦ä¹ è®¡ç®—æœºç§‘å­¦ã€‚"),
    AIMessage(content="è®¡ç®—æœºç§‘å­¦æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„ä¸“ä¸šï¼ä½ å¯¹å“ªä¸ªæ–¹å‘æœ€æ„Ÿå…´è¶£å‘¢ï¼Ÿ"),
    HumanMessage(content="æˆ‘å¯¹äººå·¥æ™ºèƒ½æœ€æ„Ÿå…´è¶£ï¼Œç‰¹åˆ«æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ã€‚")
]
response = chat.invoke(messages)
```

**ç‰¹ç‚¹**ï¼š
- å®Œæ•´å¯¹è¯å†å²ç®¡ç†
- ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›
- è¿è´¯çš„å¤šè½®äº¤äº’

### 6. æµå¼è¾“å‡ºç¤ºä¾‹ (`streaming_example`)

å®æ—¶ç”Ÿæˆå“åº”å†…å®¹ï¼š

```python
chat = ChatZhipuAI(
    model="glm-4",
    temperature=0.7,
    api_key=api_key,
    streaming=True
)
```

**ç‰¹ç‚¹**ï¼š
- å®æ—¶å“åº”ç”¨æˆ·
- æ›´å¥½çš„äº¤äº’ä½“éªŒ
- é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆ

### 7. ä»£ç ç”Ÿæˆç¤ºä¾‹ (`code_generation_example`)

æ™ºèƒ½ç¼–ç¨‹è¾…åŠ©åŠŸèƒ½ï¼š

```python
code_prompt = """è¯·ç”¨Pythonå†™ä¸€ä¸ªå‡½æ•°ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š
1. è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹
2. åŒ…å«é”™è¯¯å¤„ç†
3. æ·»åŠ æ³¨é‡Šè¯´æ˜
4. æä¾›ä½¿ç”¨ç¤ºä¾‹

è¦æ±‚ä»£ç æ¸…æ™°æ˜“æ‡‚ï¼Œé€‚åˆåˆå­¦è€…ç†è§£ã€‚"""
response = chat.invoke(code_prompt)
```

**ç‰¹ç‚¹**ï¼š
- æ™ºèƒ½ä»£ç ç”Ÿæˆ
- åŒ…å«é”™è¯¯å¤„ç†
- è¯¦ç»†æ³¨é‡Šè¯´æ˜
- é€‚åˆç¼–ç¨‹å­¦ä¹ 

## ğŸ“– APIå‚è€ƒ

### ChatZhipuAI å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| model | str | å¦ | "glm-4" | æ¨¡å‹åç§° |
| temperature | float | å¦ | 0.7 | æ§åˆ¶è¾“å‡ºéšæœºæ€§ (0-1) |
| api_key | str | æ˜¯ | - | æ™ºè°±AI APIå¯†é’¥ |
| streaming | bool | å¦ | False | æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º |

### æ”¯æŒçš„æ¨¡å‹

- `glm-4`ï¼šGLM-4.6 é€šç”¨å¤§æ¨¡å‹
- `glm-4-flash`ï¼šGLM-4.6 å¿«é€Ÿç‰ˆæœ¬
- `glm-3-turbo`ï¼šGLM-3 Turboç‰ˆæœ¬

### æ¶ˆæ¯ç±»å‹

- `SystemMessage`ï¼šç³»ç»Ÿæç¤ºæ¶ˆæ¯
- `HumanMessage`ï¼šç”¨æˆ·æ¶ˆæ¯
- `AIMessage`ï¼šAIå›å¤æ¶ˆæ¯

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•è·å–æ™ºè°±AI APIå¯†é’¥ï¼Ÿ

A: è®¿é—® [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/)ï¼Œæ³¨å†Œè´¦å·ååœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥ã€‚

### Q: è°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®
2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
3. APIä½™é¢æ˜¯å¦å……è¶³
4. æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®

### Q: å¦‚ä½•æ§åˆ¶è¾“å‡ºé•¿åº¦ï¼Ÿ

A: å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ï¼š
1. åœ¨æç¤ºè¯ä¸­æ˜ç¡®è¦æ±‚å­—æ•°é™åˆ¶
2. è°ƒæ•´temperatureå‚æ•°ï¼ˆå€¼è¶Šä½è¾“å‡ºè¶Šç®€æ´ï¼‰
3. ä½¿ç”¨output_parserè¿›è¡Œåå¤„ç†

### Q: æµå¼è¾“å‡ºå¦‚ä½•å®ç°ï¼Ÿ

A: è®¾ç½® `streaming=True` å‚æ•°ï¼Œç„¶åä½¿ç”¨é€‚å½“çš„æµå¼å¤„ç†æ–¹æ³•ã€‚å…·ä½“å®ç°è¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ã€‚

### Q: å¦‚ä½•å¤„ç†é•¿æ–‡æœ¬ï¼Ÿ

A: GLM-4.6æ”¯æŒè¾ƒé•¿çš„ä¸Šä¸‹æ–‡ï¼Œä½†ä»å»ºè®®ï¼š
1. åˆç†åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬
2. ä¿æŒæç¤ºè¯ç®€æ´æ˜äº†
3. å¿…è¦æ—¶ä½¿ç”¨æ‘˜è¦æˆ–åˆ†å—å¤„ç†

## ğŸ”— ç›¸å…³èµ„æº

- [LangChainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/)
- [LangChainä¸­æ–‡æ–‡æ¡£](https://python.langchain.ac.cn/)
- [GLM-4.6æ¨¡å‹ä»‹ç»](https://open.bigmodel.cn/model/glm4)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ç”¨äºå­¦ä¹ å’Œæ¼”ç¤ºç›®çš„ï¼Œè¯·éµå¾ªç›¸å…³å¹³å°çš„APIä½¿ç”¨æ¡æ¬¾ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

---

**æ³¨æ„**ï¼šä½¿ç”¨æœ¬ç¤ºä¾‹å‰è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®APIå¯†é’¥ï¼Œå¹¶éµå®ˆæ™ºè°±AIçš„ä½¿ç”¨æ¡æ¬¾ã€‚